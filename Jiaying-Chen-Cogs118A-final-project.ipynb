{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cf31368",
   "metadata": {},
   "source": [
    "Disclaimer: In this notebook, I used GPT to generate code for print statements and debug logs, as well as generating plots. But the idea, the words and choosing the datasets and working with them are all my work. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5365009",
   "metadata": {},
   "source": [
    "# 1. Imports\n",
    "- frameworks\n",
    "- datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f2a7975f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic utilities\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# Data preprocessing\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "\n",
    "# Classifiers\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Plotting (Plotly)\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "410556d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 147269 entries, 0 to 147268\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   Name         147269 non-null  object \n",
      " 1   Gender       147269 non-null  object \n",
      " 2   Count        147269 non-null  int64  \n",
      " 3   Probability  147269 non-null  float64\n",
      "dtypes: float64(1), int64(1), object(2)\n",
      "memory usage: 4.5+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8124 entries, 0 to 8123\n",
      "Data columns (total 23 columns):\n",
      " #   Column                    Non-Null Count  Dtype \n",
      "---  ------                    --------------  ----- \n",
      " 0   class                     8124 non-null   object\n",
      " 1   cap-shape                 8124 non-null   object\n",
      " 2   cap-surface               8124 non-null   object\n",
      " 3   cap-color                 8124 non-null   object\n",
      " 4   bruises                   8124 non-null   object\n",
      " 5   odor                      8124 non-null   object\n",
      " 6   gill-attachment           8124 non-null   object\n",
      " 7   gill-spacing              8124 non-null   object\n",
      " 8   gill-size                 8124 non-null   object\n",
      " 9   gill-color                8124 non-null   object\n",
      " 10  stalk-shape               8124 non-null   object\n",
      " 11  stalk-root                8124 non-null   object\n",
      " 12  stalk-surface-above-ring  8124 non-null   object\n",
      " 13  stalk-surface-below-ring  8124 non-null   object\n",
      " 14  stalk-color-above-ring    8124 non-null   object\n",
      " 15  stalk-color-below-ring    8124 non-null   object\n",
      " 16  veil-type                 8124 non-null   object\n",
      " 17  veil-color                8124 non-null   object\n",
      " 18  ring-number               8124 non-null   object\n",
      " 19  ring-type                 8124 non-null   object\n",
      " 20  spore-print-color         8124 non-null   object\n",
      " 21  population                8124 non-null   object\n",
      " 22  habitat                   8124 non-null   object\n",
      "dtypes: object(23)\n",
      "memory usage: 1.4+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6819 entries, 0 to 6818\n",
      "Data columns (total 96 columns):\n",
      " #   Column                                                    Non-Null Count  Dtype  \n",
      "---  ------                                                    --------------  -----  \n",
      " 0   Bankrupt?                                                 6819 non-null   int64  \n",
      " 1    ROA(C) before interest and depreciation before interest  6819 non-null   float64\n",
      " 2    ROA(A) before interest and % after tax                   6819 non-null   float64\n",
      " 3    ROA(B) before interest and depreciation after tax        6819 non-null   float64\n",
      " 4    Operating Gross Margin                                   6819 non-null   float64\n",
      " 5    Realized Sales Gross Margin                              6819 non-null   float64\n",
      " 6    Operating Profit Rate                                    6819 non-null   float64\n",
      " 7    Pre-tax net Interest Rate                                6819 non-null   float64\n",
      " 8    After-tax net Interest Rate                              6819 non-null   float64\n",
      " 9    Non-industry income and expenditure/revenue              6819 non-null   float64\n",
      " 10   Continuous interest rate (after tax)                     6819 non-null   float64\n",
      " 11   Operating Expense Rate                                   6819 non-null   float64\n",
      " 12   Research and development expense rate                    6819 non-null   float64\n",
      " 13   Cash flow rate                                           6819 non-null   float64\n",
      " 14   Interest-bearing debt interest rate                      6819 non-null   float64\n",
      " 15   Tax rate (A)                                             6819 non-null   float64\n",
      " 16   Net Value Per Share (B)                                  6819 non-null   float64\n",
      " 17   Net Value Per Share (A)                                  6819 non-null   float64\n",
      " 18   Net Value Per Share (C)                                  6819 non-null   float64\n",
      " 19   Persistent EPS in the Last Four Seasons                  6819 non-null   float64\n",
      " 20   Cash Flow Per Share                                      6819 non-null   float64\n",
      " 21   Revenue Per Share (Yuan ¥)                               6819 non-null   float64\n",
      " 22   Operating Profit Per Share (Yuan ¥)                      6819 non-null   float64\n",
      " 23   Per Share Net profit before tax (Yuan ¥)                 6819 non-null   float64\n",
      " 24   Realized Sales Gross Profit Growth Rate                  6819 non-null   float64\n",
      " 25   Operating Profit Growth Rate                             6819 non-null   float64\n",
      " 26   After-tax Net Profit Growth Rate                         6819 non-null   float64\n",
      " 27   Regular Net Profit Growth Rate                           6819 non-null   float64\n",
      " 28   Continuous Net Profit Growth Rate                        6819 non-null   float64\n",
      " 29   Total Asset Growth Rate                                  6819 non-null   float64\n",
      " 30   Net Value Growth Rate                                    6819 non-null   float64\n",
      " 31   Total Asset Return Growth Rate Ratio                     6819 non-null   float64\n",
      " 32   Cash Reinvestment %                                      6819 non-null   float64\n",
      " 33   Current Ratio                                            6819 non-null   float64\n",
      " 34   Quick Ratio                                              6819 non-null   float64\n",
      " 35   Interest Expense Ratio                                   6819 non-null   float64\n",
      " 36   Total debt/Total net worth                               6819 non-null   float64\n",
      " 37   Debt ratio %                                             6819 non-null   float64\n",
      " 38   Net worth/Assets                                         6819 non-null   float64\n",
      " 39   Long-term fund suitability ratio (A)                     6819 non-null   float64\n",
      " 40   Borrowing dependency                                     6819 non-null   float64\n",
      " 41   Contingent liabilities/Net worth                         6819 non-null   float64\n",
      " 42   Operating profit/Paid-in capital                         6819 non-null   float64\n",
      " 43   Net profit before tax/Paid-in capital                    6819 non-null   float64\n",
      " 44   Inventory and accounts receivable/Net value              6819 non-null   float64\n",
      " 45   Total Asset Turnover                                     6819 non-null   float64\n",
      " 46   Accounts Receivable Turnover                             6819 non-null   float64\n",
      " 47   Average Collection Days                                  6819 non-null   float64\n",
      " 48   Inventory Turnover Rate (times)                          6819 non-null   float64\n",
      " 49   Fixed Assets Turnover Frequency                          6819 non-null   float64\n",
      " 50   Net Worth Turnover Rate (times)                          6819 non-null   float64\n",
      " 51   Revenue per person                                       6819 non-null   float64\n",
      " 52   Operating profit per person                              6819 non-null   float64\n",
      " 53   Allocation rate per person                               6819 non-null   float64\n",
      " 54   Working Capital to Total Assets                          6819 non-null   float64\n",
      " 55   Quick Assets/Total Assets                                6819 non-null   float64\n",
      " 56   Current Assets/Total Assets                              6819 non-null   float64\n",
      " 57   Cash/Total Assets                                        6819 non-null   float64\n",
      " 58   Quick Assets/Current Liability                           6819 non-null   float64\n",
      " 59   Cash/Current Liability                                   6819 non-null   float64\n",
      " 60   Current Liability to Assets                              6819 non-null   float64\n",
      " 61   Operating Funds to Liability                             6819 non-null   float64\n",
      " 62   Inventory/Working Capital                                6819 non-null   float64\n",
      " 63   Inventory/Current Liability                              6819 non-null   float64\n",
      " 64   Current Liabilities/Liability                            6819 non-null   float64\n",
      " 65   Working Capital/Equity                                   6819 non-null   float64\n",
      " 66   Current Liabilities/Equity                               6819 non-null   float64\n",
      " 67   Long-term Liability to Current Assets                    6819 non-null   float64\n",
      " 68   Retained Earnings to Total Assets                        6819 non-null   float64\n",
      " 69   Total income/Total expense                               6819 non-null   float64\n",
      " 70   Total expense/Assets                                     6819 non-null   float64\n",
      " 71   Current Asset Turnover Rate                              6819 non-null   float64\n",
      " 72   Quick Asset Turnover Rate                                6819 non-null   float64\n",
      " 73   Working capitcal Turnover Rate                           6819 non-null   float64\n",
      " 74   Cash Turnover Rate                                       6819 non-null   float64\n",
      " 75   Cash Flow to Sales                                       6819 non-null   float64\n",
      " 76   Fixed Assets to Assets                                   6819 non-null   float64\n",
      " 77   Current Liability to Liability                           6819 non-null   float64\n",
      " 78   Current Liability to Equity                              6819 non-null   float64\n",
      " 79   Equity to Long-term Liability                            6819 non-null   float64\n",
      " 80   Cash Flow to Total Assets                                6819 non-null   float64\n",
      " 81   Cash Flow to Liability                                   6819 non-null   float64\n",
      " 82   CFO to Assets                                            6819 non-null   float64\n",
      " 83   Cash Flow to Equity                                      6819 non-null   float64\n",
      " 84   Current Liability to Current Assets                      6819 non-null   float64\n",
      " 85   Liability-Assets Flag                                    6819 non-null   int64  \n",
      " 86   Net Income to Total Assets                               6819 non-null   float64\n",
      " 87   Total assets to GNP price                                6819 non-null   float64\n",
      " 88   No-credit Interval                                       6819 non-null   float64\n",
      " 89   Gross Profit to Sales                                    6819 non-null   float64\n",
      " 90   Net Income to Stockholder's Equity                       6819 non-null   float64\n",
      " 91   Liability to Equity                                      6819 non-null   float64\n",
      " 92   Degree of Financial Leverage (DFL)                       6819 non-null   float64\n",
      " 93   Interest Coverage Ratio (Interest expense to EBIT)       6819 non-null   float64\n",
      " 94   Net Income Flag                                          6819 non-null   int64  \n",
      " 95   Equity to Liability                                      6819 non-null   float64\n",
      "dtypes: float64(93), int64(3)\n",
      "memory usage: 5.0 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "gender = pd.read_csv('gender+by+name.zip')\n",
    "bankrupts = pd.read_csv('taiwanese+bankruptcy+prediction.zip')\n",
    "cols = [\n",
    "    \"class\",\n",
    "    \"cap-shape\",\n",
    "    \"cap-surface\",\n",
    "    \"cap-color\",\n",
    "    \"bruises\",\n",
    "    \"odor\",\n",
    "    \"gill-attachment\",\n",
    "    \"gill-spacing\",\n",
    "    \"gill-size\",\n",
    "    \"gill-color\",\n",
    "    \"stalk-shape\",\n",
    "    \"stalk-root\",\n",
    "    \"stalk-surface-above-ring\",\n",
    "    \"stalk-surface-below-ring\",\n",
    "    \"stalk-color-above-ring\",\n",
    "    \"stalk-color-below-ring\",\n",
    "    \"veil-type\",\n",
    "    \"veil-color\",\n",
    "    \"ring-number\",\n",
    "    \"ring-type\",\n",
    "    \"spore-print-color\",\n",
    "    \"population\",\n",
    "    \"habitat\"\n",
    "]\n",
    "mushroom = pd.read_csv(\"mushroom/agaricus-lepiota.data\", header=None, names=cols)\n",
    "print(gender.info())\n",
    "print(mushroom.info())\n",
    "print(bankrupts.info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091c5cdc",
   "metadata": {},
   "source": [
    "# 2. Basic EDA\n",
    "## 2.1 Mushrooms dataset\n",
    "This is the only dataset that has missing values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c545a858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['class', 'cap-shape', 'cap-surface', 'cap-color', 'bruises', 'odor',\n",
       "       'gill-attachment', 'gill-spacing', 'gill-size', 'gill-color',\n",
       "       'stalk-shape', 'stalk-root', 'stalk-surface-above-ring',\n",
       "       'stalk-surface-below-ring', 'stalk-color-above-ring',\n",
       "       'stalk-color-below-ring', 'veil-type', 'veil-color', 'ring-number',\n",
       "       'ring-type', 'spore-print-color', 'population', 'habitat'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mushroom.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a73cc8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.3052683407188577)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = mushroom.copy()\n",
    "df[\"stalk-root\"].unique()\n",
    "missing_count = (df[\"stalk-root\"] == \"?\").sum()\n",
    "missing_count/len(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d8fb68",
   "metadata": {},
   "source": [
    "The stalk-root column has too many missing values, so Im dropping it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71db24ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['class', 'cap-shape', 'cap-surface', 'cap-color', 'bruises', 'odor',\n",
       "       'gill-attachment', 'gill-spacing', 'gill-size', 'gill-color',\n",
       "       'stalk-shape', 'stalk-surface-above-ring', 'stalk-surface-below-ring',\n",
       "       'stalk-color-above-ring', 'stalk-color-below-ring', 'veil-type',\n",
       "       'veil-color', 'ring-number', 'ring-type', 'spore-print-color',\n",
       "       'population', 'habitat'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mushroom = mushroom.drop(columns=[\"stalk-root\"])\n",
    "mushroom.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96e94838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>cap-shape</th>\n",
       "      <th>cap-surface</th>\n",
       "      <th>cap-color</th>\n",
       "      <th>bruises</th>\n",
       "      <th>odor</th>\n",
       "      <th>gill-attachment</th>\n",
       "      <th>gill-spacing</th>\n",
       "      <th>gill-size</th>\n",
       "      <th>gill-color</th>\n",
       "      <th>...</th>\n",
       "      <th>stalk-surface-below-ring</th>\n",
       "      <th>stalk-color-above-ring</th>\n",
       "      <th>stalk-color-below-ring</th>\n",
       "      <th>veil-type</th>\n",
       "      <th>veil-color</th>\n",
       "      <th>ring-number</th>\n",
       "      <th>ring-type</th>\n",
       "      <th>spore-print-color</th>\n",
       "      <th>population</th>\n",
       "      <th>habitat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>n</td>\n",
       "      <td>t</td>\n",
       "      <td>p</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>k</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>k</td>\n",
       "      <td>s</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>y</td>\n",
       "      <td>t</td>\n",
       "      <td>a</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>k</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e</td>\n",
       "      <td>b</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>t</td>\n",
       "      <td>l</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p</td>\n",
       "      <td>x</td>\n",
       "      <td>y</td>\n",
       "      <td>w</td>\n",
       "      <td>t</td>\n",
       "      <td>p</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>k</td>\n",
       "      <td>s</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>g</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>w</td>\n",
       "      <td>b</td>\n",
       "      <td>k</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>a</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  class cap-shape cap-surface cap-color bruises odor gill-attachment  \\\n",
       "0     p         x           s         n       t    p               f   \n",
       "1     e         x           s         y       t    a               f   \n",
       "2     e         b           s         w       t    l               f   \n",
       "3     p         x           y         w       t    p               f   \n",
       "4     e         x           s         g       f    n               f   \n",
       "\n",
       "  gill-spacing gill-size gill-color  ... stalk-surface-below-ring  \\\n",
       "0            c         n          k  ...                        s   \n",
       "1            c         b          k  ...                        s   \n",
       "2            c         b          n  ...                        s   \n",
       "3            c         n          n  ...                        s   \n",
       "4            w         b          k  ...                        s   \n",
       "\n",
       "  stalk-color-above-ring stalk-color-below-ring veil-type veil-color  \\\n",
       "0                      w                      w         p          w   \n",
       "1                      w                      w         p          w   \n",
       "2                      w                      w         p          w   \n",
       "3                      w                      w         p          w   \n",
       "4                      w                      w         p          w   \n",
       "\n",
       "  ring-number ring-type spore-print-color population habitat  \n",
       "0           o         p                 k          s       u  \n",
       "1           o         p                 n          n       g  \n",
       "2           o         p                 n          n       m  \n",
       "3           o         p                 k          s       u  \n",
       "4           o         e                 n          a       g  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mushroom.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b664d38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OrdinalEncoder()\n",
    "mushroom = pd.DataFrame(enc.fit_transform(mushroom), columns=mushroom.columns)\n",
    "mushroom = mushroom.rename(columns={\"class\":\"poisonous\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "913e18ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>poisonous</th>\n",
       "      <th>cap-shape</th>\n",
       "      <th>cap-surface</th>\n",
       "      <th>cap-color</th>\n",
       "      <th>bruises</th>\n",
       "      <th>odor</th>\n",
       "      <th>gill-attachment</th>\n",
       "      <th>gill-spacing</th>\n",
       "      <th>gill-size</th>\n",
       "      <th>gill-color</th>\n",
       "      <th>...</th>\n",
       "      <th>stalk-surface-below-ring</th>\n",
       "      <th>stalk-color-above-ring</th>\n",
       "      <th>stalk-color-below-ring</th>\n",
       "      <th>veil-type</th>\n",
       "      <th>veil-color</th>\n",
       "      <th>ring-number</th>\n",
       "      <th>ring-type</th>\n",
       "      <th>spore-print-color</th>\n",
       "      <th>population</th>\n",
       "      <th>habitat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8119</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8120</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8121</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8122</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8123</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8124 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      poisonous  cap-shape  cap-surface  cap-color  bruises  odor  \\\n",
       "0           1.0        5.0          2.0        4.0      1.0   6.0   \n",
       "1           0.0        5.0          2.0        9.0      1.0   0.0   \n",
       "2           0.0        0.0          2.0        8.0      1.0   3.0   \n",
       "3           1.0        5.0          3.0        8.0      1.0   6.0   \n",
       "4           0.0        5.0          2.0        3.0      0.0   5.0   \n",
       "...         ...        ...          ...        ...      ...   ...   \n",
       "8119        0.0        3.0          2.0        4.0      0.0   5.0   \n",
       "8120        0.0        5.0          2.0        4.0      0.0   5.0   \n",
       "8121        0.0        2.0          2.0        4.0      0.0   5.0   \n",
       "8122        1.0        3.0          3.0        4.0      0.0   8.0   \n",
       "8123        0.0        5.0          2.0        4.0      0.0   5.0   \n",
       "\n",
       "      gill-attachment  gill-spacing  gill-size  gill-color  ...  \\\n",
       "0                 1.0           0.0        1.0         4.0  ...   \n",
       "1                 1.0           0.0        0.0         4.0  ...   \n",
       "2                 1.0           0.0        0.0         5.0  ...   \n",
       "3                 1.0           0.0        1.0         5.0  ...   \n",
       "4                 1.0           1.0        0.0         4.0  ...   \n",
       "...               ...           ...        ...         ...  ...   \n",
       "8119              0.0           0.0        0.0        11.0  ...   \n",
       "8120              0.0           0.0        0.0        11.0  ...   \n",
       "8121              0.0           0.0        0.0         5.0  ...   \n",
       "8122              1.0           0.0        1.0         0.0  ...   \n",
       "8123              0.0           0.0        0.0        11.0  ...   \n",
       "\n",
       "      stalk-surface-below-ring  stalk-color-above-ring  \\\n",
       "0                          2.0                     7.0   \n",
       "1                          2.0                     7.0   \n",
       "2                          2.0                     7.0   \n",
       "3                          2.0                     7.0   \n",
       "4                          2.0                     7.0   \n",
       "...                        ...                     ...   \n",
       "8119                       2.0                     5.0   \n",
       "8120                       2.0                     5.0   \n",
       "8121                       2.0                     5.0   \n",
       "8122                       1.0                     7.0   \n",
       "8123                       2.0                     5.0   \n",
       "\n",
       "      stalk-color-below-ring  veil-type  veil-color  ring-number  ring-type  \\\n",
       "0                        7.0        0.0         2.0          1.0        4.0   \n",
       "1                        7.0        0.0         2.0          1.0        4.0   \n",
       "2                        7.0        0.0         2.0          1.0        4.0   \n",
       "3                        7.0        0.0         2.0          1.0        4.0   \n",
       "4                        7.0        0.0         2.0          1.0        0.0   \n",
       "...                      ...        ...         ...          ...        ...   \n",
       "8119                     5.0        0.0         1.0          1.0        4.0   \n",
       "8120                     5.0        0.0         0.0          1.0        4.0   \n",
       "8121                     5.0        0.0         1.0          1.0        4.0   \n",
       "8122                     7.0        0.0         2.0          1.0        0.0   \n",
       "8123                     5.0        0.0         1.0          1.0        4.0   \n",
       "\n",
       "      spore-print-color  population  habitat  \n",
       "0                   2.0         3.0      5.0  \n",
       "1                   3.0         2.0      1.0  \n",
       "2                   3.0         2.0      3.0  \n",
       "3                   2.0         3.0      5.0  \n",
       "4                   3.0         0.0      1.0  \n",
       "...                 ...         ...      ...  \n",
       "8119                0.0         1.0      2.0  \n",
       "8120                0.0         4.0      2.0  \n",
       "8121                0.0         1.0      2.0  \n",
       "8122                7.0         4.0      2.0  \n",
       "8123                4.0         1.0      2.0  \n",
       "\n",
       "[8124 rows x 22 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mushroom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "89f8fb11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8124 entries, 0 to 8123\n",
      "Data columns (total 22 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   poisonous                 8124 non-null   float64\n",
      " 1   cap-shape                 8124 non-null   float64\n",
      " 2   cap-surface               8124 non-null   float64\n",
      " 3   cap-color                 8124 non-null   float64\n",
      " 4   bruises                   8124 non-null   float64\n",
      " 5   odor                      8124 non-null   float64\n",
      " 6   gill-attachment           8124 non-null   float64\n",
      " 7   gill-spacing              8124 non-null   float64\n",
      " 8   gill-size                 8124 non-null   float64\n",
      " 9   gill-color                8124 non-null   float64\n",
      " 10  stalk-shape               8124 non-null   float64\n",
      " 11  stalk-surface-above-ring  8124 non-null   float64\n",
      " 12  stalk-surface-below-ring  8124 non-null   float64\n",
      " 13  stalk-color-above-ring    8124 non-null   float64\n",
      " 14  stalk-color-below-ring    8124 non-null   float64\n",
      " 15  veil-type                 8124 non-null   float64\n",
      " 16  veil-color                8124 non-null   float64\n",
      " 17  ring-number               8124 non-null   float64\n",
      " 18  ring-type                 8124 non-null   float64\n",
      " 19  spore-print-color         8124 non-null   float64\n",
      " 20  population                8124 non-null   float64\n",
      " 21  habitat                   8124 non-null   float64\n",
      "dtypes: float64(22)\n",
      "memory usage: 1.4 MB\n"
     ]
    }
   ],
   "source": [
    "mushroom.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ac2f612",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q9/dv0qd5v93jv_7gz3d0y5d0xc0000gn/T/ipykernel_3563/1349656660.py:3: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.countplot(data=mushroom, x=\"poisonous\", palette=\"Set2\")\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiUAAAGJCAYAAABVW0PjAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjYsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvq6yFwwAAAAlwSFlzAAAPYQAAD2EBqD+naQAASA9JREFUeJzt3Qm8TfX+//GPeZ5nGaPMQ1RylZIp1I9Lt6RQQslMyE0yVKRQMt0GQ10SRQOZpUFIImOSFN1wSobM0/4/3t/HY+3/3ts5nH2c4yzO6/l4LMda67vX/q49fvb3+/l+V6pAIBAwAACAZJY6uSsAAAAgBCUAAMAXCEoAAIAvEJQAAABfICgBAAC+QFACAAB8gaAEAAD4AkEJAADwBYISAADgCwQlQDydOXPG+vbta0WLFrXUqVNbs2bNkuy+Bg0aZKlSpQrbVqJECXv44YeD61OmTHFlvv3224se74477nBLSvTLL7+4x0mPF/xFz0uXLl2SuxrwEYISRGXHjh322GOP2bXXXmsZM2a07NmzW61atezVV1+148ePmx+MHz8+Sb6AJk2aZC+99JLde++9NnXqVOvZs2ecZRUA6AM3tqVs2bKJXrerTeTjlzt3brvpppvcc3Du3Lnkrt4Vzwt6FVzv3r37vP2HDx+2TJkyETTgskt7+e8SV6p58+bZv/71L8uQIYO1adPGKlasaKdOnbKvvvrK+vTpY5s3b7bXX3/dF0FJ3rx5w1oVEsOyZcvsmmuusdGjR8erfJEiRWzYsGHnbc+RI0eC7n/btm3uSySlCH38/vjjD3v77bft0UcftR9//NGGDx8e7+MUL17cBczp0qVLwtpemfRefvfdd10LYKjZs2cnW52QshGUIF527txpLVu2dB/w+nIuVKhQcF/nzp3tp59+ckHL1SwmJsZy5swZ7/IKPh566KFE/QJJSSIfP7XQlSlTxsaOHWtDhw6Nd5ChX/tq1cP5GjduHGtQMn36dGvSpIl98MEH5ldHjx61LFmyJHc1kMhSzs8uXJIRI0bYkSNH7K233goLSDylS5e27t27h+Vf6IujVKlS7stU+RD//ve/7eTJk+d9YagpOVJc+RMrVqywXr16Wb58+dwH0j//+U/3Kzr0dmqx+fzzz4NN/xfLpdCHW+/evV2uiOqqL76XX37ZvAtoezkJn332mTu2d9zly5dbYlBLk7om9MWpx+s///lPrOUiHxPPsWPH3Bd2njx5XHeaWrEOHDhw0fvVc/Hss8+6507nrfPXl1PkcxRJzflZs2Z19xvpgQcesIIFC9rZs2fduvJdGjZs6Fqu1B1QsmRJa9eunSVE5syZ7ZZbbnHPl/ec//zzz671Tt073v7I4Di2nJK9e/faI4884lpjdO56TTdt2tSVjWx1q1ChgitTuHBhF4AfPHgwrIxeX2o13LJli9WpU8fVQy1qes/EFtiqtadAgQLu+a5SpYrrCgyl11Vsr69LOY+4tGrVytavX28//PBD2DH1w0P7Innvw8jjx1bn7du3W4sWLdzrQeeqOuqHzaFDh8477ocffugeQ52DHu8FCxbE2t2kx1j1ypUrl916661RfdZE+3xu2LDBbr/9dvd86j3y/vvvu/36bKlRo4Z7PeuzYsmSJWG3//vvv61Hjx6uHrqf/PnzW/369e2777676PMBWkoQT5988onLI/nHP/4Rr/Lt27d3H7bKv9AX/urVq11T/NatW23OnDkJrkfXrl3dB5K+TPXB+Morr7gvyffee8/t17rK6Evz6aefdtv0BRAXBR7/93//5wIOfVlUrVrVFi5c6Lqj/ve//7muGgVA77zzjj3//PMuMPO6FMqVK3fBuuqL+c8//zxvuz7MvF94GzdutAYNGrj70AevPmB1bheqcySdv1pwdHt18UyYMMF+/fXX4BdFbJSXofNWQNSxY0d3LqqLzlfdI/qSiMv9999v48aNC3bneRSk6HWiwClNmjTuC9g7t6eeesrVUc/ZpXQNKAjRsXWsffv2udej7rdbt24uKNNrTuelLxAFrHHRl6UCTL1W9OWhui5evNh27drl1kWP5+DBg61evXrWqVOn4GO7Zs0aFxyHttQoCLzrrrusefPmdt9997n779evn1WqVMkaNWrkyqgLSV94alXUc6YAbdasWe7x0hdjaFAfX/E5jwupXbu2CxbUMjJkyBC3Te8lvX/UUpJQ6tZVMKrAQHVTYKL309y5c925hnZh6jWo18QTTzxh2bJlszFjxrjz0jnoOQ2l19t1111nL7zwQvBHQ3w/a6J9Pu+++24XROk+VU7/nzZtmgs4Hn/8cRcceTlmystR3UX79PzrOS5fvrzt37/fnaPqU61atQQ/pilGALiIQ4cO6d0faNq0abzKr1+/3pVv37592PYnn3zSbV+2bFlwm9afffbZ845RvHjxQNu2bYPrkydPdmXr1asXOHfuXHB7z549A2nSpAkcPHgwuK1ChQqB22+/PV51/fDDD91xn3vuubDt9957byBVqlSBn376KbhNx9Sx40NlddzYlsceeyxYrlmzZoGMGTMGfv311+C2LVu2uHOKfHvG9ZhUr149cOrUqeD2ESNGuO0fffRRWH1CH5N33nknkDp16sCXX34Zdh8TJ050t12xYkWc56bH/5prrgm0aNEibPvMmTPdbb/44gu3PmfOHLe+Zs2aQLRU17Jlywb++OMPt2zdujXQrVs3d7x77rnHlenRo4dbDz2Hv//+O1CyZMlAiRIlAmfPnnXbdu7c6crp8ZIDBw649ZdeeinO+4+JiQmkT58+0KBBg+BxZOzYse62kyZNCqurtr399tvBbSdPngwULFgw7DF65ZVXXLn//ve/wW163mrWrBnImjVr4PDhw27bZ5995srpb6iEnEdc9J7TbfXY6n1ZunTp4L6bbrop8Mgjj7j/q0znzp3Pe82pLqEi67xu3Tq3PmvWrAvWQ2X0OIe+z77//nu3/bXXXjuvvg888ECCPmsS8nxOnz49uO2HH35w2/SeWbVqVXD7woULw54TyZEjR9hjhujQfYOLUia+eL8ELubTTz91f9XNEkq/YuRSck/0qz701/9tt93mWiTUMpAQqqt+eeuXdmRd9Zk5f/78BNdVv1T1qzVy0S8tUb3VKqOhxcWKFQveTq0W+pUZzWMS+itPvwLTpk0bfB5io1/ouh+NBFJrjrfceeedbr9ajuKix1+/HnV8tRx59Atb3RZes7qXf6Nfx6dPn7ZoqUtBrSxaVNfXXnvN/XrXCBzR/d98883B+xP9wtfjoRYZNfXHRi1V6dOndy1JcXVzqUlev/b1XIUmF3fo0MF1kUW+hnW/ofkvOr7qppYdj+qrFgN1cXn0vOm1p8dR3QLRiM95xId+8av1Ri0G3t/Yum6i4bWE6PUdWzdfKLVcqOvFU7lyZfcYhz52HrVCJOSzJiHPp1pGPOqm0etZr0N13Xi8/4fWVeXUWvP7779f8LwRO4ISXJTetF5faXwoQNAbX/2wofSBrDdsQgMICf3yFnXlSEI/lFUX9S1HBlxe18yl1FVdNPrAjVy8IcHKi1CTvpqjI+lDML4ib68PVOUWXCivQP39avb3vvS95frrr3f71Q1wIerCUd0//vhjt64vVX1BKFjxgkb1x6sZXk3myilRrsPkyZMvmrMSGdTpC0XN38p1UICjY3nPTWyP08WeO/Xzv/jiiy7gVDeZujCU/6Hje7zbRh5fQYC6MSOPrS6QyK4yvTZDX5e6jZ6ryBFUCX2txec84uOGG25wr0l14ah7Qu9TLzhNKHVNKVB488033fOlIFtdfrHlk0S+p2N77EKPm5DPmsR4PhVoKe8qcpuE1lXPwaZNm1xZBabqNootwELsCEoQr6BEX9x6o0UjrnyG+PASJSOpVSM2Xv8y4kc5Jcp3iK0lR4v69y9ECaUKGmbOnOnWlUuiIEXBSujzr771lStXuv515RQoybV69ephLSwXC+rq1q3r5sJRwmBi0S9m5c4o90BJmM8884wLDtatW5eg4yXm6zKu901s74nEOg+1jKilS4GJnsO4hp5HU7eRI0e6ZFElneq1oRYhJZn+9ttvCX7s1DoUTb0SKq46xaeuyilSEKKWPX1uKu9E530pra4pCUEJ4kVJX5o4TV8wF6Nhw/rS06/xUEpMVJKb9of+IorMflcz6549exJc12g+oFQXNbNGtgJ5oxFC65rY1DKhD9nIx0mUhBdfkbfXF74evwslOqq5/K+//nJf+LG15sSnpUYfvholoe49faHp/hSsRNI2JQlrJI5+iauFZsaMGXap9NzE9jjF97nTY6Bm/kWLFrmAW687fZGG3jby+Cqj4fEJeV3oNnquIid/i6yv1/oX+b6IqyXlQucRTVCi14wCnAt13URbNwW+AwYMsC+++MK+/PJLF5hOnDjREkt8P2uS4vm8ELVUKrBXwriOr4RdvQdwcQQliBcNFdUvV2W66w0fSQGLZnX15j7wRsKEGjVqlPsbmtWvD1R9YIXSBGxxtZTEh+oZ+aEZF9VV96W5L0JpFIqCG2/kRFLQry41a+uDSyMNPMrSV198fOnxCs3Z0EgBjeK5UN0VUOgL4o033jhvn37VatjtxegXtbpiNPJBwYmOGUpN2pG/djW6SeLbhXOx5+6bb74JC5RVbz0eCpA08iE2ynE4ceJE2Da9DtWF59VLgZma9jUSJPQcNCReXRAJGZmi+qprxRspJnqe9ItaXW7q7hJ9Qeq1Efm+0HDWaM8jvnQ7vV/V4qIuhwuVk9C66f0TOWmiAlWdW2SAohaYxHjuPfH9rEmK5zM2eiwiu6jUwqcWk8Q876sZQ4IRL/ow8pp21TwcOqPr119/HRzaKJp7oW3btu6DSsGBPmz15aEvLyV1ai4Hj4IcJa8p90Bj+b///nv3hezlDSSEugf0xfzcc8+5vmZ9KMTVR37PPfe4+mj4sHIwVHf94vzoo49c03hoAl609OH03//+N9Z9XlKk8i30ha6EXf2y8r6k1Nyrpu/40HOgFg8FBfolqC8vJX9qaGxcWrdu7bpe9NgrqVXdI/pA1a92bddzcOONN17wfjW8UY+vHjt94IZ23Yieb9VFQ3P1OKo1SkGQugO9L5NLoWHGmvhLwZe6BjRXie5Tv0w16VdcXRBqDfAeLwUuSgrW0FEF215yo1qx+vfv754fDfXVY+k9tppTJiGT4ikBV3PQ6H2ydu1aFzipe0vDUfWl6uU1KU9BuTl6HSgw1mOnXJrIPJ/4nEc04jMkWa9LtXzpsVFLmx5ztXpFBiCa50RddjoP5Slpv4bVK9jSez2xxPezJimez9joNa58FA0TVt0UbConSsnD0bZepVhRjtZBCvfjjz8GOnTo4IZcaohdtmzZArVq1XLD906cOBEsd/r06cDgwYPd8Mx06dIFihYtGujfv39YGdHwvH79+gXy5s0byJw5c6Bhw4ZueGBcw18jh5fGNnxy7969gSZNmri6ad/FhgdrGKmGFhcuXNjV9brrrnPDLEOHHifmkODIt93nn3/uhvXq8bz22mvdsFxvCGSouB4T3b5jx46BXLlyuaGlDz74YGD//v3n1SfycdBw1BdffNGdU4YMGdztVQ89bxoGHh9PP/20q0PokFLPd99954ZwFitWzB0/f/78gbvvvjvw7bffxuvxi89jvWPHDjd8O2fOnG5o9c033xyYO3fuBYfS/vnnn27IpoYcZ8mSxQ3hrFGjhhvSHElDRlVOr4sCBQoEOnXq5Ibixqeueq70nIXat2+fG26r17ue70qVKoUNJ/VoqK6GE+s9oedFw8g3bdqU4PO40JDgC4kcEuw95hqar+dUj8m///3vwOLFi8Pehz///HOgXbt2gVKlSrnnJXfu3IE6deoElixZctHjx/Zav1B94/tZc6nPp+qkz5ULPUYaCt6nT59AlSpV3OePnhf9f/z48bE+vjhfKv2T3IERAAAAOSUAAMAXCEoAAIAvEJQAAABfICgBAAC+QFACAAB8gaAEAAD4ApOnxYOmMdZU5JrcKLGvsQAAwNUsEAi4ieU0s21ckxp6CEriQQFJ5NUhAQBA/O3evdvNeHshBCXx4E3/rAdUU2QDAID40bWQ9MPe+y69EIKSePC6bBSQEJQAABC9+KQ/kOgKAAB8gaAEAAD4AkEJAADwBYISAADgCwQlAADAFwhKAACALxCUAAAAXyAoAQAAvkBQAgAAfIGgBAAA+AJBCQAA8AWufeMTvee/ndxVAJLcyEZtkrsKAHyMlhIAAOALBCUAAMAXCEoAAIAvEJQAAABfICgBAAC+QFACAAB8gaAEAAD4AkEJAADwBYISAADgCwQlAADAF3wTlAwfPtxSpUplPXr0CG47ceKEde7c2fLkyWNZs2a1Fi1a2L59+8Jut2vXLmvSpIllzpzZ8ufPb3369LEzZ86ElVm+fLlVq1bNMmTIYKVLl7YpU6ZctvMCAABXUFCyZs0a+89//mOVK1cO296zZ0/75JNPbNasWfb555/b77//bs2bNw/uP3v2rAtITp06ZV9//bVNnTrVBRwDBw4Mltm5c6crU6dOHVu/fr0Letq3b28LFy68rOcIAAB8HpQcOXLEHnzwQXvjjTcsV65cwe2HDh2yt956y0aNGmV33nmnVa9e3SZPnuyCj1WrVrkyixYtsi1btth///tfq1q1qjVq1MiGDh1q48aNc4GKTJw40UqWLGkjR460cuXKWZcuXezee++10aNHJ9s5AwAAHwYl6p5RS0a9evXCtq9du9ZOnz4dtr1s2bJWrFgxW7lypVvX30qVKlmBAgWCZRo2bGiHDx+2zZs3B8tEHltlvGPE5uTJk+4YoQsAAEhaaS0ZzZgxw7777jvXfRNp7969lj59esuZM2fYdgUg2ueVCQ1IvP3evguVUaBx/Phxy5Qp03n3PWzYMBs8eHAinCEAAPB9S8nu3bute/fuNm3aNMuYMaP5Sf/+/V33kbeorgAA4CoNStQ9ExMT40bFpE2b1i1KZh0zZoz7v1ozlBdy8ODBsNtp9E3BggXd//U3cjSOt36xMtmzZ4+1lUQ0Skf7QxcAAHCVBiV169a1jRs3uhEx3nLjjTe6pFfv/+nSpbOlS5cGb7Nt2zY3BLhmzZpuXX91DAU3nsWLF7sgonz58sEyocfwynjHAAAAKTynJFu2bFaxYsWwbVmyZHFzknjbH330UevVq5flzp3bBRpdu3Z1wcQtt9zi9jdo0MAFH61bt7YRI0a4/JEBAwa45Fm1dsjjjz9uY8eOtb59+1q7du1s2bJlNnPmTJs3b14ynDUAAPBlouvFaNhu6tSp3aRpGhGjUTPjx48P7k+TJo3NnTvXOnXq5IIVBTVt27a1IUOGBMtoOLACEM158uqrr1qRIkXszTffdMcCAAD+kSoQCASSuxJ+p5E6OXLkcEmvSZVf0nv+20lyXMBPRjZqY1eimAl9k7sKQJLL32lEsn+HJvs8JQAAAEJQAgAAfIGgBAAA+AJBCQAA8AWCEgAA4AsEJQAAwBcISgAAgC8QlAAAAF8gKAEAAL5AUAIAAHyBoAQAAPgCQQkAAPAFghIAAOALBCUAAMAXCEoAAIAvEJQAAABfICgBAAC+QFACAAB8gaAEAAD4AkEJAADwBYISAADgCwQlAADAFwhKAACALxCUAAAAX0jWoGTChAlWuXJly549u1tq1qxp8+fPD+6/4447LFWqVGHL448/HnaMXbt2WZMmTSxz5syWP39+69Onj505cyaszPLly61atWqWIUMGK126tE2ZMuWynSMAAIiftJaMihQpYsOHD7frrrvOAoGATZ061Zo2bWrr1q2zChUquDIdOnSwIUOGBG+j4MNz9uxZF5AULFjQvv76a9uzZ4+1adPG0qVLZy+88IIrs3PnTldGwcy0adNs6dKl1r59eytUqJA1bNgwGc4aAAD4Lii55557wtaff/5513qyatWqYFCiIERBR2wWLVpkW7ZssSVLlliBAgWsatWqNnToUOvXr58NGjTI0qdPbxMnTrSSJUvayJEj3W3KlStnX331lY0ePZqgBAAAH/FNTolaPWbMmGFHjx513TgetW7kzZvXKlasaP3797djx44F961cudIqVarkAhKPAo3Dhw/b5s2bg2Xq1asXdl8qo+1xOXnypDtG6AIAAK7ilhLZuHGjC0JOnDhhWbNmtTlz5lj58uXdvlatWlnx4sWtcOHCtmHDBtcCsm3bNps9e7bbv3fv3rCARLx17btQGQUax48ft0yZMp1Xp2HDhtngwYOT7JwBAIAPg5IyZcrY+vXr7dChQ/b+++9b27Zt7fPPP3eBSceOHYPl1CKiPJC6devajh07rFSpUklWJ7XI9OrVK7iuAKZo0aJJdn8AAMAH3TfK+9CImOrVq7sWiipVqtirr74aa9kaNWq4vz/99JP7q1yTffv2hZXx1r08lLjKaLRPbK0kolE63oggbwEAAFd5UBLp3LlzLqcjNmpREbWYiLp91P0TExMTLLN48WIXRHhdQCqjETehVCY0bwUAAKTw7ht1kzRq1MiKFStmf//9t02fPt3NKbJw4ULXRaP1xo0bW548eVxOSc+ePa127dpubhNp0KCBCz5at25tI0aMcPkjAwYMsM6dO7vWDtFQ4LFjx1rfvn2tXbt2tmzZMps5c6bNmzcvOU8dAAD4KShRC4fmFdH8Ijly5HDBhgKS+vXr2+7du91Q31deecWNyFFOR4sWLVzQ4UmTJo3NnTvXOnXq5Fo+smTJ4nJSQuc10XBgBSAKaNQtpLlR3nzzTYYDAwDgM8kalLz11ltx7lMQooTXi9HonE8//fSCZTQzrCZkAwAA/uW7nBIAAJAyEZQAAABfICgBAAC+QFACAAB8gaAEAABcPUHJwYMHE+MwAAAgBYs6KHnxxRftvffeC67fd999bnKza665xr7//vvErh8AAEghog5KJk6cGLw4naZr1zJ//nw3M2ufPn2Soo4AACAFiHryNE3l7gUlmk1VLSWa7r1EiRLBC+YBAAAkeUtJrly53BTwsmDBAqtXr577fyAQsLNnz0ZdAQAAgAS1lDRv3txatWpl1113ne3fv99124imcS9dujSPKgAAuDxByejRo11XjVpLdGXerFmzuu26qN4TTzyRsFoAAIAUL+qgJF26dPbkk0+et11X4QUAALisVwn+/fff7auvvrKYmBg7d+5c2L5u3boluDIAACDlijoomTJlij322GOWPn16Nz9JqlSpgvv0f4ISAABwWYKSZ555xgYOHGj9+/e31KmZpR4AACSOqKOKY8eOWcuWLQlIAABAooo6snj00Udt1qxZiVsLAACQ4kXdfTNs2DC7++673cRplSpVcqNxQo0aNSox6wcAAFKIBAUlCxcutDJlyrj1yERXAACAyxKUjBw50iZNmmQPP/xwgu4QAAAgUXJKMmTIYLVq1Yr2ZgAAAIkblHTv3t1ee+21aG8GAACQuN0333zzjS1btszmzp1rFSpUOC/Rdfbs2dEeEgAAIPqWkpw5c7orBd9+++2WN29ey5EjR9gSjQkTJljlypUte/bsbqlZs6bNnz8/uP/EiRPWuXNnN3OsLvzXokUL27dvX9gxdu3aZU2aNLHMmTNb/vz5rU+fPnbmzJmwMsuXL7dq1aq5riddyViz0gIAgCu8pWTy5MmJdudFihSx4cOH23XXXWeBQMCmTp1qTZs2tXXr1rlWGF3kb968eW5eFAU8Xbp0cQHRihUr3O3Pnj3rApKCBQva119/7a5U3KZNG9d688ILL7gyO3fudGUef/xxmzZtmi1dutTat29vhQoVsoYNGybauQAAgEuTKqBoIAH++OMP27Ztm/u/hgfny5fPEkPu3LntpZdesnvvvdcdc/r06e7/8sMPP1i5cuVs5cqVdsstt7hWFc2ZogsEFihQwJWZOHGi9evXz9VP1+fR/xXYbNq0KXgfmpH24MGDbq6V+Dh8+LALig4dOuRadJJC7/lvJ8lxAT8Z2aiNXYliJvRN7ioASS5/pxFJctxovkOj7r45evSotWvXzrU01K5d2y2FCxd2M71qCvqEUqvHjBkz3PHVjbN27Vo7ffq01atXL1imbNmyVqxYMReUiP5qAjcvIBG1fugB2Lx5c7BM6DG8Mt4xYnPy5El3jNAFAAAkraiDkl69etnnn39un3zyiWtt0PLRRx+5bb179466Ahs3bnT5Isr3UBfLnDlzrHz58rZ3717X0qEcllAKQLRP9Dc0IPH2e/suVEaBxvHjx+OcIC40T6Zo0aJRnxcAAEjioOSDDz6wt956yxo1ahRMUG3cuLG98cYb9v7770d7ONf1s379elu9erV16tTJ2rZta1u2bLHkpCsgq5nJW3bv3p2s9QEAICWIOtFVXTSRLQ+ikS8J6b5Ra4hGxEj16tVtzZo19uqrr9r9999vp06dci0xoa0lGn2jxFbRXw1RDuWNzgktEzliR+sKpjJlyhRrndRqowUAAPi4pUT5Hs8++6wbrutRN8jgwYPdvkt17tw5l9OhAEWjaDRaxqPEWg0B9u5Hf9X9ExMTEyyzePFiF3CoC8grE3oMr0xi1BUAACRjS4laMZQoquG8VapUcdu+//57y5gxo7tQX7TdJOoGUvLq33//7UbaaE4RHUe5HEqeVQ6LRuQo0OjatasLJjTyRho0aOCCj9atW9uIESNc/siAAQPc3CZeS4fyVMaOHWt9+/Z1Cbqa+G3mzJluRA4AALiCg5KKFSva9u3b3ZwfGqIrDzzwgD344INxdofERS0cmldE84soCNFEagpI6tev7/aPHj3aUqdO7SZNU+uJgqHx48cHb58mTRo3s6xyURSsZMmSxeWkDBkyJFimZMmSLgDRnCcKqBRMvfnmm8xRAgDA1TJPSUrCPCVA4mCeEsC/8vtgnpKoW0pkx44d9sorr9jWrVvdumZf7datm5UqVSphNQYAACle1Imu6l5RHodGvai7RcuqVatcYKIEUgAAgISIuqXkqaeecvkZumZN5HZN6e7lgwAAACRpS4m6bDQqJpJGtiT3pGcAACAFBSW6SJ5mYI2kbZpADQAA4LJ033To0ME6duxoP//8s/3jH/9w21asWGEvvviim1MEAADgsgQlzzzzjGXLls1GjhzpJj8TXSV40KBBbgQOAABAkgclZ86ccbOutmrVyiW7ahZWUZACAABw2XJK0qZN66Zt9657o2CEgAQAACRLouvNN99s69atS5Q7BwAASHBOyRNPPGG9e/e23377zV3JV9ebCaXJ1AAAAJI8KGnZsqX7G5rUmipVKtMldPT37NmzUVcCAAAg6qBk586dSVMTAACQokUdlBQvXjxpagIAAFK0BF0lePv27fbZZ59ZTEyMnTt3LmzfwIEDE6tuAAAgBYk6KHnjjTesU6dOljdvXitYsKDLI/Ho/wQlAADgsgQlzz33nD3//PPuisAAAADJNk/JgQMH7F//+leiVQAAACBBQYkCkkWLFvHoAQCAy999M2bMmOD/S5cu7S7Kt2rVKqtUqZKlS5curCwX5QMAAEkWlIwePTpsPWvWrPb555+7JZQSXQlKAABAkgUlTJgGAAB8l1MSSdPKr1+/3iXAAgAAXLagpEePHvbWW28FA5LatWtbtWrVrGjRorZ8+fIEVwQAAKRsUQcl77//vlWpUsX9/5NPPrFffvnFfvjhB+vZs6c9/fTTUR1r2LBhdtNNN1m2bNksf/781qxZM9u2bVtYmTvuuMPlqoQujz/+eFiZXbt2WZMmTSxz5szuOH369LEzZ86ElVHApOApQ4YMLll3ypQp0Z46AADwU1Dy559/uplc5dNPP3VDhK+//npr166dbdy4MapjKVG2c+fObiTP4sWL7fTp09agQQM7evRoWLkOHTrYnj17gsuIESOC+9Rao4Dk1KlT9vXXX9vUqVNdwBE6s6xyYlSmTp06rqtJrT3t27e3hQsXRnv6AADALzO6FihQwLZs2WKFChWyBQsW2IQJE9z2Y8eOWZo0aaI6lm4fSsGEWjrWrl3ruoU8agHxAqFImjNF9VmyZImrW9WqVW3o0KFuxtlBgwZZ+vTpbeLEiVayZEkbOXKku025cuXsq6++cqOKGjZseN4xT5486RbP4cOHozovAABwGVpKHnnkEbvvvvusYsWKriulXr16bvvq1autbNmydikOHTrk/ubOnTts+7Rp09y1dnSf/fv3dwGQZ+XKlW6+FAUkHgUaCiQ2b94cLOPVM7SMtsfVrZQjR47gonwZAADgs5YStT4oONi9e7frulGOhqiV5KmnnkpwRXS1YXWr1KpVyx3f06pVKytevLgVLlzYNmzY4FpAlHcye/Zst3/v3r1hAYl469p3oTIKXI4fP26ZMmUK26fAp1evXsF1lSMwAQDAZ0GJ3Hvvvedta9u27SVVRLklmzZtct0qoTp27Bj8v1pE1G1Ut25d27Fjh5UqVcqSggItL9gCAAA+DUqGDBlywf2hCabx1aVLF5s7d6598cUXVqRIkQuWrVGjhvv7008/uaBEuSbffPNNWJl9+/a5v14eiv5620LLZM+e/bxWEgAAcIUEJXPmzAlb14gZjW5JmzatCxKiCUoCgYB17drVHVNDdpWMejEaPSNqMZGaNWva888/bzExMS5JVjSSRwFH+fLlg2U0UiiUymg7AAC4QoOSdevWnbdNORcPP/yw/fOf/4y6y2b69On20UcfublKvBwQJZeqBUNdNNrfuHFjy5Mnj8sp0XwoGplTuXJlV1ZDiBV8tG7d2g0V1jEGDBjgju11wWhek7Fjx1rfvn3d0OVly5bZzJkzbd68edGePgAA8Os086JWicGDB7urB0dDw4k14kYTpKnlw1vee+89t1/DeTXUV4GHRvb07t3bWrRo4SZt8yjBVl0/+quWj4ceesjatGkT1s2kFhgFIGod0cRvGhr85ptvxjocGAAAXEGJrrFRcOEN6Y2m++ZCNOIl8krEsdHonMjumUgKfGJr5QEAAFdoUDJmzJjzAgvNsvrOO+9Yo0aNErNuAAAgBYk6KNEsqKFSp05t+fLlc0OCNb8HAADAZQlKNNIGAADAl4muAAAAl62lRENp42PSpEmXUh8AAJBCxTso0RV8NcrlhhtuuOioGQAAgCQLSjp16mTvvvuuyynRlYI1H0jk1XwBAACSPKdk3LhxbuivZkXV5GWaQ+S+++6zhQsX0nICAAAub6Krpm1/4IEH3MyoW7ZssQoVKtgTTzxhJUqUsCNHjlx6bQAAQIqV4NE3mp8kVapUrpXk7NmziVsrAACQ4kQVlJw8edLlldSvX9+uv/5627hxo7vQ3a5duyxr1qxJV0sAAHDVi3eiq7ppZsyY4XJJNDxYwUnevHmTtnYAACDFiHdQMnHiRCtWrJhde+217iJ5cV0ob/bs2YlZPwAAkELEOyhp06aNyyEBAABI9snTAAAAkgrXvgEAAL5AUAIAAHyBoAQAAPgCQQkAALhygpJq1arZgQMH3P+HDBlix44dS+p6AQCAFCZeQcnWrVvt6NGj7v+DBw/mOjcAACB5hgRXrVrVHnnkEbv11lvdtW5efvnlOKeVHzhwYGLXEQAApABp4ztHybPPPmtz5851E6jNnz/f0qY9/6baR1ACAACSrPumTJky7ro3a9ascS0lS5cutXXr1p23fPfdd1Hd+bBhw+ymm26ybNmyWf78+a1Zs2a2bdu2sDInTpywzp07W548eVzrTIsWLWzfvn1hZXRBwCZNmljmzJndcfr06WNnzpwJK7N8+XKXG5MhQwYrXbo0k8EBAHClj745d+6c++JPDLp+jgKOVatW2eLFi+306dPWoEGDYP6K9OzZ0z755BObNWuWK//7779b8+bNg/vPnj3rApJTp07Z119/bVOnTnUBR2iLzc6dO12ZOnXq2Pr1661Hjx7Wvn17W7hwYaKcBwAAuHSpAmr6iNKOHTvslVdecQmwUr58eevevbuVKlXqkirzxx9/uIBHwUft2rXt0KFDli9fPps+fbrde++9rswPP/xg5cqVs5UrV9ott9ziupLuvvtuF6wUKFAgePHAfv36ueOlT5/e/X/evHm2adOm4H21bNnSDh48aAsWLLhovQ4fPmw5cuRw9cmePbslhd7z306S4wJ+MrJRG7sSxUzom9xVAJJc/k4jkuS40XyHRt1SotYFBSHffPONVa5c2S2rV6+2ChUquNaOS6EKS+7cud3ftWvXutaTevXqBcuULVvWXa1YQYnob6VKlYIBiTRs2NA9CJs3bw6WCT2GV8Y7RqSTJ0+624cuAADAJxfk8zz11FOuS2X48OHnbVeLRP369RNUEXULqVulVq1aVrFiRbdt7969rqUjZ86cYWUVgGifVyY0IPH2e/suVEbBxvHjxy1Tpkzn5bpo6DMAALh8om4pUZfNo48+et72du3a2ZYtWxJcEeWWqHtFCbXJrX///q7Vxlt2796d3FUCAOCqF3VQohwPJYtG0raEJsB26dLFDTf+7LPPrEiRIsHtBQsWdAmsyv0IpdE32ueViRyN461frIz6tiJbSUQjdLQvdAEAAD4LSjp06GAdO3a0F1980b788ku3qCvnsccec/uioRxbBSRz5syxZcuWWcmSJcP2V69e3dKlS+eGIHs0ZFhDgGvWrOnW9Xfjxo0WExMTLKPcFgUSyn3xyoQewyvjHQMAAFyBOSXPPPOMm1dk5MiRrptDChcubIMGDbJu3bpF3WWjkTUfffSRO6aXA6IsXbVg6K+6inr16uWSXxVodO3a1QUTGnkjGkKs4KN169Y2YsQId4wBAwa4Y6vFQx5//HEbO3as9e3b13UzKQCaOXOmG5EDAACu0KBEs7Yq0VXL33//7bYpoEiICRMmuL933HFH2PbJkyfbww8/7P4/evRoS506tZs0TaNiNGpm/PjxwbJp0qRxXT+dOnVywUqWLFmsbdu27sKBHrXAKABRnV999VXXRfTmm2+6YwEAgCs0KAmV0GDEE58pUjJmzGjjxo1zS1yKFy9un3766QWPo8BHs84CAICrJKcEAAAgKRCUAAAAXyAoAQAAV15Qoinf69ata9u3b0+6GgEAgBQpqqBEc4Zs2LAh6WoDAABSrKi7bx566CF76623kqY2AAAgxYp6SPCZM2ds0qRJtmTJEjfjquYFCTVq1KjErB8AAEghog5KdNG8atWquf//+OOP502sBgAAcFmCEl00DwAAwDdDgn/66SdbuHChHT9+PN6zswIAACRaULJ//343LPj666+3xo0b2549e9x2XTivd+/e0R4OAAAgYUGJLmqnocG7du2yzJkzB7fff//9tmDBgmgPBwAAkLCckkWLFrluG11pN9R1111nv/76a7SHAwAASFhLydGjR8NaSDx//fWXZciQIdrDAQAAJCwoue222+ztt98OGwZ87tw5GzFihNWpUyfawwEAACSs+0bBhxJdv/32Wzt16pT17dvXNm/e7FpKVqxYEe3hAAAAEtZSUrFiRTdp2q233mpNmzZ13TnNmze3devWWalSpaI9HAAAQMJaSiRHjhz29NNPJ+SmAAAAiReUHDhwwF2Ub+vWrW69fPny9sgjj1ju3LkTcjgAAIDou2+++OILK1GihI0ZM8YFJ1r0/5IlS7p9AAAAl6WlpHPnzm6itAkTJliaNGnctrNnz9oTTzzh9m3cuDFBFQEAAClb6oRc80bTyXsBiej/vXr1cvsAAAAuS1BSrVq1YC5JKG2rUqVKgioBAAAQr+6bDRs2BP/frVs36969u2sVueWWW9y2VatW2bhx42z48OFJV1MAAHBVi1dLSdWqVe2GG25wfx944AHbvXu3mzStdu3abtH/dd2bVq1aRXXnSoy95557rHDhwm5m2A8//DBs/8MPP+y2hy533XVXWBlN2vbggw9a9uzZLWfOnO5qxUeOHDkvqNJMtBkzZrSiRYu6CeAAAMAV2FKyc+fOJLlzTbymLp927dq5CdhioyBk8uTJwfXI6+soINmzZ48tXrzYTp8+7YYmd+zY0aZPn+72Hz582Bo0aGD16tWziRMnukRc3Z8CGJUDAABXUFBSvHjxJLnzRo0aueVCFIQULFgw1n3KY1mwYIGtWbPGbrzxRrfttddes8aNG9vLL7/sWmCmTZvmpsOfNGmSpU+f3ipUqGDr16+3UaNGEZQAAHClT572+++/21dffWUxMTHuYnyhlHOSmJYvX2758+e3XLly2Z133mnPPfec5cmTx+1buXKla/HwAhJRi0jq1Klt9erV9s9//tOVUReTAhJPw4YN7cUXX3RzrOi4kU6ePOkWj1pbAACAz4KSKVOm2GOPPea+5BUcKM/Do/8nZlCirht162hith07dti///1v17KiQEPDkPfu3esCllBp06Z1M8tqn+ivbh+qQIECwX2xBSXDhg2zwYMHJ9p5AACAJAhKnnnmGRs4cKD179/ftUgkpZYtWwb/X6lSJatcubK76J9aT3Sl4qSic9O8K6EtJUqQBQAASSfqqOLYsWMuWEjqgCQ21157reXNmzc4SZtyTdSFFOrMmTNuRI6Xh6K/+/btCyvjrceVq6I8Fo3mCV0AAEDSijqy0JDbWbNmWXL47bffbP/+/VaoUCG3XrNmTTt48KCtXbs2WGbZsmUuz6VGjRrBMhp6rJE5Ho3UKVOmTKxdNwAA4ArpvlG+xd133+1GvahLJV26dGH7NaolvjSfSOjU9Bp6rJExygnRoryOFi1auBYN5ZRoPpTSpUu7RFUpV66cyzvp0KGDG+6rwKNLly6uJUcjb0Rzp+g4Cqb69etnmzZtsldffdVGjx4d7akDAAC/BSULFy50LQ0SmegajW+//dbq1KkTXPfyONq2besu+KdJz6ZOnepaQxRkaL6RoUOHhs1VoiG/CkSUY6IuJQUxumqxJ0eOHLZo0SJ3scDq1au77h/lxDAcGACAKzwoGTlypJvzQ7OtXqo77rjDAoFAnPsV/FyMWlS8idLiogTZL7/8MkF1BAAAPs0pUStFrVq1kqY2AAAgxYo6KNHF+DRrKgAAQLJ233zzzTduhMvcuXPdlO2Ria6zZ89OzPoBAIAUIuqgRNO6x3XxPAAAgMsWlIResRcAACCxXP5pWQEAABKjpUQXt7vQfCQ///xztIcEAACIPijp0aNH2LpmUV23bp2b4bVPnz6JWTcAAJCCpE3IkODYjBs3zs3QCgAAkKw5JY0aNbIPPvggsQ4HAABSmEQLSt5//3035TsAAMBl6b654YYbwhJdde2avXv32h9//GHjx49PUCUAAACiDkqaNWsWtq4r8+bLl89dXK9s2bKJWTcAAJCCRB2UPPvss0lTEwAAkKIxeRoAALiyWkrUTXOhSdNE+8+cOZMY9QIAAClMvIOSOXPmxLlv5cqVNmbMGDt37lxi1QsAAKQw8Q5KmjZtet62bdu22VNPPWWffPKJPfjggzZkyJDErh8AAEghEpRT8vvvv1uHDh2sUqVKrrtm/fr1NnXqVCtevHji1xAAAKQIUQUlhw4dsn79+lnp0qVt8+bNtnTpUtdKUrFixaSrIQAASBHi3X0zYsQIe/HFF61gwYL27rvvxtqdAwAAkORBiXJHMmXK5FpJ1FWjJTazZ89OcGUAAEDKFe+gpE2bNhcdEgwAAJDkQcmUKVMSfCcAAAC+ntH1iy++sHvuuccKFy7sWmE+/PDDsP262N/AgQOtUKFCruuoXr16tn379rAyf/31lxuOnD17dsuZM6c9+uijduTIkbAyGzZssNtuu80yZsxoRYsWdfkxAADAX5I1KDl69KhVqVLFxo0bF+t+BQ+alG3ixIm2evVqy5IlizVs2NBOnDgRLKOARCOBFi9ebHPnznWBTseOHYP7Dx8+bA0aNHDDldeuXWsvvfSSDRo0yF5//fXLco4AACCJLsiXmBo1auSW2KiV5JVXXrEBAwYER/q8/fbbVqBAAdei0rJlS9u6dastWLDA1qxZYzfeeKMr89prr1njxo3t5Zdfdi0w06ZNs1OnTtmkSZMsffr0VqFCBTevyqhRo8KCFwAAkLx8e0G+nTt32t69e12XjSdHjhxWo0YNN6296K+6bLyARFRe1+lRy4pXpnbt2i4g8ai1RbPRHjhwINb7PnnypGthCV0AAEAKDUoUkIhaRkJp3dunv/nz5w/bnzZtWsudO3dYmdiOEXofkYYNG+YCIG9RHgoAAEihQUly6t+/v5u91lt2796d3FUCAOCq59ugRDPHyr59+8K2a93bp78xMTFh+3UtHo3ICS0T2zFC7yNShgwZ3Gie0AUAAKTQoKRkyZIuaND1dTzK7VCuSM2aNd26/h48eNCNqvEsW7bMzp0753JPvDIakXP69OlgGY3UKVOmjOXKleuynhMAAPBpUKL5RDQSRouX3Kr/79q1y81b0qNHD3vuuefs448/to0bN7pZZTWiplmzZq58uXLl7K677nJXLP7mm29sxYoV1qVLFzcyR+WkVatWLslV85do6PB7771nr776qvXq1Ss5Tx0AAPhpSPC3335rderUCa57gULbtm3dDLJ9+/Z1c5lo6K5aRG699VY3BFiToHk05FeBSN26dd2omxYtWri5TTxKVF20aJF17tzZqlevbnnz5nUTsjEcGAAAf0kV0IQguCB1Gym4UdJrUuWX9J7/dpIcF/CTkY3a2JUoZkLf5K4CkOTydxqR7N+hvs0pAQAAKQtBCQAA8AWCEgAA4AsEJQAAwBcISgAAgC8QlAAAAF8gKAEAAL5AUAIAAHyBoAQAAPgCQQkAAPAFghIAAOALBCUAAMAXCEoAAIAvEJQAAABfICgBAAC+QFACAAB8gaAEAAD4AkEJAADwBYISAADgCwQlAADAFwhKAACALxCUAAAAXyAoAQAAvkBQAgAAfMHXQcmgQYMsVapUYUvZsmWD+0+cOGGdO3e2PHnyWNasWa1Fixa2b9++sGPs2rXLmjRpYpkzZ7b8+fNbnz597MyZM8lwNgAA4ELSms9VqFDBlixZElxPm/b/V7lnz542b948mzVrluXIkcO6dOlizZs3txUrVrj9Z8+edQFJwYIF7euvv7Y9e/ZYmzZtLF26dPbCCy8ky/kAAIArNChREKKgItKhQ4fsrbfesunTp9udd97ptk2ePNnKlStnq1atsltuucUWLVpkW7ZscUFNgQIFrGrVqjZ06FDr16+fa4VJnz59MpwRAAC44rpvZPv27Va4cGG79tpr7cEHH3TdMbJ27Vo7ffq01atXL1hWXTvFihWzlStXunX9rVSpkgtIPA0bNrTDhw/b5s2b47zPkydPujKhCwAASMFBSY0aNWzKlCm2YMECmzBhgu3cudNuu+02+/vvv23v3r2upSNnzpxht1EAon2iv6EBibff2xeXYcOGue4gbylatGiSnB8AALhCum8aNWoU/H/lypVdkFK8eHGbOXOmZcqUKcnut3///tarV6/gulpKCEwAAEjBLSWR1Cpy/fXX208//eTyTE6dOmUHDx4MK6PRN14Oiv5Gjsbx1mPLU/FkyJDBsmfPHrYAAICkdUUFJUeOHLEdO3ZYoUKFrHr16m4UzdKlS4P7t23b5nJOatas6db1d+PGjRYTExMss3jxYhdklC9fPlnOAQAAXIHdN08++aTdc889rsvm999/t2effdbSpEljDzzwgMv1ePTRR103S+7cuV2g0bVrVxeIaOSNNGjQwAUfrVu3thEjRrg8kgEDBri5TdQaAgAA/MPXQclvv/3mApD9+/dbvnz57NZbb3XDffV/GT16tKVOndpNmqYRMxpZM378+ODtFcDMnTvXOnXq5IKVLFmyWNu2bW3IkCHJeFYAAOCKC0pmzJhxwf0ZM2a0cePGuSUuamX59NNPk6B2AAAgxeaUAACAqxdBCQAA8AWCEgAA4AsEJQAAwBcISgAAgC8QlAAAAF8gKAEAAL5AUAIAAHyBoAQAAPgCQQkAAPAFghIAAOALBCUAAMAXCEoAAIAvEJQAAABfICgBAAC+QFACAAB8gaAEAAD4AkEJAADwBYISAADgCwQlAADAFwhKAACALxCUAAAAXyAoAQAAvkBQAgAAfCFFBSXjxo2zEiVKWMaMGa1GjRr2zTffJHeVAABASgtK3nvvPevVq5c9++yz9t1331mVKlWsYcOGFhMTk9xVAwAAKSkoGTVqlHXo0MEeeeQRK1++vE2cONEyZ85skyZNSu6qAQAAM0trKcCpU6ds7dq11r9//+C21KlTW7169WzlypXnlT958qRbPIcOHXJ/Dx8+nGR1PHnseJIdG/CLpHwPJaW/j///zwPgapUxid6f3vs+EAhctGyKCEr+/PNPO3v2rBUoUCBsu9Z/+OGH88oPGzbMBg8efN72okWLJmk9gavdOHs8uasAIC69x1hS+vvvvy1HjhwXLJMigpJoqUVF+Seec+fO2V9//WV58uSxVKlSJWvdkHiRu4LM3bt3W/bs2ZO7OgBC8P68uqiFRAFJ4cKFL1o2RQQlefPmtTRp0ti+ffvCtmu9YMGC55XPkCGDW0LlzJkzyeuJy08feHzoAf7E+/PqcbEWkhSV6Jo+fXqrXr26LV26NKz1Q+s1a9ZM1roBAIAU1FIi6o5p27at3XjjjXbzzTfbK6+8YkePHnWjcQAAQPJLMUHJ/fffb3/88YcNHDjQ9u7da1WrVrUFCxacl/yKlEHdc5qzJrKbDkDy4/2ZcqUKxGeMDgAAQBJLETklAADA/whKAACALxCUAAAAXyAowVVNk919+OGH7v+//PKLW1+/fr1bX758uVs/ePBgnLefMmUKc9QAUeA9g0tBUIIrxsMPP+yCiMjlrrvuitftNUPknj17rGLFikleV+Bqea9pnqfSpUvbkCFD7MyZM/Ea6fjjjz9elnri6pNihgTj6qAAZPLkyWHb4jtsULP6xjaDL4C432u6OOmnn35qnTt3tnTp0oVd2DQ2mTJlcguQELSU4IqiAESBReiSK1cut2/79u1Wu3Zty5gxo5UvX94WL14cdtvI7hvPihUrrHLlyu52t9xyi23atOmCdfjoo4+sWrVqrvy1117rLt4Yn1+QwJX4XitevLh16tTJXVX9448/tgMHDlibNm3c+y5z5szWqFEj996Lq/vm+++/tzp16li2bNnclPGaXfvbb78N7v/ggw+sQoUK7v5KlChhI0eODKuHtr3wwgvWrl07d4xixYrZ66+/HlZm48aNduedd7pgSNco69ixox05ciS4/4477rAePXqE3aZZs2auRcgzfvx4u+6669z7WvNX3XvvvYn0SCIaBCW4KuiyAc2bN3dNzatXr7aJEydav3794nXbPn36uA/CNWvWWL58+eyee+6x06dPx1r2yy+/dB/I3bt3ty1btth//vMf9yH8/PPPJ/IZAf6iL/xTp065L3IFFQpQVq5c6S621rhx4zjfMw8++KAVKVLEvb/Wrl1rTz31lGtxEa3fd9991rJlSxdYDBo0yJ555hn3ngql96dm4163bp098cQTLkjatm2b26eZuRs2bOiCJN3HrFmzbMmSJdalS5d4n5vOp1u3bq6LSsfVxJr6gYNkoMnTgCtB27ZtA2nSpAlkyZIlbHn++ecDCxcuDKRNmzbwv//9L1h+/vz5mhgwMGfOHLe+c+dOt75u3Tq3/tlnn7n1GTNmBG+zf//+QKZMmQLvvfeeW588eXIgR44cwf1169YNvPDCC2H1eueddwKFChVK8vMHLud7rWnTpu7/586dCyxevDiQIUOGQLNmzdx7ZsWKFcGyf/75p3vPzJw5M9b3TLZs2QJTpkyJ9X5atWoVqF+/fti2Pn36BMqXLx9cL168eOChhx4Krqs++fPnD0yYMMGtv/7664FcuXIFjhw5Eiwzb968QOrUqQN79+5167fffnuge/fuYfej89N5ygcffBDInj174PDhwwl6vJB4aCnBFUXNwOp+CV0ef/xx27p1q0tkDb00dnwvthhaLnfu3FamTBl3vNioKVq/prJmzRpcOnTo4BJojx07lghnCPjD3Llz3etb3RnqolECq1pJ0qZNazVq1AiWU3fJhd4zuu5Y+/btXffP8OHDbceOHcF9uk2tWrXCymtd3UFnz54NblP3qkddsOpWiomJCR6jSpUqliVLlrBjqPXUa025mPr167tuKnXHtm7d2qZNm8b7OZkQlOCKog8ejQQIXRRIXC7qp1YOSWhQpGZnfYjqwxu42n4A6LV9/Phxmzp1qgsIoqUumc2bN1uTJk1s2bJlLt9rzpw5UR3D6+7xqB4KOuIrderUrpspVGh3k3JVvvvuO3v33XetUKFC7hppCnQuNF0AkgZBCa4K5cqVs927d7sWC8+qVaviddvQckri03BGHS82SnDVr6/IwEiLPviAq+0HgBJL1Toiel8oqVt5W579+/e794SCjbhcf/311rNnT1u0aJHL/fJG0Ol4SjQPpXWV12i5+NAx1IKp3JLQY+j9qBYcUa5Y6GeDWmEiE9p1jmrNGTFihG3YsMElxiuIwuXFkGBcUTQ8UVd5ju3DRB9kbdu2tZdeeskOHz5sTz/9dLyOqe4YNUEr4163yZs3r8vMj41+Qd19993ug1rZ+frg0weiPuCee+65RDlHwK80OqVp06auy1JJ3mphUOLqNddc47ZHUguLEsn1XilZsqT99ttvLhm1RYsWbn/v3r3tpptusqFDh7ruISXOjh071o2EiS8l0uqKwnrvq1VGV4Pv2rWr64bxrgKvkTnqRpo3b56VKlXKRo0aFdYKoq6qn3/+2SW3KmFWQ6DVEuMFNbh8+GmHK4qy4tW8GrrceuutLjhQk7A+BG+++WbXhx3fETHq59ZoGg1VVMDzySefuFE8sVGWvz7A9ItPH6YaQjx69GjXHw2kBGrl0HtFwbnysdQtoi/xyC4WUWuHWlI0Yk0/GjTSRvkp6gL1Wh5nzpxpM2bMcJMaKujXj4TQoboXo2HJCxcutL/++su9JxUA1a1b1wU3Hg0nVtCietx+++0ud0TdUx4NYZ49e7YLXtTyotF76srRUGVcXqmU7XqZ7xMAAOA8tJQAAABfICgBAAC+QFACAAB8gaAEAAD4AkEJAADwBYISAADgCwQlAADAFwhKAACALxCUAEhWU6ZMcTNqAgBBCYBLpmnBdeVWLZqiXxdy03ThunjbxeiaJ7oIIgBwQT4AieKuu+5y10XRRRN1LZTOnTu766H079//grfLlCmTWwCAlhIAiSJDhgxWsGBBd3HCTp06uSs3f/zxx3bgwAF3ITRdfVUXT9MF2bZv3x5n942uuqyLpekKtNmzZ3cXf/v222+D+z/44AN3oTTdX4kSJWzkyJFh9dC2F154wV2ETcfQFZ1ff/31sDIbN250F19TMKQrRHfs2NGOHDkS3H/HHXdYjx49wm6jK0eHXihOV7LVVXMzZszorkarC8EBuDQEJQCShL7wT5065b7IFVQoQNGl6XUN0MaNG9vp06fjvBR9kSJF3CXu165da0899VTwCrRa15VmW7Zs6QILXar+mWeecYFNKAUqN954o61bt86eeOIJFyRt27bN7Tt69Ki72rOCJN3HrFmzbMmSJdalS5d4n5vOp1u3bq6LSsfV1at12XsAl0hXCQaAS9G2bdtA06ZN3f/PnTsXWLx4cSBDhgyBZs2a6SrkgRUrVgTL/vnnn4FMmTIFZs6c6dYnT54cyJEjR3B/tmzZAlOmTIn1flq1ahWoX79+2LY+ffoEypcvH1wvXrx44KGHHgquqz758+cPTJgwwa2//vrrgVy5cgWOHDkSLDNv3rxA6tSpA3v37nXrt99+e6B79+5h96Pz03nKBx98EMiePXvg8OHDCXq8AMSOlhIAiWLu3LmWNWtW152hLholsKqVJG3atFajRo1gOXWXlClTxrZu3RrrcXr16mXt27d33T/Dhw+3HTt2BPfpNrVq1Qorr3V1B509eza4rXLlysH/K/lW3UoxMTHBY1SpUsWyZMkSdoxz584FW1Mupn79+q6b6tprr7XWrVvbtGnT7NixY/G6LYC4EZQASBTKA1m/fr0LEI4fP25Tp051AUG01CWzefNma9KkiS1btszKly9vc+bMieoYXnePR/VQ0BFfqVOndt1MoUK7m5Sr8t1339m7775rhQoVsoEDB7pA5+DBg1HVE0A4ghIAiUItDxoKrMRStY5IuXLl3LDg1atXB8vt37/ftUgo2IjL9ddfbz179rRFixZZ8+bN3age73grVqwIK6t1lU+TJk286qljKJlWuSWhx1AgohYcyZcvn+3Zsye4X60wmzZtCjuOzlGtOSNGjLANGzbYL7/84oIoAAlHUAIgyWh0StOmTa1Dhw721VdfuWDgoYcesmuuucZtj6QWFiWcLl++3H799VcXLCgZVYGE9O7d25YuXWpDhw51c5uoNWbs2LH25JNPxrtOSqRVF1Pbtm1doPHZZ59Z165dXTeMRtGIRubMmzfPLT/88INLlA1tBVFX1ZgxY1zLkOr59ttvu5YYL6gBkDDMUwIgSamVo3v37nb33Xe70TgapaJ5TCK7WEStHWpJ0RDiffv2Wd68eV1LyeDBg93+atWq2cyZM113iQITdZ1oBEzoUN2L0bDkhQsXujrddNNNbr1FixY2atSoYBkNJ1YApXqoRUStNuqe8mgI8+zZs11X04kTJ1zwpa4cDVUGkHCplO16CbcHAABIFHTfAAAAXyAoAQAAvkBQAgAAfIGgBAAA+AJBCQAA8AWCEgAA4AsEJQAAwBcISgAAgC8QlAAAAF8gKAEAAL5AUAIAAMwP/h/nDHDusPrS+gAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Bar plot of class counts\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(data=mushroom, x=\"poisonous\", palette=\"Set2\")\n",
    "plt.title(\"Count of Edible vs Poisonous Mushrooms\")\n",
    "plt.xlabel(\"Poisonous\")\n",
    "plt.ylabel(\"Number of Mushrooms\")\n",
    "plt.xticks([0,1], [\"Edible\", \"Poisonous\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f282ba7",
   "metadata": {},
   "source": [
    "## 2.2 Gender dataset\n",
    "Challenge of this dataset is that the names are strings, so we'd have to convert them into some represenation without string. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "601e9d38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Count</th>\n",
       "      <th>Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>James</td>\n",
       "      <td>M</td>\n",
       "      <td>5304407</td>\n",
       "      <td>0.014517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>John</td>\n",
       "      <td>M</td>\n",
       "      <td>5260831</td>\n",
       "      <td>0.014398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Robert</td>\n",
       "      <td>M</td>\n",
       "      <td>4970386</td>\n",
       "      <td>0.013603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Michael</td>\n",
       "      <td>M</td>\n",
       "      <td>4579950</td>\n",
       "      <td>0.012534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>William</td>\n",
       "      <td>M</td>\n",
       "      <td>4226608</td>\n",
       "      <td>0.011567</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Name Gender    Count  Probability\n",
       "0    James      M  5304407     0.014517\n",
       "1     John      M  5260831     0.014398\n",
       "2   Robert      M  4970386     0.013603\n",
       "3  Michael      M  4579950     0.012534\n",
       "4  William      M  4226608     0.011567"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63f0eaa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q9/dv0qd5v93jv_7gz3d0y5d0xc0000gn/T/ipykernel_3563/2984661251.py:2: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(data=gender, x=\"Gender\", y=\"Count\", palette=\"pastel\")\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "sns.barplot(data=gender, x=\"Gender\", y=\"Count\", palette=\"pastel\")\n",
    "plt.title(\"Count of Names by Gender\")\n",
    "plt.xlabel(\"Gender\")\n",
    "plt.ylabel(\"Number of Names\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9fd77f51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>char_1</th>\n",
       "      <th>char_2</th>\n",
       "      <th>char_3</th>\n",
       "      <th>char_4</th>\n",
       "      <th>char_5</th>\n",
       "      <th>char_6</th>\n",
       "      <th>char_7</th>\n",
       "      <th>char_8</th>\n",
       "      <th>char_9</th>\n",
       "      <th>char_10</th>\n",
       "      <th>...</th>\n",
       "      <th>char_19</th>\n",
       "      <th>char_20</th>\n",
       "      <th>char_21</th>\n",
       "      <th>char_22</th>\n",
       "      <th>char_23</th>\n",
       "      <th>char_24</th>\n",
       "      <th>char_25</th>\n",
       "      <th>Count</th>\n",
       "      <th>Probability</th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>5304407.0</td>\n",
       "      <td>0.014517</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>5260831.0</td>\n",
       "      <td>0.014398</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>4970386.0</td>\n",
       "      <td>0.013603</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>4579950.0</td>\n",
       "      <td>0.012534</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>4226608.0</td>\n",
       "      <td>0.011567</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   char_1  char_2  char_3  char_4  char_5  char_6  char_7  char_8  char_9  \\\n",
       "0     9.0     0.0    12.0     4.0    18.0    -1.0    -1.0    -1.0    -1.0   \n",
       "1     9.0    14.0     7.0    13.0    -1.0    -1.0    -1.0    -1.0    -1.0   \n",
       "2    17.0    14.0     1.0     4.0    17.0    19.0    -1.0    -1.0    -1.0   \n",
       "3    12.0     8.0     2.0     7.0     0.0     4.0    11.0    -1.0    -1.0   \n",
       "4    22.0     8.0    11.0    11.0     8.0     0.0    12.0    -1.0    -1.0   \n",
       "\n",
       "   char_10  ...  char_19  char_20  char_21  char_22  char_23  char_24  \\\n",
       "0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "1     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "2     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "3     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "4     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "\n",
       "   char_25      Count  Probability  Gender  \n",
       "0     -1.0  5304407.0     0.014517       1  \n",
       "1     -1.0  5260831.0     0.014398       1  \n",
       "2     -1.0  4970386.0     0.013603       1  \n",
       "3     -1.0  4579950.0     0.012534       1  \n",
       "4     -1.0  4226608.0     0.011567       1  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_to_int = {c: i for i, c in enumerate(\"abcdefghijklmnopqrstuvwxyz\")}\n",
    "max_len = gender['Name'].str.len().max()\n",
    "def encode_name(name, max_len=max_len):\n",
    "    name = name.lower()\n",
    "    vec = [char_to_int.get(c, -1) for c in name]  \n",
    "    if len(vec) < max_len:\n",
    "        vec += [-1] * (max_len - len(vec))  \n",
    "    return vec\n",
    "X_names = np.array(gender['Name'].apply(encode_name).to_list())\n",
    "X_numeric = gender[['Count', 'Probability']].values\n",
    "X_final = np.hstack([X_names, X_numeric])\n",
    "name_cols = [f\"char_{i+1}\" for i in range(X_names.shape[1])]\n",
    "numeric_cols = ['Count', 'Probability']\n",
    "all_cols = name_cols + numeric_cols\n",
    "gender_numeric = pd.DataFrame(X_final, columns=all_cols)\n",
    "gender_numeric['Gender'] = (gender['Gender'] == 'M').astype(int)\n",
    "gender_numeric.head() # For gender, 1 is male, 0 is female \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1928b678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 147269 entries, 0 to 147268\n",
      "Data columns (total 28 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   char_1       147269 non-null  float64\n",
      " 1   char_2       147269 non-null  float64\n",
      " 2   char_3       147269 non-null  float64\n",
      " 3   char_4       147269 non-null  float64\n",
      " 4   char_5       147269 non-null  float64\n",
      " 5   char_6       147269 non-null  float64\n",
      " 6   char_7       147269 non-null  float64\n",
      " 7   char_8       147269 non-null  float64\n",
      " 8   char_9       147269 non-null  float64\n",
      " 9   char_10      147269 non-null  float64\n",
      " 10  char_11      147269 non-null  float64\n",
      " 11  char_12      147269 non-null  float64\n",
      " 12  char_13      147269 non-null  float64\n",
      " 13  char_14      147269 non-null  float64\n",
      " 14  char_15      147269 non-null  float64\n",
      " 15  char_16      147269 non-null  float64\n",
      " 16  char_17      147269 non-null  float64\n",
      " 17  char_18      147269 non-null  float64\n",
      " 18  char_19      147269 non-null  float64\n",
      " 19  char_20      147269 non-null  float64\n",
      " 20  char_21      147269 non-null  float64\n",
      " 21  char_22      147269 non-null  float64\n",
      " 22  char_23      147269 non-null  float64\n",
      " 23  char_24      147269 non-null  float64\n",
      " 24  char_25      147269 non-null  float64\n",
      " 25  Count        147269 non-null  float64\n",
      " 26  Probability  147269 non-null  float64\n",
      " 27  Gender       147269 non-null  int64  \n",
      "dtypes: float64(27), int64(1)\n",
      "memory usage: 31.5 MB\n"
     ]
    }
   ],
   "source": [
    "gender_numeric.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee41eace",
   "metadata": {},
   "source": [
    "## 2.3 Bankrupt dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75d2c516",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bankrupt?</th>\n",
       "      <th>ROA(C) before interest and depreciation before interest</th>\n",
       "      <th>ROA(A) before interest and % after tax</th>\n",
       "      <th>ROA(B) before interest and depreciation after tax</th>\n",
       "      <th>Operating Gross Margin</th>\n",
       "      <th>Realized Sales Gross Margin</th>\n",
       "      <th>Operating Profit Rate</th>\n",
       "      <th>Pre-tax net Interest Rate</th>\n",
       "      <th>After-tax net Interest Rate</th>\n",
       "      <th>Non-industry income and expenditure/revenue</th>\n",
       "      <th>...</th>\n",
       "      <th>Net Income to Total Assets</th>\n",
       "      <th>Total assets to GNP price</th>\n",
       "      <th>No-credit Interval</th>\n",
       "      <th>Gross Profit to Sales</th>\n",
       "      <th>Net Income to Stockholder's Equity</th>\n",
       "      <th>Liability to Equity</th>\n",
       "      <th>Degree of Financial Leverage (DFL)</th>\n",
       "      <th>Interest Coverage Ratio (Interest expense to EBIT)</th>\n",
       "      <th>Net Income Flag</th>\n",
       "      <th>Equity to Liability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.370594</td>\n",
       "      <td>0.424389</td>\n",
       "      <td>0.405750</td>\n",
       "      <td>0.601457</td>\n",
       "      <td>0.601457</td>\n",
       "      <td>0.998969</td>\n",
       "      <td>0.796887</td>\n",
       "      <td>0.808809</td>\n",
       "      <td>0.302646</td>\n",
       "      <td>...</td>\n",
       "      <td>0.716845</td>\n",
       "      <td>0.009219</td>\n",
       "      <td>0.622879</td>\n",
       "      <td>0.601453</td>\n",
       "      <td>0.827890</td>\n",
       "      <td>0.290202</td>\n",
       "      <td>0.026601</td>\n",
       "      <td>0.564050</td>\n",
       "      <td>1</td>\n",
       "      <td>0.016469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.464291</td>\n",
       "      <td>0.538214</td>\n",
       "      <td>0.516730</td>\n",
       "      <td>0.610235</td>\n",
       "      <td>0.610235</td>\n",
       "      <td>0.998946</td>\n",
       "      <td>0.797380</td>\n",
       "      <td>0.809301</td>\n",
       "      <td>0.303556</td>\n",
       "      <td>...</td>\n",
       "      <td>0.795297</td>\n",
       "      <td>0.008323</td>\n",
       "      <td>0.623652</td>\n",
       "      <td>0.610237</td>\n",
       "      <td>0.839969</td>\n",
       "      <td>0.283846</td>\n",
       "      <td>0.264577</td>\n",
       "      <td>0.570175</td>\n",
       "      <td>1</td>\n",
       "      <td>0.020794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.426071</td>\n",
       "      <td>0.499019</td>\n",
       "      <td>0.472295</td>\n",
       "      <td>0.601450</td>\n",
       "      <td>0.601364</td>\n",
       "      <td>0.998857</td>\n",
       "      <td>0.796403</td>\n",
       "      <td>0.808388</td>\n",
       "      <td>0.302035</td>\n",
       "      <td>...</td>\n",
       "      <td>0.774670</td>\n",
       "      <td>0.040003</td>\n",
       "      <td>0.623841</td>\n",
       "      <td>0.601449</td>\n",
       "      <td>0.836774</td>\n",
       "      <td>0.290189</td>\n",
       "      <td>0.026555</td>\n",
       "      <td>0.563706</td>\n",
       "      <td>1</td>\n",
       "      <td>0.016474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.399844</td>\n",
       "      <td>0.451265</td>\n",
       "      <td>0.457733</td>\n",
       "      <td>0.583541</td>\n",
       "      <td>0.583541</td>\n",
       "      <td>0.998700</td>\n",
       "      <td>0.796967</td>\n",
       "      <td>0.808966</td>\n",
       "      <td>0.303350</td>\n",
       "      <td>...</td>\n",
       "      <td>0.739555</td>\n",
       "      <td>0.003252</td>\n",
       "      <td>0.622929</td>\n",
       "      <td>0.583538</td>\n",
       "      <td>0.834697</td>\n",
       "      <td>0.281721</td>\n",
       "      <td>0.026697</td>\n",
       "      <td>0.564663</td>\n",
       "      <td>1</td>\n",
       "      <td>0.023982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.465022</td>\n",
       "      <td>0.538432</td>\n",
       "      <td>0.522298</td>\n",
       "      <td>0.598783</td>\n",
       "      <td>0.598783</td>\n",
       "      <td>0.998973</td>\n",
       "      <td>0.797366</td>\n",
       "      <td>0.809304</td>\n",
       "      <td>0.303475</td>\n",
       "      <td>...</td>\n",
       "      <td>0.795016</td>\n",
       "      <td>0.003878</td>\n",
       "      <td>0.623521</td>\n",
       "      <td>0.598782</td>\n",
       "      <td>0.839973</td>\n",
       "      <td>0.278514</td>\n",
       "      <td>0.024752</td>\n",
       "      <td>0.575617</td>\n",
       "      <td>1</td>\n",
       "      <td>0.035490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 96 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Bankrupt?   ROA(C) before interest and depreciation before interest  \\\n",
       "0          1                                           0.370594          \n",
       "1          1                                           0.464291          \n",
       "2          1                                           0.426071          \n",
       "3          1                                           0.399844          \n",
       "4          1                                           0.465022          \n",
       "\n",
       "    ROA(A) before interest and % after tax  \\\n",
       "0                                 0.424389   \n",
       "1                                 0.538214   \n",
       "2                                 0.499019   \n",
       "3                                 0.451265   \n",
       "4                                 0.538432   \n",
       "\n",
       "    ROA(B) before interest and depreciation after tax  \\\n",
       "0                                           0.405750    \n",
       "1                                           0.516730    \n",
       "2                                           0.472295    \n",
       "3                                           0.457733    \n",
       "4                                           0.522298    \n",
       "\n",
       "    Operating Gross Margin   Realized Sales Gross Margin  \\\n",
       "0                 0.601457                      0.601457   \n",
       "1                 0.610235                      0.610235   \n",
       "2                 0.601450                      0.601364   \n",
       "3                 0.583541                      0.583541   \n",
       "4                 0.598783                      0.598783   \n",
       "\n",
       "    Operating Profit Rate   Pre-tax net Interest Rate  \\\n",
       "0                0.998969                    0.796887   \n",
       "1                0.998946                    0.797380   \n",
       "2                0.998857                    0.796403   \n",
       "3                0.998700                    0.796967   \n",
       "4                0.998973                    0.797366   \n",
       "\n",
       "    After-tax net Interest Rate   Non-industry income and expenditure/revenue  \\\n",
       "0                      0.808809                                      0.302646   \n",
       "1                      0.809301                                      0.303556   \n",
       "2                      0.808388                                      0.302035   \n",
       "3                      0.808966                                      0.303350   \n",
       "4                      0.809304                                      0.303475   \n",
       "\n",
       "   ...   Net Income to Total Assets   Total assets to GNP price  \\\n",
       "0  ...                     0.716845                    0.009219   \n",
       "1  ...                     0.795297                    0.008323   \n",
       "2  ...                     0.774670                    0.040003   \n",
       "3  ...                     0.739555                    0.003252   \n",
       "4  ...                     0.795016                    0.003878   \n",
       "\n",
       "    No-credit Interval   Gross Profit to Sales  \\\n",
       "0             0.622879                0.601453   \n",
       "1             0.623652                0.610237   \n",
       "2             0.623841                0.601449   \n",
       "3             0.622929                0.583538   \n",
       "4             0.623521                0.598782   \n",
       "\n",
       "    Net Income to Stockholder's Equity   Liability to Equity  \\\n",
       "0                             0.827890              0.290202   \n",
       "1                             0.839969              0.283846   \n",
       "2                             0.836774              0.290189   \n",
       "3                             0.834697              0.281721   \n",
       "4                             0.839973              0.278514   \n",
       "\n",
       "    Degree of Financial Leverage (DFL)  \\\n",
       "0                             0.026601   \n",
       "1                             0.264577   \n",
       "2                             0.026555   \n",
       "3                             0.026697   \n",
       "4                             0.024752   \n",
       "\n",
       "    Interest Coverage Ratio (Interest expense to EBIT)   Net Income Flag  \\\n",
       "0                                           0.564050                   1   \n",
       "1                                           0.570175                   1   \n",
       "2                                           0.563706                   1   \n",
       "3                                           0.564663                   1   \n",
       "4                                           0.575617                   1   \n",
       "\n",
       "    Equity to Liability  \n",
       "0              0.016469  \n",
       "1              0.020794  \n",
       "2              0.016474  \n",
       "3              0.023982  \n",
       "4              0.035490  \n",
       "\n",
       "[5 rows x 96 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bankrupts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15e8ff9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q9/dv0qd5v93jv_7gz3d0y5d0xc0000gn/T/ipykernel_3563/1771985786.py:2: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.countplot(data=bankrupts, x=\"Bankrupt?\", palette=\"Set1\")\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(data=bankrupts, x=\"Bankrupt?\", palette=\"Set1\")\n",
    "plt.title(\"Count of Bankrupt vs Non-Bankrupt Companies\")\n",
    "plt.xlabel(\"Bankrupt\")\n",
    "plt.ylabel(\"Number of Companies\")\n",
    "plt.xticks([0,1], [\"Not Bankrupt\", \"Bankrupt\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0887831",
   "metadata": {},
   "source": [
    "# 3. Train test partitions: 20/80, 50/50, 80/20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34153492",
   "metadata": {},
   "source": [
    "### 3.1 Main function for creating partition for ease of use, and created partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1f8cc70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_partitions(df, y_col, seeds=[0, 42, 99]):\n",
    "    partitions = {}\n",
    "    X = df.drop(columns=[y_col])\n",
    "    y = df[y_col]\n",
    "    splits = [0.2, 0.5, 0.8] \n",
    "    for seed in seeds:\n",
    "        partitions[seed] = {}\n",
    "        for train_frac in splits:\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X, y, train_size=train_frac, random_state=seed, stratify=y\n",
    "            )\n",
    "            partitions[seed][train_frac] = (X_train, X_test, y_train, y_test)\n",
    "    return partitions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628c0b26",
   "metadata": {},
   "source": [
    "Preparing to split datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b7ee49",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\"mushroom\": mushroom, \n",
    "            \"bankrupt\": bankrupts, \n",
    "            \"gender\": gender_numeric}\n",
    "splits = [0.2, 0.5, 0.8]       \n",
    "seeds = [0, 42, 99]            \n",
    "all_partitions = {} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf31c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dname, df in datasets.items():\n",
    "    \n",
    "    if dname.lower() == \"mushroom\":\n",
    "        target = \"poisonous\"\n",
    "    elif dname.lower() == \"bankrupt\":\n",
    "        target = \"Bankrupt?\"   \n",
    "    elif dname.lower() == \"gender\":\n",
    "        target = \"Gender\"\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown dataset name: {dname}\")\n",
    "    X = df.drop(columns=[target])\n",
    "    y = df[target]\n",
    "    \n",
    "    all_partitions[dname] = {}\n",
    "    \n",
    "    for seed in seeds:\n",
    "        all_partitions[dname][seed] = {}\n",
    "        for frac in splits:\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X, y, train_size=frac, random_state=seed, stratify=y\n",
    "            )\n",
    "            all_partitions[dname][seed][frac] = (X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "022c8bb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mushroom': {0: {0.2: (      cap-shape  cap-surface  cap-color  bruises  odor  gill-attachment  \\\n",
       "    155         5.0          3.0        4.0      1.0   3.0              1.0   \n",
       "    4584        2.0          0.0        3.0      0.0   2.0              1.0   \n",
       "    2859        5.0          0.0        2.0      1.0   5.0              1.0   \n",
       "    2455        2.0          0.0        4.0      1.0   5.0              1.0   \n",
       "    2780        2.0          0.0        4.0      1.0   5.0              1.0   \n",
       "    ...         ...          ...        ...      ...   ...              ...   \n",
       "    3962        2.0          0.0        9.0      0.0   2.0              1.0   \n",
       "    4315        2.0          0.0        3.0      0.0   2.0              1.0   \n",
       "    3214        2.0          0.0        2.0      1.0   5.0              1.0   \n",
       "    1207        2.0          3.0        8.0      1.0   6.0              1.0   \n",
       "    3833        5.0          2.0        8.0      0.0   1.0              1.0   \n",
       "    \n",
       "          gill-spacing  gill-size  gill-color  stalk-shape  ...  \\\n",
       "    155            0.0        0.0        10.0          0.0  ...   \n",
       "    4584           0.0        0.0         7.0          0.0  ...   \n",
       "    2859           0.0        0.0         9.0          1.0  ...   \n",
       "    2455           0.0        0.0         7.0          1.0  ...   \n",
       "    2780           0.0        0.0         9.0          1.0  ...   \n",
       "    ...            ...        ...         ...          ...  ...   \n",
       "    3962           0.0        0.0         2.0          0.0  ...   \n",
       "    4315           0.0        0.0         7.0          0.0  ...   \n",
       "    3214           0.0        0.0         5.0          1.0  ...   \n",
       "    1207           0.0        1.0         7.0          0.0  ...   \n",
       "    3833           0.0        1.0         5.0          0.0  ...   \n",
       "    \n",
       "          stalk-surface-below-ring  stalk-color-above-ring  \\\n",
       "    155                        3.0                     7.0   \n",
       "    4584                       1.0                     0.0   \n",
       "    2859                       2.0                     6.0   \n",
       "    2455                       2.0                     6.0   \n",
       "    2780                       2.0                     3.0   \n",
       "    ...                        ...                     ...   \n",
       "    3962                       1.0                     6.0   \n",
       "    4315                       1.0                     0.0   \n",
       "    3214                       2.0                     7.0   \n",
       "    1207                       2.0                     7.0   \n",
       "    3833                       2.0                     7.0   \n",
       "    \n",
       "          stalk-color-below-ring  veil-type  veil-color  ring-number  ring-type  \\\n",
       "    155                      7.0        0.0         2.0          1.0        4.0   \n",
       "    4584                     6.0        0.0         2.0          1.0        2.0   \n",
       "    2859                     7.0        0.0         2.0          1.0        4.0   \n",
       "    2455                     6.0        0.0         2.0          1.0        4.0   \n",
       "    2780                     6.0        0.0         2.0          1.0        4.0   \n",
       "    ...                      ...        ...         ...          ...        ...   \n",
       "    3962                     0.0        0.0         2.0          1.0        2.0   \n",
       "    4315                     6.0        0.0         2.0          1.0        2.0   \n",
       "    3214                     3.0        0.0         2.0          1.0        4.0   \n",
       "    1207                     7.0        0.0         2.0          1.0        4.0   \n",
       "    3833                     7.0        0.0         2.0          1.0        4.0   \n",
       "    \n",
       "          spore-print-color  population  habitat  \n",
       "    155                 2.0         3.0      1.0  \n",
       "    4584                1.0         5.0      0.0  \n",
       "    2859                3.0         5.0      0.0  \n",
       "    2455                2.0         4.0      0.0  \n",
       "    2780                2.0         5.0      0.0  \n",
       "    ...                 ...         ...      ...  \n",
       "    3962                1.0         5.0      0.0  \n",
       "    4315                1.0         4.0      1.0  \n",
       "    3214                2.0         4.0      0.0  \n",
       "    1207                2.0         3.0      5.0  \n",
       "    3833                2.0         3.0      0.0  \n",
       "    \n",
       "    [1624 rows x 21 columns],\n",
       "          cap-shape  cap-surface  cap-color  bruises  odor  gill-attachment  \\\n",
       "    3042        2.0          3.0        4.0      1.0   5.0              1.0   \n",
       "    2452        5.0          0.0        3.0      0.0   5.0              1.0   \n",
       "    1446        5.0          2.0        4.0      0.0   5.0              1.0   \n",
       "    7835        3.0          3.0        2.0      0.0   8.0              1.0   \n",
       "    873         5.0          0.0        4.0      1.0   5.0              1.0   \n",
       "    ...         ...          ...        ...      ...   ...              ...   \n",
       "    4978        5.0          3.0        9.0      0.0   2.0              1.0   \n",
       "    1151        2.0          3.0        4.0      1.0   0.0              1.0   \n",
       "    4922        2.0          3.0        3.0      0.0   2.0              1.0   \n",
       "    1625        2.0          3.0        8.0      1.0   6.0              1.0   \n",
       "    4816        2.0          0.0        9.0      0.0   2.0              1.0   \n",
       "    \n",
       "          gill-spacing  gill-size  gill-color  stalk-shape  ...  \\\n",
       "    3042           0.0        0.0         9.0          1.0  ...   \n",
       "    2452           1.0        0.0         4.0          1.0  ...   \n",
       "    1446           1.0        0.0         7.0          1.0  ...   \n",
       "    7835           0.0        1.0         0.0          1.0  ...   \n",
       "    873            0.0        0.0         5.0          1.0  ...   \n",
       "    ...            ...        ...         ...          ...  ...   \n",
       "    4978           0.0        0.0         7.0          0.0  ...   \n",
       "    1151           0.0        0.0         5.0          0.0  ...   \n",
       "    4922           0.0        0.0         7.0          0.0  ...   \n",
       "    1625           0.0        1.0         4.0          0.0  ...   \n",
       "    4816           0.0        0.0         3.0          0.0  ...   \n",
       "    \n",
       "          stalk-surface-below-ring  stalk-color-above-ring  \\\n",
       "    3042                       2.0                     6.0   \n",
       "    2452                       0.0                     7.0   \n",
       "    1446                       0.0                     7.0   \n",
       "    7835                       1.0                     7.0   \n",
       "    873                        2.0                     3.0   \n",
       "    ...                        ...                     ...   \n",
       "    4978                       1.0                     6.0   \n",
       "    1151                       3.0                     7.0   \n",
       "    4922                       1.0                     0.0   \n",
       "    1625                       2.0                     7.0   \n",
       "    4816                       1.0                     4.0   \n",
       "    \n",
       "          stalk-color-below-ring  veil-type  veil-color  ring-number  ring-type  \\\n",
       "    3042                     3.0        0.0         2.0          1.0        4.0   \n",
       "    2452                     7.0        0.0         2.0          1.0        0.0   \n",
       "    1446                     7.0        0.0         2.0          1.0        0.0   \n",
       "    7835                     7.0        0.0         2.0          1.0        0.0   \n",
       "    873                      7.0        0.0         2.0          1.0        4.0   \n",
       "    ...                      ...        ...         ...          ...        ...   \n",
       "    4978                     0.0        0.0         2.0          1.0        2.0   \n",
       "    1151                     7.0        0.0         2.0          1.0        4.0   \n",
       "    4922                     0.0        0.0         2.0          1.0        2.0   \n",
       "    1625                     7.0        0.0         2.0          1.0        4.0   \n",
       "    4816                     0.0        0.0         2.0          1.0        2.0   \n",
       "    \n",
       "          spore-print-color  population  habitat  \n",
       "    3042                2.0         4.0      0.0  \n",
       "    2452                3.0         0.0      1.0  \n",
       "    1446                2.0         3.0      1.0  \n",
       "    7835                7.0         4.0      0.0  \n",
       "    873                 2.0         4.0      0.0  \n",
       "    ...                 ...         ...      ...  \n",
       "    4978                1.0         4.0      0.0  \n",
       "    1151                2.0         5.0      4.0  \n",
       "    4922                1.0         5.0      4.0  \n",
       "    1625                3.0         4.0      5.0  \n",
       "    4816                1.0         4.0      4.0  \n",
       "    \n",
       "    [6500 rows x 21 columns],\n",
       "    155     0.0\n",
       "    4584    1.0\n",
       "    2859    0.0\n",
       "    2455    0.0\n",
       "    2780    0.0\n",
       "           ... \n",
       "    3962    1.0\n",
       "    4315    1.0\n",
       "    3214    0.0\n",
       "    1207    1.0\n",
       "    3833    1.0\n",
       "    Name: poisonous, Length: 1624, dtype: float64,\n",
       "    3042    0.0\n",
       "    2452    0.0\n",
       "    1446    0.0\n",
       "    7835    1.0\n",
       "    873     0.0\n",
       "           ... \n",
       "    4978    1.0\n",
       "    1151    0.0\n",
       "    4922    1.0\n",
       "    1625    1.0\n",
       "    4816    1.0\n",
       "    Name: poisonous, Length: 6500, dtype: float64),\n",
       "   0.5: (      cap-shape  cap-surface  cap-color  bruises  odor  gill-attachment  \\\n",
       "    540         5.0          2.0        9.0      1.0   0.0              1.0   \n",
       "    5655        2.0          2.0        0.0      1.0   2.0              1.0   \n",
       "    3741        2.0          0.0        9.0      0.0   2.0              1.0   \n",
       "    541         2.0          0.0        3.0      0.0   5.0              1.0   \n",
       "    2012        5.0          0.0        2.0      1.0   5.0              1.0   \n",
       "    ...         ...          ...        ...      ...   ...              ...   \n",
       "    6193        5.0          2.0        2.0      0.0   2.0              1.0   \n",
       "    6581        2.0          3.0        4.0      0.0   7.0              1.0   \n",
       "    3214        2.0          0.0        2.0      1.0   5.0              1.0   \n",
       "    1271        5.0          2.0        8.0      0.0   5.0              1.0   \n",
       "    7668        3.0          3.0        4.0      0.0   7.0              1.0   \n",
       "    \n",
       "          gill-spacing  gill-size  gill-color  stalk-shape  ...  \\\n",
       "    540            0.0        0.0         5.0          0.0  ...   \n",
       "    5655           0.0        0.0         7.0          1.0  ...   \n",
       "    3741           0.0        0.0         3.0          0.0  ...   \n",
       "    541            1.0        0.0         7.0          1.0  ...   \n",
       "    2012           0.0        0.0         9.0          1.0  ...   \n",
       "    ...            ...        ...         ...          ...  ...   \n",
       "    6193           0.0        1.0         0.0          1.0  ...   \n",
       "    6581           0.0        1.0         0.0          1.0  ...   \n",
       "    3214           0.0        0.0         5.0          1.0  ...   \n",
       "    1271           1.0        0.0         5.0          1.0  ...   \n",
       "    7668           0.0        1.0         0.0          1.0  ...   \n",
       "    \n",
       "          stalk-surface-below-ring  stalk-color-above-ring  \\\n",
       "    540                        2.0                     7.0   \n",
       "    5655                       0.0                     7.0   \n",
       "    3741                       1.0                     6.0   \n",
       "    541                        0.0                     7.0   \n",
       "    2012                       2.0                     3.0   \n",
       "    ...                        ...                     ...   \n",
       "    6193                       1.0                     6.0   \n",
       "    6581                       2.0                     6.0   \n",
       "    3214                       2.0                     7.0   \n",
       "    1271                       0.0                     7.0   \n",
       "    7668                       2.0                     6.0   \n",
       "    \n",
       "          stalk-color-below-ring  veil-type  veil-color  ring-number  ring-type  \\\n",
       "    540                      7.0        0.0         2.0          1.0        4.0   \n",
       "    5655                     7.0        0.0         2.0          1.0        4.0   \n",
       "    3741                     6.0        0.0         2.0          1.0        2.0   \n",
       "    541                      7.0        0.0         2.0          1.0        0.0   \n",
       "    2012                     7.0        0.0         2.0          1.0        4.0   \n",
       "    ...                      ...        ...         ...          ...        ...   \n",
       "    6193                     6.0        0.0         2.0          1.0        0.0   \n",
       "    6581                     7.0        0.0         2.0          1.0        0.0   \n",
       "    3214                     3.0        0.0         2.0          1.0        4.0   \n",
       "    1271                     7.0        0.0         2.0          1.0        0.0   \n",
       "    7668                     7.0        0.0         2.0          1.0        0.0   \n",
       "    \n",
       "          spore-print-color  population  habitat  \n",
       "    540                 2.0         3.0      3.0  \n",
       "    5655                1.0         4.0      1.0  \n",
       "    3741                1.0         4.0      4.0  \n",
       "    541                 2.0         3.0      1.0  \n",
       "    2012                2.0         4.0      0.0  \n",
       "    ...                 ...         ...      ...  \n",
       "    6193                7.0         4.0      4.0  \n",
       "    6581                7.0         4.0      0.0  \n",
       "    3214                2.0         4.0      0.0  \n",
       "    1271                3.0         3.0      1.0  \n",
       "    7668                7.0         4.0      4.0  \n",
       "    \n",
       "    [4062 rows x 21 columns],\n",
       "          cap-shape  cap-surface  cap-color  bruises  odor  gill-attachment  \\\n",
       "    7397        3.0          3.0        4.0      0.0   8.0              1.0   \n",
       "    2668        5.0          0.0        2.0      1.0   5.0              1.0   \n",
       "    7996        2.0          2.0        4.0      0.0   5.0              0.0   \n",
       "    2041        2.0          0.0        4.0      1.0   5.0              1.0   \n",
       "    7610        0.0          2.0        8.0      0.0   5.0              1.0   \n",
       "    ...         ...          ...        ...      ...   ...              ...   \n",
       "    5640        3.0          2.0        4.0      1.0   5.0              1.0   \n",
       "    1357        2.0          0.0        8.0      0.0   5.0              1.0   \n",
       "    6101        2.0          3.0        4.0      0.0   7.0              1.0   \n",
       "    6397        2.0          3.0        4.0      0.0   8.0              1.0   \n",
       "    1365        2.0          0.0        8.0      0.0   5.0              1.0   \n",
       "    \n",
       "          gill-spacing  gill-size  gill-color  stalk-shape  ...  \\\n",
       "    7397           0.0        1.0         0.0          1.0  ...   \n",
       "    2668           0.0        0.0        10.0          1.0  ...   \n",
       "    7996           0.0        0.0         6.0          0.0  ...   \n",
       "    2041           0.0        0.0         5.0          1.0  ...   \n",
       "    7610           1.0        0.0         2.0          0.0  ...   \n",
       "    ...            ...        ...         ...          ...  ...   \n",
       "    5640           0.0        0.0         1.0          0.0  ...   \n",
       "    1357           1.0        0.0         7.0          1.0  ...   \n",
       "    6101           0.0        1.0         0.0          1.0  ...   \n",
       "    6397           0.0        1.0         0.0          1.0  ...   \n",
       "    1365           1.0        0.0         7.0          1.0  ...   \n",
       "    \n",
       "          stalk-surface-below-ring  stalk-color-above-ring  \\\n",
       "    7397                       1.0                     7.0   \n",
       "    2668                       2.0                     3.0   \n",
       "    7996                       2.0                     5.0   \n",
       "    2041                       2.0                     6.0   \n",
       "    7610                       2.0                     7.0   \n",
       "    ...                        ...                     ...   \n",
       "    5640                       2.0                     7.0   \n",
       "    1357                       2.0                     7.0   \n",
       "    6101                       2.0                     7.0   \n",
       "    6397                       2.0                     7.0   \n",
       "    1365                       0.0                     7.0   \n",
       "    \n",
       "          stalk-color-below-ring  veil-type  veil-color  ring-number  ring-type  \\\n",
       "    7397                     7.0        0.0         2.0          1.0        0.0   \n",
       "    2668                     3.0        0.0         2.0          1.0        4.0   \n",
       "    7996                     5.0        0.0         0.0          1.0        4.0   \n",
       "    2041                     7.0        0.0         2.0          1.0        4.0   \n",
       "    7610                     7.0        0.0         2.0          2.0        4.0   \n",
       "    ...                      ...        ...         ...          ...        ...   \n",
       "    5640                     2.0        0.0         2.0          2.0        0.0   \n",
       "    1357                     7.0        0.0         2.0          1.0        0.0   \n",
       "    6101                     7.0        0.0         2.0          1.0        0.0   \n",
       "    6397                     6.0        0.0         2.0          1.0        0.0   \n",
       "    1365                     7.0        0.0         2.0          1.0        0.0   \n",
       "    \n",
       "          spore-print-color  population  habitat  \n",
       "    7397                7.0         4.0      4.0  \n",
       "    2668                3.0         5.0      0.0  \n",
       "    7996                8.0         4.0      2.0  \n",
       "    2041                2.0         5.0      0.0  \n",
       "    7610                7.0         2.0      1.0  \n",
       "    ...                 ...         ...      ...  \n",
       "    5640                7.0         1.0      6.0  \n",
       "    1357                2.0         0.0      1.0  \n",
       "    6101                7.0         4.0      4.0  \n",
       "    6397                7.0         4.0      0.0  \n",
       "    1365                3.0         3.0      1.0  \n",
       "    \n",
       "    [4062 rows x 21 columns],\n",
       "    540     0.0\n",
       "    5655    1.0\n",
       "    3741    1.0\n",
       "    541     0.0\n",
       "    2012    0.0\n",
       "           ... \n",
       "    6193    1.0\n",
       "    6581    1.0\n",
       "    3214    0.0\n",
       "    1271    0.0\n",
       "    7668    1.0\n",
       "    Name: poisonous, Length: 4062, dtype: float64,\n",
       "    7397    1.0\n",
       "    2668    0.0\n",
       "    7996    0.0\n",
       "    2041    0.0\n",
       "    7610    0.0\n",
       "           ... \n",
       "    5640    0.0\n",
       "    1357    0.0\n",
       "    6101    1.0\n",
       "    6397    1.0\n",
       "    1365    0.0\n",
       "    Name: poisonous, Length: 4062, dtype: float64),\n",
       "   0.8: (      cap-shape  cap-surface  cap-color  bruises  odor  gill-attachment  \\\n",
       "    6373        2.0          2.0        4.0      0.0   2.0              1.0   \n",
       "    4331        3.0          3.0        4.0      0.0   5.0              1.0   \n",
       "    6496        2.0          2.0        2.0      0.0   8.0              1.0   \n",
       "    91          0.0          2.0        8.0      1.0   3.0              1.0   \n",
       "    4543        2.0          0.0        9.0      0.0   2.0              1.0   \n",
       "    ...         ...          ...        ...      ...   ...              ...   \n",
       "    7437        2.0          2.0        4.0      0.0   5.0              0.0   \n",
       "    3214        2.0          0.0        2.0      1.0   5.0              1.0   \n",
       "    6271        2.0          2.0        2.0      0.0   7.0              1.0   \n",
       "    7265        2.0          3.0        4.0      0.0   4.0              0.0   \n",
       "    1833        5.0          0.0        3.0      1.0   5.0              1.0   \n",
       "    \n",
       "          gill-spacing  gill-size  gill-color  stalk-shape  ...  \\\n",
       "    6373           0.0        1.0         0.0          1.0  ...   \n",
       "    4331           0.0        1.0        10.0          0.0  ...   \n",
       "    6496           0.0        1.0         0.0          1.0  ...   \n",
       "    91             0.0        0.0         4.0          0.0  ...   \n",
       "    4543           0.0        0.0         3.0          0.0  ...   \n",
       "    ...            ...        ...         ...          ...  ...   \n",
       "    7437           0.0        0.0         5.0          0.0  ...   \n",
       "    3214           0.0        0.0         5.0          1.0  ...   \n",
       "    6271           0.0        1.0         0.0          1.0  ...   \n",
       "    7265           0.0        0.0        10.0          0.0  ...   \n",
       "    1833           0.0        0.0         9.0          1.0  ...   \n",
       "    \n",
       "          stalk-surface-below-ring  stalk-color-above-ring  \\\n",
       "    6373                       1.0                     6.0   \n",
       "    4331                       3.0                     7.0   \n",
       "    6496                       1.0                     7.0   \n",
       "    91                         2.0                     7.0   \n",
       "    4543                       1.0                     6.0   \n",
       "    ...                        ...                     ...   \n",
       "    7437                       2.0                     5.0   \n",
       "    3214                       2.0                     7.0   \n",
       "    6271                       2.0                     6.0   \n",
       "    7265                       3.0                     1.0   \n",
       "    1833                       2.0                     6.0   \n",
       "    \n",
       "          stalk-color-below-ring  veil-type  veil-color  ring-number  ring-type  \\\n",
       "    6373                     6.0        0.0         2.0          1.0        0.0   \n",
       "    4331                     4.0        0.0         2.0          1.0        0.0   \n",
       "    6496                     6.0        0.0         2.0          1.0        0.0   \n",
       "    91                       7.0        0.0         2.0          1.0        4.0   \n",
       "    4543                     6.0        0.0         2.0          1.0        2.0   \n",
       "    ...                      ...        ...         ...          ...        ...   \n",
       "    7437                     5.0        0.0         1.0          1.0        4.0   \n",
       "    3214                     3.0        0.0         2.0          1.0        4.0   \n",
       "    6271                     7.0        0.0         2.0          1.0        0.0   \n",
       "    7265                     1.0        0.0         2.0          0.0        3.0   \n",
       "    1833                     7.0        0.0         2.0          1.0        4.0   \n",
       "    \n",
       "          spore-print-color  population  habitat  \n",
       "    6373                7.0         4.0      0.0  \n",
       "    4331                7.0         4.0      0.0  \n",
       "    6496                7.0         4.0      0.0  \n",
       "    91                  2.0         3.0      1.0  \n",
       "    4543                1.0         4.0      0.0  \n",
       "    ...                 ...         ...      ...  \n",
       "    7437                4.0         4.0      2.0  \n",
       "    3214                2.0         4.0      0.0  \n",
       "    6271                7.0         4.0      0.0  \n",
       "    7265                7.0         1.0      0.0  \n",
       "    1833                2.0         4.0      0.0  \n",
       "    \n",
       "    [6499 rows x 21 columns],\n",
       "          cap-shape  cap-surface  cap-color  bruises  odor  gill-attachment  \\\n",
       "    5163        5.0          3.0        2.0      1.0   5.0              1.0   \n",
       "    3215        2.0          0.0        3.0      1.0   5.0              1.0   \n",
       "    640         0.0          3.0        9.0      1.0   3.0              1.0   \n",
       "    4569        5.0          0.0        9.0      0.0   2.0              1.0   \n",
       "    1672        2.0          3.0        4.0      1.0   3.0              1.0   \n",
       "    ...         ...          ...        ...      ...   ...              ...   \n",
       "    995         2.0          2.0        8.0      0.0   5.0              1.0   \n",
       "    1769        5.0          3.0        9.0      1.0   0.0              1.0   \n",
       "    5165        2.0          2.0        8.0      1.0   2.0              1.0   \n",
       "    3893        2.0          3.0        3.0      1.0   5.0              1.0   \n",
       "    7304        3.0          3.0        2.0      0.0   7.0              1.0   \n",
       "    \n",
       "          gill-spacing  gill-size  gill-color  stalk-shape  ...  \\\n",
       "    5163           0.0        0.0        10.0          0.0  ...   \n",
       "    3215           0.0        0.0         9.0          1.0  ...   \n",
       "    640            0.0        0.0        10.0          0.0  ...   \n",
       "    4569           0.0        0.0         2.0          0.0  ...   \n",
       "    1672           0.0        0.0         5.0          0.0  ...   \n",
       "    ...            ...        ...         ...          ...  ...   \n",
       "    995            1.0        0.0         5.0          1.0  ...   \n",
       "    1769           0.0        0.0         7.0          0.0  ...   \n",
       "    5165           0.0        0.0         7.0          1.0  ...   \n",
       "    3893           0.0        0.0         7.0          1.0  ...   \n",
       "    7304           0.0        1.0         0.0          1.0  ...   \n",
       "    \n",
       "          stalk-surface-below-ring  stalk-color-above-ring  \\\n",
       "    5163                       2.0                     7.0   \n",
       "    3215                       2.0                     7.0   \n",
       "    640                        2.0                     7.0   \n",
       "    4569                       1.0                     6.0   \n",
       "    1672                       3.0                     7.0   \n",
       "    ...                        ...                     ...   \n",
       "    995                        0.0                     7.0   \n",
       "    1769                       3.0                     7.0   \n",
       "    5165                       2.0                     7.0   \n",
       "    3893                       2.0                     3.0   \n",
       "    7304                       2.0                     7.0   \n",
       "    \n",
       "          stalk-color-below-ring  veil-type  veil-color  ring-number  ring-type  \\\n",
       "    5163                     7.0        0.0         2.0          2.0        0.0   \n",
       "    3215                     6.0        0.0         2.0          1.0        4.0   \n",
       "    640                      7.0        0.0         2.0          1.0        4.0   \n",
       "    4569                     6.0        0.0         2.0          1.0        2.0   \n",
       "    1672                     7.0        0.0         2.0          1.0        4.0   \n",
       "    ...                      ...        ...         ...          ...        ...   \n",
       "    995                      7.0        0.0         2.0          1.0        0.0   \n",
       "    1769                     7.0        0.0         2.0          1.0        4.0   \n",
       "    5165                     7.0        0.0         2.0          1.0        4.0   \n",
       "    3893                     7.0        0.0         2.0          1.0        4.0   \n",
       "    7304                     7.0        0.0         2.0          1.0        0.0   \n",
       "    \n",
       "          spore-print-color  population  habitat  \n",
       "    5163                7.0         1.0      6.0  \n",
       "    3215                3.0         4.0      0.0  \n",
       "    640                 2.0         2.0      3.0  \n",
       "    4569                1.0         5.0      4.0  \n",
       "    1672                3.0         5.0      4.0  \n",
       "    ...                 ...         ...      ...  \n",
       "    995                 2.0         0.0      1.0  \n",
       "    1769                3.0         5.0      1.0  \n",
       "    5165                1.0         3.0      1.0  \n",
       "    3893                3.0         4.0      0.0  \n",
       "    7304                7.0         4.0      2.0  \n",
       "    \n",
       "    [1625 rows x 21 columns],\n",
       "    6373    1.0\n",
       "    4331    1.0\n",
       "    6496    1.0\n",
       "    91      0.0\n",
       "    4543    1.0\n",
       "           ... \n",
       "    7437    0.0\n",
       "    3214    0.0\n",
       "    6271    1.0\n",
       "    7265    1.0\n",
       "    1833    0.0\n",
       "    Name: poisonous, Length: 6499, dtype: float64,\n",
       "    5163    0.0\n",
       "    3215    0.0\n",
       "    640     0.0\n",
       "    4569    1.0\n",
       "    1672    0.0\n",
       "           ... \n",
       "    995     0.0\n",
       "    1769    0.0\n",
       "    5165    1.0\n",
       "    3893    0.0\n",
       "    7304    1.0\n",
       "    Name: poisonous, Length: 1625, dtype: float64)},\n",
       "  42: {0.2: (      cap-shape  cap-surface  cap-color  bruises  odor  gill-attachment  \\\n",
       "    7108        3.0          3.0        2.0      0.0   2.0              1.0   \n",
       "    7021        2.0          2.0        2.0      0.0   7.0              1.0   \n",
       "    3136        2.0          0.0        2.0      1.0   5.0              1.0   \n",
       "    3659        2.0          3.0        4.0      1.0   5.0              1.0   \n",
       "    5246        5.0          3.0        9.0      0.0   2.0              1.0   \n",
       "    ...         ...          ...        ...      ...   ...              ...   \n",
       "    6981        3.0          2.0        2.0      0.0   2.0              1.0   \n",
       "    4762        5.0          3.0        9.0      0.0   2.0              1.0   \n",
       "    1357        2.0          0.0        8.0      0.0   5.0              1.0   \n",
       "    2775        5.0          0.0        2.0      1.0   5.0              1.0   \n",
       "    4837        5.0          0.0        9.0      0.0   2.0              1.0   \n",
       "    \n",
       "          gill-spacing  gill-size  gill-color  stalk-shape  ...  \\\n",
       "    7108           0.0        1.0         0.0          1.0  ...   \n",
       "    7021           0.0        1.0         0.0          1.0  ...   \n",
       "    3136           0.0        0.0         7.0          1.0  ...   \n",
       "    3659           0.0        0.0         9.0          1.0  ...   \n",
       "    5246           0.0        0.0         3.0          0.0  ...   \n",
       "    ...            ...        ...         ...          ...  ...   \n",
       "    6981           0.0        1.0         0.0          1.0  ...   \n",
       "    4762           0.0        0.0         7.0          0.0  ...   \n",
       "    1357           1.0        0.0         7.0          1.0  ...   \n",
       "    2775           0.0        0.0         7.0          1.0  ...   \n",
       "    4837           0.0        0.0         2.0          0.0  ...   \n",
       "    \n",
       "          stalk-surface-below-ring  stalk-color-above-ring  \\\n",
       "    7108                       1.0                     6.0   \n",
       "    7021                       1.0                     6.0   \n",
       "    3136                       2.0                     3.0   \n",
       "    3659                       2.0                     3.0   \n",
       "    5246                       1.0                     6.0   \n",
       "    ...                        ...                     ...   \n",
       "    6981                       2.0                     7.0   \n",
       "    4762                       1.0                     0.0   \n",
       "    1357                       2.0                     7.0   \n",
       "    2775                       2.0                     3.0   \n",
       "    4837                       1.0                     4.0   \n",
       "    \n",
       "          stalk-color-below-ring  veil-type  veil-color  ring-number  ring-type  \\\n",
       "    7108                     7.0        0.0         2.0          1.0        0.0   \n",
       "    7021                     7.0        0.0         2.0          1.0        0.0   \n",
       "    3136                     7.0        0.0         2.0          1.0        4.0   \n",
       "    3659                     6.0        0.0         2.0          1.0        4.0   \n",
       "    5246                     0.0        0.0         2.0          1.0        2.0   \n",
       "    ...                      ...        ...         ...          ...        ...   \n",
       "    6981                     7.0        0.0         2.0          1.0        0.0   \n",
       "    4762                     0.0        0.0         2.0          1.0        2.0   \n",
       "    1357                     7.0        0.0         2.0          1.0        0.0   \n",
       "    2775                     6.0        0.0         2.0          1.0        4.0   \n",
       "    4837                     0.0        0.0         2.0          1.0        2.0   \n",
       "    \n",
       "          spore-print-color  population  habitat  \n",
       "    7108                7.0         4.0      0.0  \n",
       "    7021                7.0         4.0      0.0  \n",
       "    3136                2.0         4.0      0.0  \n",
       "    3659                3.0         4.0      0.0  \n",
       "    5246                1.0         5.0      0.0  \n",
       "    ...                 ...         ...      ...  \n",
       "    6981                7.0         4.0      4.0  \n",
       "    4762                1.0         5.0      0.0  \n",
       "    1357                2.0         0.0      1.0  \n",
       "    2775                3.0         5.0      0.0  \n",
       "    4837                1.0         4.0      4.0  \n",
       "    \n",
       "    [1624 rows x 21 columns],\n",
       "          cap-shape  cap-surface  cap-color  bruises  odor  gill-attachment  \\\n",
       "    6508        5.0          3.0        2.0      0.0   8.0              1.0   \n",
       "    93          5.0          3.0        9.0      1.0   3.0              1.0   \n",
       "    8102        5.0          2.0        4.0      0.0   5.0              0.0   \n",
       "    4860        2.0          2.0        0.0      1.0   5.0              1.0   \n",
       "    4588        2.0          3.0        3.0      0.0   2.0              1.0   \n",
       "    ...         ...          ...        ...      ...   ...              ...   \n",
       "    4518        5.0          3.0        3.0      0.0   2.0              1.0   \n",
       "    1807        5.0          0.0        3.0      1.0   5.0              1.0   \n",
       "    4491        2.0          0.0        1.0      0.0   5.0              1.0   \n",
       "    3062        5.0          0.0        3.0      0.0   2.0              1.0   \n",
       "    6516        5.0          2.0        4.0      0.0   8.0              1.0   \n",
       "    \n",
       "          gill-spacing  gill-size  gill-color  stalk-shape  ...  \\\n",
       "    6508           0.0        1.0         0.0          1.0  ...   \n",
       "    93             0.0        0.0         2.0          0.0  ...   \n",
       "    8102           0.0        0.0        11.0          0.0  ...   \n",
       "    4860           0.0        0.0        10.0          0.0  ...   \n",
       "    4588           0.0        0.0         3.0          0.0  ...   \n",
       "    ...            ...        ...         ...          ...  ...   \n",
       "    4518           0.0        0.0         2.0          0.0  ...   \n",
       "    1807           0.0        0.0         9.0          1.0  ...   \n",
       "    4491           1.0        1.0        10.0          0.0  ...   \n",
       "    3062           0.0        0.0         2.0          0.0  ...   \n",
       "    6516           0.0        1.0         0.0          1.0  ...   \n",
       "    \n",
       "          stalk-surface-below-ring  stalk-color-above-ring  \\\n",
       "    6508                       2.0                     7.0   \n",
       "    93                         2.0                     7.0   \n",
       "    8102                       2.0                     5.0   \n",
       "    4860                       2.0                     2.0   \n",
       "    4588                       1.0                     6.0   \n",
       "    ...                        ...                     ...   \n",
       "    4518                       1.0                     0.0   \n",
       "    1807                       2.0                     6.0   \n",
       "    4491                       0.0                     7.0   \n",
       "    3062                       1.0                     0.0   \n",
       "    6516                       1.0                     7.0   \n",
       "    \n",
       "          stalk-color-below-ring  veil-type  veil-color  ring-number  ring-type  \\\n",
       "    6508                     7.0        0.0         2.0          1.0        0.0   \n",
       "    93                       7.0        0.0         2.0          1.0        4.0   \n",
       "    8102                     5.0        0.0         0.0          1.0        4.0   \n",
       "    4860                     7.0        0.0         2.0          2.0        0.0   \n",
       "    4588                     4.0        0.0         2.0          1.0        2.0   \n",
       "    ...                      ...        ...         ...          ...        ...   \n",
       "    4518                     4.0        0.0         2.0          1.0        2.0   \n",
       "    1807                     6.0        0.0         2.0          1.0        4.0   \n",
       "    4491                     4.0        0.0         2.0          1.0        0.0   \n",
       "    3062                     0.0        0.0         2.0          1.0        2.0   \n",
       "    6516                     7.0        0.0         2.0          1.0        0.0   \n",
       "    \n",
       "          spore-print-color  population  habitat  \n",
       "    6508                7.0         4.0      0.0  \n",
       "    93                  2.0         2.0      3.0  \n",
       "    8102                3.0         1.0      2.0  \n",
       "    4860                7.0         1.0      6.0  \n",
       "    4588                1.0         4.0      0.0  \n",
       "    ...                 ...         ...      ...  \n",
       "    4518                1.0         4.0      0.0  \n",
       "    1807                3.0         5.0      0.0  \n",
       "    4491                7.0         4.0      2.0  \n",
       "    3062                1.0         4.0      4.0  \n",
       "    6516                7.0         4.0      2.0  \n",
       "    \n",
       "    [6500 rows x 21 columns],\n",
       "    7108    1.0\n",
       "    7021    1.0\n",
       "    3136    0.0\n",
       "    3659    0.0\n",
       "    5246    1.0\n",
       "           ... \n",
       "    6981    1.0\n",
       "    4762    1.0\n",
       "    1357    0.0\n",
       "    2775    0.0\n",
       "    4837    1.0\n",
       "    Name: poisonous, Length: 1624, dtype: float64,\n",
       "    6508    1.0\n",
       "    93      0.0\n",
       "    8102    0.0\n",
       "    4860    0.0\n",
       "    4588    1.0\n",
       "           ... \n",
       "    4518    1.0\n",
       "    1807    0.0\n",
       "    4491    0.0\n",
       "    3062    1.0\n",
       "    6516    1.0\n",
       "    Name: poisonous, Length: 6500, dtype: float64),\n",
       "   0.5: (      cap-shape  cap-surface  cap-color  bruises  odor  gill-attachment  \\\n",
       "    6232        5.0          3.0        2.0      0.0   8.0              1.0   \n",
       "    2655        2.0          0.0        4.0      1.0   5.0              1.0   \n",
       "    2469        5.0          3.0        3.0      1.0   5.0              1.0   \n",
       "    41          5.0          3.0        9.0      1.0   3.0              1.0   \n",
       "    6794        2.0          3.0        2.0      0.0   8.0              1.0   \n",
       "    ...         ...          ...        ...      ...   ...              ...   \n",
       "    5091        5.0          3.0        3.0      0.0   2.0              1.0   \n",
       "    5386        5.0          3.0        4.0      0.0   5.0              1.0   \n",
       "    1357        2.0          0.0        8.0      0.0   5.0              1.0   \n",
       "    7877        5.0          2.0        4.0      0.0   7.0              1.0   \n",
       "    5995        5.0          3.0        4.0      0.0   2.0              1.0   \n",
       "    \n",
       "          gill-spacing  gill-size  gill-color  stalk-shape  ...  \\\n",
       "    6232           0.0        1.0         0.0          1.0  ...   \n",
       "    2655           0.0        0.0        10.0          1.0  ...   \n",
       "    2469           0.0        0.0        10.0          1.0  ...   \n",
       "    41             0.0        0.0         5.0          0.0  ...   \n",
       "    6794           0.0        1.0         0.0          1.0  ...   \n",
       "    ...            ...        ...         ...          ...  ...   \n",
       "    5091           0.0        0.0         7.0          0.0  ...   \n",
       "    5386           1.0        1.0        10.0          0.0  ...   \n",
       "    1357           1.0        0.0         7.0          1.0  ...   \n",
       "    7877           0.0        1.0         0.0          1.0  ...   \n",
       "    5995           0.0        1.0         0.0          1.0  ...   \n",
       "    \n",
       "          stalk-surface-below-ring  stalk-color-above-ring  \\\n",
       "    6232                       2.0                     7.0   \n",
       "    2655                       2.0                     7.0   \n",
       "    2469                       2.0                     3.0   \n",
       "    41                         3.0                     7.0   \n",
       "    6794                       1.0                     6.0   \n",
       "    ...                        ...                     ...   \n",
       "    5091                       1.0                     6.0   \n",
       "    5386                       0.0                     7.0   \n",
       "    1357                       2.0                     7.0   \n",
       "    7877                       1.0                     6.0   \n",
       "    5995                       2.0                     7.0   \n",
       "    \n",
       "          stalk-color-below-ring  veil-type  veil-color  ring-number  ring-type  \\\n",
       "    6232                     6.0        0.0         2.0          1.0        0.0   \n",
       "    2655                     7.0        0.0         2.0          1.0        4.0   \n",
       "    2469                     6.0        0.0         2.0          1.0        4.0   \n",
       "    41                       7.0        0.0         2.0          1.0        4.0   \n",
       "    6794                     7.0        0.0         2.0          1.0        0.0   \n",
       "    ...                      ...        ...         ...          ...        ...   \n",
       "    5091                     0.0        0.0         2.0          1.0        2.0   \n",
       "    5386                     4.0        0.0         2.0          1.0        0.0   \n",
       "    1357                     7.0        0.0         2.0          1.0        0.0   \n",
       "    7877                     7.0        0.0         2.0          1.0        0.0   \n",
       "    5995                     7.0        0.0         2.0          1.0        0.0   \n",
       "    \n",
       "          spore-print-color  population  habitat  \n",
       "    6232                7.0         4.0      2.0  \n",
       "    2655                2.0         4.0      0.0  \n",
       "    2469                2.0         4.0      0.0  \n",
       "    41                  2.0         5.0      4.0  \n",
       "    6794                7.0         4.0      2.0  \n",
       "    ...                 ...         ...      ...  \n",
       "    5091                1.0         4.0      4.0  \n",
       "    5386                7.0         4.0      2.0  \n",
       "    1357                2.0         0.0      1.0  \n",
       "    7877                7.0         4.0      2.0  \n",
       "    5995                7.0         4.0      0.0  \n",
       "    \n",
       "    [4062 rows x 21 columns],\n",
       "          cap-shape  cap-surface  cap-color  bruises  odor  gill-attachment  \\\n",
       "    1674        2.0          2.0        4.0      0.0   5.0              1.0   \n",
       "    6669        5.0          2.0        2.0      0.0   7.0              1.0   \n",
       "    5148        2.0          0.0        4.0      0.0   5.0              1.0   \n",
       "    5800        5.0          3.0        9.0      0.0   5.0              1.0   \n",
       "    490         2.0          0.0        9.0      1.0   0.0              1.0   \n",
       "    ...         ...          ...        ...      ...   ...              ...   \n",
       "    1095        2.0          3.0        4.0      1.0   6.0              1.0   \n",
       "    4827        2.0          3.0        9.0      0.0   2.0              1.0   \n",
       "    3631        5.0          0.0        2.0      1.0   5.0              1.0   \n",
       "    1261        2.0          3.0        4.0      1.0   6.0              1.0   \n",
       "    1009        5.0          2.0        8.0      1.0   3.0              1.0   \n",
       "    \n",
       "          gill-spacing  gill-size  gill-color  stalk-shape  ...  \\\n",
       "    1674           1.0        0.0         7.0          1.0  ...   \n",
       "    6669           0.0        1.0         0.0          1.0  ...   \n",
       "    5148           1.0        1.0        10.0          0.0  ...   \n",
       "    5800           0.0        1.0        10.0          0.0  ...   \n",
       "    490            1.0        1.0         5.0          1.0  ...   \n",
       "    ...            ...        ...         ...          ...  ...   \n",
       "    1095           0.0        1.0         5.0          0.0  ...   \n",
       "    4827           0.0        0.0         7.0          0.0  ...   \n",
       "    3631           0.0        0.0        10.0          1.0  ...   \n",
       "    1261           0.0        1.0        10.0          0.0  ...   \n",
       "    1009           0.0        0.0         4.0          0.0  ...   \n",
       "    \n",
       "          stalk-surface-below-ring  stalk-color-above-ring  \\\n",
       "    1674                       2.0                     7.0   \n",
       "    6669                       2.0                     7.0   \n",
       "    5148                       0.0                     7.0   \n",
       "    5800                       3.0                     7.0   \n",
       "    490                        2.0                     7.0   \n",
       "    ...                        ...                     ...   \n",
       "    1095                       2.0                     7.0   \n",
       "    4827                       1.0                     4.0   \n",
       "    3631                       2.0                     3.0   \n",
       "    1261                       2.0                     7.0   \n",
       "    1009                       2.0                     7.0   \n",
       "    \n",
       "          stalk-color-below-ring  veil-type  veil-color  ring-number  ring-type  \\\n",
       "    1674                     7.0        0.0         2.0          1.0        0.0   \n",
       "    6669                     7.0        0.0         2.0          1.0        0.0   \n",
       "    5148                     4.0        0.0         2.0          1.0        0.0   \n",
       "    5800                     8.0        0.0         2.0          1.0        0.0   \n",
       "    490                      7.0        0.0         2.0          1.0        4.0   \n",
       "    ...                      ...        ...         ...          ...        ...   \n",
       "    1095                     7.0        0.0         2.0          1.0        4.0   \n",
       "    4827                     4.0        0.0         2.0          1.0        2.0   \n",
       "    3631                     3.0        0.0         2.0          1.0        4.0   \n",
       "    1261                     7.0        0.0         2.0          1.0        4.0   \n",
       "    1009                     7.0        0.0         2.0          1.0        4.0   \n",
       "    \n",
       "          spore-print-color  population  habitat  \n",
       "    1674                2.0         3.0      1.0  \n",
       "    6669                7.0         4.0      2.0  \n",
       "    5148                7.0         4.0      2.0  \n",
       "    5800                7.0         4.0      0.0  \n",
       "    490                 6.0         4.0      0.0  \n",
       "    ...                 ...         ...      ...  \n",
       "    1095                2.0         4.0      5.0  \n",
       "    4827                1.0         4.0      0.0  \n",
       "    3631                2.0         5.0      0.0  \n",
       "    1261                2.0         4.0      1.0  \n",
       "    1009                3.0         3.0      1.0  \n",
       "    \n",
       "    [4062 rows x 21 columns],\n",
       "    6232    1.0\n",
       "    2655    0.0\n",
       "    2469    0.0\n",
       "    41      0.0\n",
       "    6794    1.0\n",
       "           ... \n",
       "    5091    1.0\n",
       "    5386    0.0\n",
       "    1357    0.0\n",
       "    7877    1.0\n",
       "    5995    1.0\n",
       "    Name: poisonous, Length: 4062, dtype: float64,\n",
       "    1674    0.0\n",
       "    6669    1.0\n",
       "    5148    0.0\n",
       "    5800    1.0\n",
       "    490     0.0\n",
       "           ... \n",
       "    1095    1.0\n",
       "    4827    1.0\n",
       "    3631    0.0\n",
       "    1261    1.0\n",
       "    1009    0.0\n",
       "    Name: poisonous, Length: 4062, dtype: float64),\n",
       "   0.8: (      cap-shape  cap-surface  cap-color  bruises  odor  gill-attachment  \\\n",
       "    5249        2.0          3.0        9.0      0.0   2.0              1.0   \n",
       "    5781        5.0          2.0        5.0      1.0   5.0              1.0   \n",
       "    7586        0.0          2.0        3.0      0.0   5.0              1.0   \n",
       "    6181        2.0          2.0        4.0      0.0   7.0              1.0   \n",
       "    7338        3.0          3.0        4.0      0.0   2.0              1.0   \n",
       "    ...         ...          ...        ...      ...   ...              ...   \n",
       "    6150        5.0          2.0        4.0      0.0   7.0              1.0   \n",
       "    5386        5.0          3.0        4.0      0.0   5.0              1.0   \n",
       "    1357        2.0          0.0        8.0      0.0   5.0              1.0   \n",
       "    2977        5.0          0.0        3.0      1.0   5.0              1.0   \n",
       "    2411        2.0          0.0        4.0      1.0   5.0              1.0   \n",
       "    \n",
       "          gill-spacing  gill-size  gill-color  stalk-shape  ...  \\\n",
       "    5249           0.0        0.0         2.0          0.0  ...   \n",
       "    5781           0.0        0.0         1.0          0.0  ...   \n",
       "    7586           1.0        0.0        10.0          0.0  ...   \n",
       "    6181           0.0        1.0         0.0          1.0  ...   \n",
       "    7338           0.0        1.0         0.0          1.0  ...   \n",
       "    ...            ...        ...         ...          ...  ...   \n",
       "    6150           0.0        1.0         0.0          1.0  ...   \n",
       "    5386           1.0        1.0        10.0          0.0  ...   \n",
       "    1357           1.0        0.0         7.0          1.0  ...   \n",
       "    2977           0.0        0.0        10.0          1.0  ...   \n",
       "    2411           0.0        0.0         7.0          1.0  ...   \n",
       "    \n",
       "          stalk-surface-below-ring  stalk-color-above-ring  \\\n",
       "    5249                       1.0                     6.0   \n",
       "    5781                       2.0                     2.0   \n",
       "    7586                       2.0                     7.0   \n",
       "    6181                       1.0                     6.0   \n",
       "    7338                       1.0                     6.0   \n",
       "    ...                        ...                     ...   \n",
       "    6150                       2.0                     6.0   \n",
       "    5386                       0.0                     7.0   \n",
       "    1357                       2.0                     7.0   \n",
       "    2977                       2.0                     3.0   \n",
       "    2411                       2.0                     7.0   \n",
       "    \n",
       "          stalk-color-below-ring  veil-type  veil-color  ring-number  ring-type  \\\n",
       "    5249                     0.0        0.0         2.0          1.0        2.0   \n",
       "    5781                     7.0        0.0         2.0          2.0        0.0   \n",
       "    7586                     7.0        0.0         2.0          2.0        4.0   \n",
       "    6181                     7.0        0.0         2.0          1.0        0.0   \n",
       "    7338                     6.0        0.0         2.0          1.0        0.0   \n",
       "    ...                      ...        ...         ...          ...        ...   \n",
       "    6150                     6.0        0.0         2.0          1.0        0.0   \n",
       "    5386                     4.0        0.0         2.0          1.0        0.0   \n",
       "    1357                     7.0        0.0         2.0          1.0        0.0   \n",
       "    2977                     6.0        0.0         2.0          1.0        4.0   \n",
       "    2411                     6.0        0.0         2.0          1.0        4.0   \n",
       "    \n",
       "          spore-print-color  population  habitat  \n",
       "    5249                1.0         5.0      1.0  \n",
       "    5781                7.0         1.0      6.0  \n",
       "    7586                7.0         3.0      1.0  \n",
       "    6181                7.0         4.0      0.0  \n",
       "    7338                7.0         4.0      4.0  \n",
       "    ...                 ...         ...      ...  \n",
       "    6150                7.0         4.0      0.0  \n",
       "    5386                7.0         4.0      2.0  \n",
       "    1357                2.0         0.0      1.0  \n",
       "    2977                3.0         5.0      0.0  \n",
       "    2411                3.0         4.0      0.0  \n",
       "    \n",
       "    [6499 rows x 21 columns],\n",
       "          cap-shape  cap-surface  cap-color  bruises  odor  gill-attachment  \\\n",
       "    4632        5.0          3.0        3.0      0.0   2.0              1.0   \n",
       "    3444        5.0          2.0        8.0      0.0   1.0              1.0   \n",
       "    1209        5.0          0.0        8.0      0.0   5.0              1.0   \n",
       "    6880        2.0          2.0        2.0      0.0   2.0              1.0   \n",
       "    4542        5.0          0.0        9.0      0.0   2.0              1.0   \n",
       "    ...         ...          ...        ...      ...   ...              ...   \n",
       "    7554        3.0          2.0        4.0      0.0   7.0              1.0   \n",
       "    3198        2.0          0.0        3.0      1.0   5.0              1.0   \n",
       "    3850        5.0          0.0        2.0      1.0   5.0              1.0   \n",
       "    1965        2.0          2.0        4.0      0.0   5.0              1.0   \n",
       "    5718        2.0          2.0        3.0      1.0   2.0              1.0   \n",
       "    \n",
       "          gill-spacing  gill-size  gill-color  stalk-shape  ...  \\\n",
       "    4632           0.0        0.0         7.0          0.0  ...   \n",
       "    3444           0.0        1.0         9.0          0.0  ...   \n",
       "    1209           1.0        0.0         7.0          1.0  ...   \n",
       "    6880           0.0        1.0         0.0          1.0  ...   \n",
       "    4542           0.0        0.0         2.0          0.0  ...   \n",
       "    ...            ...        ...         ...          ...  ...   \n",
       "    7554           0.0        1.0         0.0          1.0  ...   \n",
       "    3198           0.0        0.0        10.0          1.0  ...   \n",
       "    3850           0.0        0.0         5.0          1.0  ...   \n",
       "    1965           1.0        0.0         7.0          1.0  ...   \n",
       "    5718           0.0        0.0         7.0          1.0  ...   \n",
       "    \n",
       "          stalk-surface-below-ring  stalk-color-above-ring  \\\n",
       "    4632                       1.0                     6.0   \n",
       "    3444                       2.0                     7.0   \n",
       "    1209                       2.0                     7.0   \n",
       "    6880                       2.0                     7.0   \n",
       "    4542                       1.0                     6.0   \n",
       "    ...                        ...                     ...   \n",
       "    7554                       2.0                     6.0   \n",
       "    3198                       2.0                     7.0   \n",
       "    3850                       2.0                     7.0   \n",
       "    1965                       2.0                     7.0   \n",
       "    5718                       2.0                     7.0   \n",
       "    \n",
       "          stalk-color-below-ring  veil-type  veil-color  ring-number  ring-type  \\\n",
       "    4632                     4.0        0.0         2.0          1.0        2.0   \n",
       "    3444                     7.0        0.0         2.0          1.0        4.0   \n",
       "    1209                     7.0        0.0         2.0          1.0        0.0   \n",
       "    6880                     7.0        0.0         2.0          1.0        0.0   \n",
       "    4542                     4.0        0.0         2.0          1.0        2.0   \n",
       "    ...                      ...        ...         ...          ...        ...   \n",
       "    7554                     7.0        0.0         2.0          1.0        0.0   \n",
       "    3198                     6.0        0.0         2.0          1.0        4.0   \n",
       "    3850                     7.0        0.0         2.0          1.0        4.0   \n",
       "    1965                     7.0        0.0         2.0          1.0        0.0   \n",
       "    5718                     7.0        0.0         2.0          1.0        4.0   \n",
       "    \n",
       "          spore-print-color  population  habitat  \n",
       "    4632                1.0         5.0      0.0  \n",
       "    3444                3.0         3.0      0.0  \n",
       "    1209                3.0         3.0      1.0  \n",
       "    6880                7.0         4.0      4.0  \n",
       "    4542                1.0         5.0      1.0  \n",
       "    ...                 ...         ...      ...  \n",
       "    7554                7.0         4.0      2.0  \n",
       "    3198                3.0         4.0      0.0  \n",
       "    3850                3.0         5.0      0.0  \n",
       "    1965                2.0         3.0      1.0  \n",
       "    5718                1.0         3.0      1.0  \n",
       "    \n",
       "    [1625 rows x 21 columns],\n",
       "    5249    1.0\n",
       "    5781    0.0\n",
       "    7586    0.0\n",
       "    6181    1.0\n",
       "    7338    1.0\n",
       "           ... \n",
       "    6150    1.0\n",
       "    5386    0.0\n",
       "    1357    0.0\n",
       "    2977    0.0\n",
       "    2411    0.0\n",
       "    Name: poisonous, Length: 6499, dtype: float64,\n",
       "    4632    1.0\n",
       "    3444    1.0\n",
       "    1209    0.0\n",
       "    6880    1.0\n",
       "    4542    1.0\n",
       "           ... \n",
       "    7554    1.0\n",
       "    3198    0.0\n",
       "    3850    0.0\n",
       "    1965    0.0\n",
       "    5718    1.0\n",
       "    Name: poisonous, Length: 1625, dtype: float64)},\n",
       "  99: {0.2: (      cap-shape  cap-surface  cap-color  bruises  odor  gill-attachment  \\\n",
       "    6084        3.0          3.0        4.0      0.0   8.0              1.0   \n",
       "    7119        3.0          0.0        8.0      0.0   5.0              1.0   \n",
       "    3121        2.0          3.0        3.0      1.0   5.0              1.0   \n",
       "    2074        5.0          2.0        8.0      1.0   6.0              1.0   \n",
       "    8097        3.0          3.0        4.0      0.0   7.0              1.0   \n",
       "    ...         ...          ...        ...      ...   ...              ...   \n",
       "    6790        2.0          3.0        4.0      0.0   2.0              1.0   \n",
       "    2330        2.0          0.0        4.0      1.0   5.0              1.0   \n",
       "    7354        0.0          2.0        8.0      0.0   5.0              1.0   \n",
       "    2575        5.0          3.0        4.0      1.0   5.0              1.0   \n",
       "    1247        5.0          2.0        3.0      0.0   5.0              1.0   \n",
       "    \n",
       "          gill-spacing  gill-size  gill-color  stalk-shape  ...  \\\n",
       "    6084           0.0        1.0         0.0          1.0  ...   \n",
       "    7119           1.0        0.0        10.0          0.0  ...   \n",
       "    3121           0.0        0.0        10.0          1.0  ...   \n",
       "    2074           0.0        1.0         7.0          0.0  ...   \n",
       "    8097           0.0        1.0         0.0          1.0  ...   \n",
       "    ...            ...        ...         ...          ...  ...   \n",
       "    6790           0.0        1.0         0.0          1.0  ...   \n",
       "    2330           0.0        0.0        10.0          1.0  ...   \n",
       "    7354           1.0        0.0         2.0          0.0  ...   \n",
       "    2575           0.0        0.0         5.0          1.0  ...   \n",
       "    1247           1.0        0.0         4.0          1.0  ...   \n",
       "    \n",
       "          stalk-surface-below-ring  stalk-color-above-ring  \\\n",
       "    6084                       2.0                     7.0   \n",
       "    7119                       1.0                     7.0   \n",
       "    3121                       2.0                     3.0   \n",
       "    2074                       2.0                     7.0   \n",
       "    8097                       1.0                     6.0   \n",
       "    ...                        ...                     ...   \n",
       "    6790                       1.0                     7.0   \n",
       "    2330                       2.0                     6.0   \n",
       "    7354                       1.0                     7.0   \n",
       "    2575                       2.0                     7.0   \n",
       "    1247                       2.0                     7.0   \n",
       "    \n",
       "          stalk-color-below-ring  veil-type  veil-color  ring-number  ring-type  \\\n",
       "    6084                     6.0        0.0         2.0          1.0        0.0   \n",
       "    7119                     7.0        0.0         2.0          2.0        4.0   \n",
       "    3121                     7.0        0.0         2.0          1.0        4.0   \n",
       "    2074                     7.0        0.0         2.0          1.0        4.0   \n",
       "    8097                     6.0        0.0         2.0          1.0        0.0   \n",
       "    ...                      ...        ...         ...          ...        ...   \n",
       "    6790                     6.0        0.0         2.0          1.0        0.0   \n",
       "    2330                     3.0        0.0         2.0          1.0        4.0   \n",
       "    7354                     7.0        0.0         2.0          2.0        4.0   \n",
       "    2575                     7.0        0.0         2.0          1.0        4.0   \n",
       "    1247                     7.0        0.0         2.0          1.0        0.0   \n",
       "    \n",
       "          spore-print-color  population  habitat  \n",
       "    6084                7.0         4.0      2.0  \n",
       "    7119                7.0         2.0      1.0  \n",
       "    3121                3.0         5.0      0.0  \n",
       "    2074                3.0         4.0      5.0  \n",
       "    8097                7.0         4.0      2.0  \n",
       "    ...                 ...         ...      ...  \n",
       "    6790                7.0         4.0      4.0  \n",
       "    2330                2.0         4.0      0.0  \n",
       "    7354                7.0         2.0      1.0  \n",
       "    2575                2.0         5.0      0.0  \n",
       "    1247                2.0         0.0      1.0  \n",
       "    \n",
       "    [1624 rows x 21 columns],\n",
       "          cap-shape  cap-surface  cap-color  bruises  odor  gill-attachment  \\\n",
       "    4192        2.0          0.0        3.0      0.0   2.0              1.0   \n",
       "    2024        5.0          0.0        3.0      1.0   5.0              1.0   \n",
       "    4767        2.0          0.0        3.0      0.0   2.0              1.0   \n",
       "    1722        5.0          0.0        4.0      0.0   5.0              1.0   \n",
       "    5443        5.0          3.0        5.0      1.0   5.0              1.0   \n",
       "    ...         ...          ...        ...      ...   ...              ...   \n",
       "    338         5.0          0.0        3.0      0.0   5.0              1.0   \n",
       "    7655        3.0          2.0        4.0      0.0   8.0              1.0   \n",
       "    3516        2.0          3.0        2.0      1.0   5.0              1.0   \n",
       "    130         0.0          2.0        8.0      1.0   3.0              1.0   \n",
       "    2118        5.0          0.0        3.0      1.0   5.0              1.0   \n",
       "    \n",
       "          gill-spacing  gill-size  gill-color  stalk-shape  ...  \\\n",
       "    4192           0.0        0.0         3.0          0.0  ...   \n",
       "    2024           0.0        0.0         9.0          1.0  ...   \n",
       "    4767           0.0        0.0         2.0          0.0  ...   \n",
       "    1722           1.0        0.0         3.0          1.0  ...   \n",
       "    5443           0.0        0.0         1.0          0.0  ...   \n",
       "    ...            ...        ...         ...          ...  ...   \n",
       "    338            0.0        1.0         2.0          0.0  ...   \n",
       "    7655           0.0        1.0         0.0          1.0  ...   \n",
       "    3516           0.0        0.0         9.0          1.0  ...   \n",
       "    130            0.0        0.0        10.0          0.0  ...   \n",
       "    2118           0.0        0.0         5.0          1.0  ...   \n",
       "    \n",
       "          stalk-surface-below-ring  stalk-color-above-ring  \\\n",
       "    4192                       1.0                     0.0   \n",
       "    2024                       2.0                     7.0   \n",
       "    4767                       1.0                     6.0   \n",
       "    1722                       0.0                     7.0   \n",
       "    5443                       2.0                     2.0   \n",
       "    ...                        ...                     ...   \n",
       "    338                        2.0                     7.0   \n",
       "    7655                       1.0                     7.0   \n",
       "    3516                       2.0                     6.0   \n",
       "    130                        2.0                     7.0   \n",
       "    2118                       2.0                     6.0   \n",
       "    \n",
       "          stalk-color-below-ring  veil-type  veil-color  ring-number  ring-type  \\\n",
       "    4192                     0.0        0.0         2.0          1.0        2.0   \n",
       "    2024                     7.0        0.0         2.0          1.0        4.0   \n",
       "    4767                     0.0        0.0         2.0          1.0        2.0   \n",
       "    1722                     7.0        0.0         2.0          1.0        0.0   \n",
       "    5443                     2.0        0.0         2.0          2.0        0.0   \n",
       "    ...                      ...        ...         ...          ...        ...   \n",
       "    338                      7.0        0.0         2.0          1.0        4.0   \n",
       "    7655                     6.0        0.0         2.0          1.0        0.0   \n",
       "    3516                     7.0        0.0         2.0          1.0        4.0   \n",
       "    130                      7.0        0.0         2.0          1.0        4.0   \n",
       "    2118                     6.0        0.0         2.0          1.0        4.0   \n",
       "    \n",
       "          spore-print-color  population  habitat  \n",
       "    4192                1.0         5.0      4.0  \n",
       "    2024                3.0         5.0      0.0  \n",
       "    4767                1.0         5.0      4.0  \n",
       "    1722                3.0         0.0      1.0  \n",
       "    5443                7.0         1.0      6.0  \n",
       "    ...                 ...         ...      ...  \n",
       "    338                 3.0         4.0      5.0  \n",
       "    7655                7.0         4.0      4.0  \n",
       "    3516                2.0         4.0      0.0  \n",
       "    130                 3.0         3.0      1.0  \n",
       "    2118                2.0         4.0      0.0  \n",
       "    \n",
       "    [6500 rows x 21 columns],\n",
       "    6084    1.0\n",
       "    7119    0.0\n",
       "    3121    0.0\n",
       "    2074    1.0\n",
       "    8097    1.0\n",
       "           ... \n",
       "    6790    1.0\n",
       "    2330    0.0\n",
       "    7354    0.0\n",
       "    2575    0.0\n",
       "    1247    0.0\n",
       "    Name: poisonous, Length: 1624, dtype: float64,\n",
       "    4192    1.0\n",
       "    2024    0.0\n",
       "    4767    1.0\n",
       "    1722    0.0\n",
       "    5443    0.0\n",
       "           ... \n",
       "    338     0.0\n",
       "    7655    1.0\n",
       "    3516    0.0\n",
       "    130     0.0\n",
       "    2118    0.0\n",
       "    Name: poisonous, Length: 6500, dtype: float64),\n",
       "   0.5: (      cap-shape  cap-surface  cap-color  bruises  odor  gill-attachment  \\\n",
       "    3913        2.0          0.0        9.0      0.0   2.0              1.0   \n",
       "    6810        2.0          2.0        2.0      0.0   2.0              1.0   \n",
       "    4445        2.0          0.0        3.0      0.0   2.0              1.0   \n",
       "    7126        3.0          2.0        2.0      0.0   8.0              1.0   \n",
       "    1031        5.0          3.0        4.0      1.0   6.0              1.0   \n",
       "    ...         ...          ...        ...      ...   ...              ...   \n",
       "    7456        2.0          3.0        2.0      0.0   2.0              1.0   \n",
       "    5108        5.0          2.0        3.0      1.0   2.0              1.0   \n",
       "    7354        0.0          2.0        8.0      0.0   5.0              1.0   \n",
       "    5821        2.0          3.0        3.0      0.0   2.0              1.0   \n",
       "    3166        5.0          0.0        3.0      0.0   2.0              1.0   \n",
       "    \n",
       "          gill-spacing  gill-size  gill-color  stalk-shape  ...  \\\n",
       "    3913           0.0        0.0         2.0          0.0  ...   \n",
       "    6810           0.0        1.0         0.0          1.0  ...   \n",
       "    4445           0.0        0.0         2.0          0.0  ...   \n",
       "    7126           0.0        1.0         0.0          1.0  ...   \n",
       "    1031           0.0        1.0         5.0          0.0  ...   \n",
       "    ...            ...        ...         ...          ...  ...   \n",
       "    7456           0.0        1.0         0.0          1.0  ...   \n",
       "    5108           0.0        0.0         7.0          1.0  ...   \n",
       "    7354           1.0        0.0         2.0          0.0  ...   \n",
       "    5821           0.0        0.0         3.0          0.0  ...   \n",
       "    3166           0.0        0.0         7.0          0.0  ...   \n",
       "    \n",
       "          stalk-surface-below-ring  stalk-color-above-ring  \\\n",
       "    3913                       1.0                     6.0   \n",
       "    6810                       2.0                     6.0   \n",
       "    4445                       1.0                     0.0   \n",
       "    7126                       1.0                     7.0   \n",
       "    1031                       2.0                     7.0   \n",
       "    ...                        ...                     ...   \n",
       "    7456                       2.0                     7.0   \n",
       "    5108                       2.0                     7.0   \n",
       "    7354                       1.0                     7.0   \n",
       "    5821                       1.0                     6.0   \n",
       "    3166                       1.0                     6.0   \n",
       "    \n",
       "          stalk-color-below-ring  veil-type  veil-color  ring-number  ring-type  \\\n",
       "    3913                     0.0        0.0         2.0          1.0        2.0   \n",
       "    6810                     7.0        0.0         2.0          1.0        0.0   \n",
       "    4445                     4.0        0.0         2.0          1.0        2.0   \n",
       "    7126                     7.0        0.0         2.0          1.0        0.0   \n",
       "    1031                     7.0        0.0         2.0          1.0        4.0   \n",
       "    ...                      ...        ...         ...          ...        ...   \n",
       "    7456                     6.0        0.0         2.0          1.0        0.0   \n",
       "    5108                     7.0        0.0         2.0          1.0        4.0   \n",
       "    7354                     7.0        0.0         2.0          2.0        4.0   \n",
       "    5821                     6.0        0.0         2.0          1.0        2.0   \n",
       "    3166                     6.0        0.0         2.0          1.0        2.0   \n",
       "    \n",
       "          spore-print-color  population  habitat  \n",
       "    3913                1.0         5.0      1.0  \n",
       "    6810                7.0         4.0      2.0  \n",
       "    4445                1.0         5.0      0.0  \n",
       "    7126                7.0         4.0      4.0  \n",
       "    1031                2.0         4.0      1.0  \n",
       "    ...                 ...         ...      ...  \n",
       "    7456                7.0         4.0      0.0  \n",
       "    5108                1.0         4.0      5.0  \n",
       "    7354                7.0         2.0      1.0  \n",
       "    5821                1.0         4.0      4.0  \n",
       "    3166                1.0         4.0      4.0  \n",
       "    \n",
       "    [4062 rows x 21 columns],\n",
       "          cap-shape  cap-surface  cap-color  bruises  odor  gill-attachment  \\\n",
       "    6104        2.0          3.0        4.0      0.0   8.0              1.0   \n",
       "    4179        2.0          3.0        2.0      1.0   5.0              1.0   \n",
       "    4123        2.0          0.0        9.0      0.0   2.0              1.0   \n",
       "    2628        2.0          0.0        3.0      1.0   5.0              1.0   \n",
       "    8023        3.0          2.0        2.0      0.0   8.0              1.0   \n",
       "    ...         ...          ...        ...      ...   ...              ...   \n",
       "    6293        2.0          2.0        2.0      0.0   7.0              1.0   \n",
       "    6133        2.0          3.0        2.0      0.0   8.0              1.0   \n",
       "    5855        0.0          2.0        0.0      1.0   5.0              1.0   \n",
       "    2167        5.0          0.0        3.0      1.0   5.0              1.0   \n",
       "    6602        5.0          2.0        4.0      0.0   7.0              1.0   \n",
       "    \n",
       "          gill-spacing  gill-size  gill-color  stalk-shape  ...  \\\n",
       "    6104           0.0        1.0         0.0          1.0  ...   \n",
       "    4179           0.0        0.0         9.0          1.0  ...   \n",
       "    4123           0.0        0.0         3.0          0.0  ...   \n",
       "    2628           0.0        0.0         5.0          1.0  ...   \n",
       "    8023           0.0        1.0         0.0          1.0  ...   \n",
       "    ...            ...        ...         ...          ...  ...   \n",
       "    6293           0.0        1.0         0.0          1.0  ...   \n",
       "    6133           0.0        1.0         0.0          1.0  ...   \n",
       "    5855           0.0        0.0        10.0          0.0  ...   \n",
       "    2167           0.0        0.0         7.0          1.0  ...   \n",
       "    6602           0.0        1.0         0.0          1.0  ...   \n",
       "    \n",
       "          stalk-surface-below-ring  stalk-color-above-ring  \\\n",
       "    6104                       1.0                     7.0   \n",
       "    4179                       2.0                     6.0   \n",
       "    4123                       1.0                     4.0   \n",
       "    2628                       2.0                     6.0   \n",
       "    8023                       1.0                     7.0   \n",
       "    ...                        ...                     ...   \n",
       "    6293                       2.0                     6.0   \n",
       "    6133                       2.0                     7.0   \n",
       "    5855                       2.0                     7.0   \n",
       "    2167                       2.0                     6.0   \n",
       "    6602                       2.0                     7.0   \n",
       "    \n",
       "          stalk-color-below-ring  veil-type  veil-color  ring-number  ring-type  \\\n",
       "    6104                     7.0        0.0         2.0          1.0        0.0   \n",
       "    4179                     6.0        0.0         2.0          1.0        4.0   \n",
       "    4123                     6.0        0.0         2.0          1.0        2.0   \n",
       "    2628                     6.0        0.0         2.0          1.0        4.0   \n",
       "    8023                     6.0        0.0         2.0          1.0        0.0   \n",
       "    ...                      ...        ...         ...          ...        ...   \n",
       "    6293                     7.0        0.0         2.0          1.0        0.0   \n",
       "    6133                     7.0        0.0         2.0          1.0        0.0   \n",
       "    5855                     7.0        0.0         2.0          2.0        4.0   \n",
       "    2167                     3.0        0.0         2.0          1.0        4.0   \n",
       "    6602                     7.0        0.0         2.0          1.0        0.0   \n",
       "    \n",
       "          spore-print-color  population  habitat  \n",
       "    6104                7.0         4.0      0.0  \n",
       "    4179                2.0         5.0      0.0  \n",
       "    4123                1.0         4.0      1.0  \n",
       "    2628                3.0         4.0      0.0  \n",
       "    8023                7.0         4.0      4.0  \n",
       "    ...                 ...         ...      ...  \n",
       "    6293                7.0         4.0      2.0  \n",
       "    6133                7.0         4.0      4.0  \n",
       "    5855                5.0         4.0      3.0  \n",
       "    2167                2.0         5.0      0.0  \n",
       "    6602                7.0         4.0      4.0  \n",
       "    \n",
       "    [4062 rows x 21 columns],\n",
       "    3913    1.0\n",
       "    6810    1.0\n",
       "    4445    1.0\n",
       "    7126    1.0\n",
       "    1031    1.0\n",
       "           ... \n",
       "    7456    1.0\n",
       "    5108    1.0\n",
       "    7354    0.0\n",
       "    5821    1.0\n",
       "    3166    1.0\n",
       "    Name: poisonous, Length: 4062, dtype: float64,\n",
       "    6104    1.0\n",
       "    4179    0.0\n",
       "    4123    1.0\n",
       "    2628    0.0\n",
       "    8023    1.0\n",
       "           ... \n",
       "    6293    1.0\n",
       "    6133    1.0\n",
       "    5855    1.0\n",
       "    2167    0.0\n",
       "    6602    1.0\n",
       "    Name: poisonous, Length: 4062, dtype: float64),\n",
       "   0.8: (      cap-shape  cap-surface  cap-color  bruises  odor  gill-attachment  \\\n",
       "    6301        3.0          3.0        4.0      0.0   8.0              1.0   \n",
       "    5784        2.0          3.0        9.0      0.0   2.0              1.0   \n",
       "    4050        5.0          0.0        9.0      0.0   2.0              1.0   \n",
       "    4223        5.0          3.0        3.0      0.0   2.0              1.0   \n",
       "    3604        5.0          3.0        3.0      0.0   2.0              1.0   \n",
       "    ...         ...          ...        ...      ...   ...              ...   \n",
       "    4929        5.0          3.0        9.0      0.0   2.0              1.0   \n",
       "    2256        2.0          3.0        4.0      1.0   5.0              1.0   \n",
       "    4512        2.0          0.0        9.0      0.0   2.0              1.0   \n",
       "    7354        0.0          2.0        8.0      0.0   5.0              1.0   \n",
       "    7557        3.0          3.0        2.0      0.0   2.0              1.0   \n",
       "    \n",
       "          gill-spacing  gill-size  gill-color  stalk-shape  ...  \\\n",
       "    6301           0.0        1.0         0.0          1.0  ...   \n",
       "    5784           0.0        0.0         2.0          0.0  ...   \n",
       "    4050           0.0        0.0         7.0          0.0  ...   \n",
       "    4223           0.0        0.0         7.0          0.0  ...   \n",
       "    3604           0.0        0.0         7.0          0.0  ...   \n",
       "    ...            ...        ...         ...          ...  ...   \n",
       "    4929           0.0        0.0         2.0          0.0  ...   \n",
       "    2256           0.0        0.0         9.0          1.0  ...   \n",
       "    4512           0.0        0.0         3.0          0.0  ...   \n",
       "    7354           1.0        0.0         2.0          0.0  ...   \n",
       "    7557           0.0        1.0         0.0          1.0  ...   \n",
       "    \n",
       "          stalk-surface-below-ring  stalk-color-above-ring  \\\n",
       "    6301                       2.0                     6.0   \n",
       "    5784                       1.0                     6.0   \n",
       "    4050                       1.0                     0.0   \n",
       "    4223                       1.0                     4.0   \n",
       "    3604                       1.0                     0.0   \n",
       "    ...                        ...                     ...   \n",
       "    4929                       1.0                     0.0   \n",
       "    2256                       2.0                     7.0   \n",
       "    4512                       1.0                     0.0   \n",
       "    7354                       1.0                     7.0   \n",
       "    7557                       1.0                     6.0   \n",
       "    \n",
       "          stalk-color-below-ring  veil-type  veil-color  ring-number  ring-type  \\\n",
       "    6301                     6.0        0.0         2.0          1.0        0.0   \n",
       "    5784                     6.0        0.0         2.0          1.0        2.0   \n",
       "    4050                     4.0        0.0         2.0          1.0        2.0   \n",
       "    4223                     0.0        0.0         2.0          1.0        2.0   \n",
       "    3604                     4.0        0.0         2.0          1.0        2.0   \n",
       "    ...                      ...        ...         ...          ...        ...   \n",
       "    4929                     0.0        0.0         2.0          1.0        2.0   \n",
       "    2256                     7.0        0.0         2.0          1.0        4.0   \n",
       "    4512                     6.0        0.0         2.0          1.0        2.0   \n",
       "    7354                     7.0        0.0         2.0          2.0        4.0   \n",
       "    7557                     6.0        0.0         2.0          1.0        0.0   \n",
       "    \n",
       "          spore-print-color  population  habitat  \n",
       "    6301                7.0         4.0      4.0  \n",
       "    5784                1.0         5.0      4.0  \n",
       "    4050                1.0         5.0      0.0  \n",
       "    4223                1.0         5.0      4.0  \n",
       "    3604                1.0         4.0      0.0  \n",
       "    ...                 ...         ...      ...  \n",
       "    4929                1.0         5.0      1.0  \n",
       "    2256                3.0         5.0      0.0  \n",
       "    4512                1.0         5.0      4.0  \n",
       "    7354                7.0         2.0      1.0  \n",
       "    7557                7.0         4.0      0.0  \n",
       "    \n",
       "    [6499 rows x 21 columns],\n",
       "          cap-shape  cap-surface  cap-color  bruises  odor  gill-attachment  \\\n",
       "    2592        2.0          0.0        4.0      1.0   5.0              1.0   \n",
       "    5878        5.0          3.0        4.0      0.0   7.0              1.0   \n",
       "    2810        2.0          3.0        2.0      1.0   5.0              1.0   \n",
       "    2946        2.0          0.0        3.0      1.0   5.0              1.0   \n",
       "    5764        2.0          3.0        6.0      0.0   5.0              1.0   \n",
       "    ...         ...          ...        ...      ...   ...              ...   \n",
       "    5120        2.0          2.0        0.0      1.0   2.0              1.0   \n",
       "    6899        2.0          2.0        4.0      0.0   2.0              1.0   \n",
       "    6598        2.0          2.0        2.0      0.0   8.0              1.0   \n",
       "    6515        5.0          2.0        4.0      0.0   2.0              1.0   \n",
       "    3845        5.0          0.0        3.0      0.0   1.0              1.0   \n",
       "    \n",
       "          gill-spacing  gill-size  gill-color  stalk-shape  ...  \\\n",
       "    2592           0.0        0.0         7.0          1.0  ...   \n",
       "    5878           0.0        1.0         0.0          1.0  ...   \n",
       "    2810           0.0        0.0         5.0          1.0  ...   \n",
       "    2946           0.0        0.0         7.0          1.0  ...   \n",
       "    5764           0.0        1.0         9.0          0.0  ...   \n",
       "    ...            ...        ...         ...          ...  ...   \n",
       "    5120           0.0        0.0        10.0          1.0  ...   \n",
       "    6899           0.0        1.0         0.0          1.0  ...   \n",
       "    6598           0.0        1.0         0.0          1.0  ...   \n",
       "    6515           0.0        1.0         0.0          1.0  ...   \n",
       "    3845           1.0        1.0         7.0          0.0  ...   \n",
       "    \n",
       "          stalk-surface-below-ring  stalk-color-above-ring  \\\n",
       "    2592                       2.0                     7.0   \n",
       "    5878                       1.0                     7.0   \n",
       "    2810                       2.0                     7.0   \n",
       "    2946                       2.0                     7.0   \n",
       "    5764                       0.0                     7.0   \n",
       "    ...                        ...                     ...   \n",
       "    5120                       0.0                     7.0   \n",
       "    6899                       2.0                     6.0   \n",
       "    6598                       2.0                     6.0   \n",
       "    6515                       2.0                     7.0   \n",
       "    3845                       2.0                     7.0   \n",
       "    \n",
       "          stalk-color-below-ring  veil-type  veil-color  ring-number  ring-type  \\\n",
       "    2592                     7.0        0.0         2.0          1.0        4.0   \n",
       "    5878                     6.0        0.0         2.0          1.0        0.0   \n",
       "    2810                     7.0        0.0         2.0          1.0        4.0   \n",
       "    2946                     3.0        0.0         2.0          1.0        4.0   \n",
       "    5764                     7.0        0.0         2.0          1.0        1.0   \n",
       "    ...                      ...        ...         ...          ...        ...   \n",
       "    5120                     7.0        0.0         2.0          1.0        4.0   \n",
       "    6899                     7.0        0.0         2.0          1.0        0.0   \n",
       "    6598                     6.0        0.0         2.0          1.0        0.0   \n",
       "    6515                     7.0        0.0         2.0          1.0        0.0   \n",
       "    3845                     7.0        0.0         2.0          1.0        4.0   \n",
       "    \n",
       "          spore-print-color  population  habitat  \n",
       "    2592                2.0         5.0      0.0  \n",
       "    5878                7.0         4.0      2.0  \n",
       "    2810                2.0         4.0      0.0  \n",
       "    2946                2.0         5.0      0.0  \n",
       "    5764                1.0         5.0      0.0  \n",
       "    ...                 ...         ...      ...  \n",
       "    5120                1.0         4.0      5.0  \n",
       "    6899                7.0         4.0      4.0  \n",
       "    6598                7.0         4.0      4.0  \n",
       "    6515                7.0         4.0      4.0  \n",
       "    3845                3.0         3.0      0.0  \n",
       "    \n",
       "    [1625 rows x 21 columns],\n",
       "    6301    1.0\n",
       "    5784    1.0\n",
       "    4050    1.0\n",
       "    4223    1.0\n",
       "    3604    1.0\n",
       "           ... \n",
       "    4929    1.0\n",
       "    2256    0.0\n",
       "    4512    1.0\n",
       "    7354    0.0\n",
       "    7557    1.0\n",
       "    Name: poisonous, Length: 6499, dtype: float64,\n",
       "    2592    0.0\n",
       "    5878    1.0\n",
       "    2810    0.0\n",
       "    2946    0.0\n",
       "    5764    0.0\n",
       "           ... \n",
       "    5120    1.0\n",
       "    6899    1.0\n",
       "    6598    1.0\n",
       "    6515    1.0\n",
       "    3845    1.0\n",
       "    Name: poisonous, Length: 1625, dtype: float64)}},\n",
       " 'bankrupt': {0: {0.2: (      ROA(C) before interest and depreciation before interest  \\\n",
       "    4510                                           0.547750         \n",
       "    6396                                           0.447424         \n",
       "    5714                                           0.527860         \n",
       "    2807                                           0.413884         \n",
       "    5929                                           0.555843         \n",
       "    ...                                                 ...         \n",
       "    2240                                           0.498757         \n",
       "    959                                            0.533710         \n",
       "    4584                                           0.470921         \n",
       "    2086                                           0.526300         \n",
       "    2624                                           0.523034         \n",
       "    \n",
       "          ROA(A) before interest and % after tax  \\\n",
       "    4510                                0.627181   \n",
       "    6396                                0.497874   \n",
       "    5714                                0.581334   \n",
       "    2807                                0.472852   \n",
       "    5929                                0.605048   \n",
       "    ...                                      ...   \n",
       "    2240                                0.559093   \n",
       "    959                                 0.591910   \n",
       "    4584                                0.491550   \n",
       "    2086                                0.589784   \n",
       "    2624                                0.574738   \n",
       "    \n",
       "          ROA(B) before interest and depreciation after tax  \\\n",
       "    4510                                           0.610150   \n",
       "    6396                                           0.492478   \n",
       "    5714                                           0.571283   \n",
       "    2807                                           0.458750   \n",
       "    5929                                           0.593126   \n",
       "    ...                                                 ...   \n",
       "    2240                                           0.546603   \n",
       "    959                                            0.579421   \n",
       "    4584                                           0.518175   \n",
       "    2086                                           0.571712   \n",
       "    2624                                           0.573853   \n",
       "    \n",
       "          Operating Gross Margin  Realized Sales Gross Margin  \\\n",
       "    4510                0.602805                     0.602762   \n",
       "    6396                0.598755                     0.598755   \n",
       "    5714                0.601241                     0.601241   \n",
       "    2807                0.613060                     0.613053   \n",
       "    5929                0.605176                     0.604794   \n",
       "    ...                      ...                          ...   \n",
       "    2240                0.599338                     0.599310   \n",
       "    959                 0.608743                     0.608743   \n",
       "    4584                0.603749                     0.604852   \n",
       "    2086                0.617190                     0.617190   \n",
       "    2624                0.605068                     0.605061   \n",
       "    \n",
       "          Operating Profit Rate  Pre-tax net Interest Rate  \\\n",
       "    4510               0.999046                   0.797890   \n",
       "    6396               0.998928                   0.797336   \n",
       "    5714               0.999039                   0.797484   \n",
       "    2807               0.998735                   0.796800   \n",
       "    5929               0.999099                   0.797625   \n",
       "    ...                     ...                        ...   \n",
       "    2240               0.999000                   0.797416   \n",
       "    959                0.999109                   0.797557   \n",
       "    4584               0.998976                   0.796916   \n",
       "    2086               0.999044                   0.797483   \n",
       "    2624               0.999038                   0.797466   \n",
       "    \n",
       "          After-tax net Interest Rate  \\\n",
       "    4510                     0.809796   \n",
       "    6396                     0.809262   \n",
       "    5714                     0.809381   \n",
       "    2807                     0.808738   \n",
       "    5929                     0.809484   \n",
       "    ...                           ...   \n",
       "    2240                     0.809333   \n",
       "    959                      0.809441   \n",
       "    4584                     0.808871   \n",
       "    2086                     0.809382   \n",
       "    2624                     0.809374   \n",
       "    \n",
       "          Non-industry income and expenditure/revenue  \\\n",
       "    4510                                     0.304238   \n",
       "    6396                                     0.303518   \n",
       "    5714                                     0.303543   \n",
       "    2807                                     0.302983   \n",
       "    5929                                     0.303664   \n",
       "    ...                                           ...   \n",
       "    2240                                     0.303505   \n",
       "    959                                      0.303525   \n",
       "    4584                                     0.302681   \n",
       "    2086                                     0.303530   \n",
       "    2624                                     0.303514   \n",
       "    \n",
       "          Continuous interest rate (after tax)  ...  Net Income to Total Assets  \\\n",
       "    4510                              0.782050  ...                    0.838856   \n",
       "    6396                              0.781525  ...                    0.774113   \n",
       "    5714                              0.781644  ...                    0.820430   \n",
       "    2807                              0.780936  ...                    0.755144   \n",
       "    5929                              0.781756  ...                    0.836389   \n",
       "    ...                                    ...  ...                         ...   \n",
       "    2240                              0.781593  ...                    0.813378   \n",
       "    959                               0.781710  ...                    0.830067   \n",
       "    4584                              0.781361  ...                    0.768341   \n",
       "    2086                              0.781643  ...                    0.820275   \n",
       "    2624                              0.781638  ...                    0.815026   \n",
       "    \n",
       "          Total assets to GNP price  No-credit Interval  Gross Profit to Sales  \\\n",
       "    4510                   0.017036            0.635066               0.602804   \n",
       "    6396                   0.001088            0.623729               0.598750   \n",
       "    5714                   0.030475            0.624292               0.601240   \n",
       "    2807                   0.006335            0.623436               0.613056   \n",
       "    5929                   0.003480            0.625293               0.605175   \n",
       "    ...                         ...                 ...                    ...   \n",
       "    2240                   0.001624            0.624087               0.599336   \n",
       "    959                    0.005713            0.623449               0.608741   \n",
       "    4584                   0.082432            0.623554               0.603745   \n",
       "    2086                   0.000562            0.623743               0.617187   \n",
       "    2624                   0.001641            0.623675               0.605068   \n",
       "    \n",
       "          Net Income to Stockholder's Equity  Liability to Equity  \\\n",
       "    4510                            0.843832             0.280800   \n",
       "    6396                            0.838146             0.280573   \n",
       "    5714                            0.842331             0.281552   \n",
       "    2807                            0.836257             0.281429   \n",
       "    5929                            0.842957             0.278461   \n",
       "    ...                                  ...                  ...   \n",
       "    2240                            0.841438             0.279619   \n",
       "    959                             0.843525             0.282785   \n",
       "    4584                            0.838090             0.278248   \n",
       "    2086                            0.843552             0.288868   \n",
       "    2624                            0.841418             0.278470   \n",
       "    \n",
       "          Degree of Financial Leverage (DFL)  \\\n",
       "    4510                            0.026819   \n",
       "    6396                            0.026644   \n",
       "    5714                            0.026837   \n",
       "    2807                            0.026618   \n",
       "    5929                            0.026822   \n",
       "    ...                                  ...   \n",
       "    2240                            0.026808   \n",
       "    959                             0.026860   \n",
       "    4584                            0.026745   \n",
       "    2086                            0.027081   \n",
       "    2624                            0.027010   \n",
       "    \n",
       "          Interest Coverage Ratio (Interest expense to EBIT)  Net Income Flag  \\\n",
       "    4510                                           0.565286                 1   \n",
       "    6396                                           0.564346                 1   \n",
       "    5714                                           0.565367                 1   \n",
       "    2807                                           0.564170                 1   \n",
       "    5929                                           0.565300                 1   \n",
       "    ...                                                 ...               ...   \n",
       "    2240                                           0.565236                 1   \n",
       "    959                                            0.565466                 1   \n",
       "    4584                                           0.564929                 1   \n",
       "    2086                                           0.566243                 1   \n",
       "    2624                                           0.566023                 1   \n",
       "    \n",
       "          Equity to Liability  \n",
       "    4510             0.026054  \n",
       "    6396             0.026662  \n",
       "    5714             0.024321  \n",
       "    2807             0.024579  \n",
       "    5929             0.035841  \n",
       "    ...                   ...  \n",
       "    2240             0.029837  \n",
       "    959              0.022177  \n",
       "    4584             0.037370  \n",
       "    2086             0.017055  \n",
       "    2624             0.035780  \n",
       "    \n",
       "    [1363 rows x 95 columns],\n",
       "          ROA(C) before interest and depreciation before interest  \\\n",
       "    2888                                           0.490762         \n",
       "    6753                                           0.584849         \n",
       "    5129                                           0.438210         \n",
       "    4871                                           0.492712         \n",
       "    1014                                           0.583289         \n",
       "    ...                                                 ...         \n",
       "    3742                                           0.526739         \n",
       "    4779                                           0.485497         \n",
       "    2185                                           0.478526         \n",
       "    0                                              0.370594         \n",
       "    4382                                           0.472920         \n",
       "    \n",
       "          ROA(A) before interest and % after tax  \\\n",
       "    2888                                0.561982   \n",
       "    6753                                0.652584   \n",
       "    5129                                0.500000   \n",
       "    4871                                0.551461   \n",
       "    1014                                0.611044   \n",
       "    ...                                      ...   \n",
       "    3742                                0.563727   \n",
       "    4779                                0.520824   \n",
       "    2185                                0.547209   \n",
       "    0                                   0.424389   \n",
       "    4382                                0.544211   \n",
       "    \n",
       "          ROA(B) before interest and depreciation after tax  \\\n",
       "    2888                                           0.542481   \n",
       "    6753                                           0.637936   \n",
       "    5129                                           0.494566   \n",
       "    4871                                           0.544515   \n",
       "    1014                                           0.629370   \n",
       "    ...                                                 ...   \n",
       "    3742                                           0.574335   \n",
       "    4779                                           0.543230   \n",
       "    2185                                           0.530596   \n",
       "    0                                              0.405750   \n",
       "    4382                                           0.527598   \n",
       "    \n",
       "          Operating Gross Margin  Realized Sales Gross Margin  \\\n",
       "    2888                0.599021                     0.599021   \n",
       "    6753                0.621780                     0.621780   \n",
       "    5129                0.600953                     0.600953   \n",
       "    4871                0.612015                     0.612015   \n",
       "    1014                0.619323                     0.618278   \n",
       "    ...                      ...                          ...   \n",
       "    3742                0.604412                     0.604412   \n",
       "    4779                0.597803                     0.597803   \n",
       "    2185                0.605774                     0.605774   \n",
       "    0                   0.601457                     0.601457   \n",
       "    4382                0.596614                     0.596521   \n",
       "    \n",
       "          Operating Profit Rate  Pre-tax net Interest Rate  \\\n",
       "    2888               0.999018                   0.797480   \n",
       "    6753               0.999208                   0.797689   \n",
       "    5129               0.998898                   0.797249   \n",
       "    4871               0.998985                   0.797442   \n",
       "    1014               0.999223                   0.797705   \n",
       "    ...                     ...                        ...   \n",
       "    3742               0.999057                   0.797515   \n",
       "    4779               0.998896                   0.797237   \n",
       "    2185               0.999008                   0.797466   \n",
       "    0                  0.998969                   0.796887   \n",
       "    4382               0.998966                   0.797393   \n",
       "    \n",
       "          After-tax net Interest Rate  \\\n",
       "    2888                     0.809391   \n",
       "    6753                     0.809574   \n",
       "    5129                     0.809204   \n",
       "    4871                     0.809367   \n",
       "    1014                     0.809555   \n",
       "    ...                           ...   \n",
       "    3742                     0.809425   \n",
       "    4779                     0.809197   \n",
       "    2185                     0.809379   \n",
       "    0                        0.808809   \n",
       "    4382                     0.809320   \n",
       "    \n",
       "          Non-industry income and expenditure/revenue  \\\n",
       "    2888                                     0.303580   \n",
       "    6753                                     0.303548   \n",
       "    5129                                     0.303427   \n",
       "    4871                                     0.303583   \n",
       "    1014                                     0.303544   \n",
       "    ...                                           ...   \n",
       "    3742                                     0.303560   \n",
       "    4779                                     0.303411   \n",
       "    2185                                     0.303576   \n",
       "    0                                        0.302646   \n",
       "    4382                                     0.303536   \n",
       "    \n",
       "          Continuous interest rate (after tax)  ...  Net Income to Total Assets  \\\n",
       "    2888                              0.781645  ...                    0.811248   \n",
       "    6753                              0.781853  ...                    0.853173   \n",
       "    5129                              0.781454  ...                    0.777940   \n",
       "    4871                              0.781631  ...                    0.805125   \n",
       "    1014                              0.781832  ...                    0.839141   \n",
       "    ...                                    ...  ...                         ...   \n",
       "    3742                              0.781706  ...                    0.812962   \n",
       "    4779                              0.781446  ...                    0.786736   \n",
       "    2185                              0.781645  ...                    0.806046   \n",
       "    0                                 0.780985  ...                    0.716845   \n",
       "    4382                              0.781578  ...                    0.803358   \n",
       "    \n",
       "          Total assets to GNP price  No-credit Interval  Gross Profit to Sales  \\\n",
       "    2888                   0.019377            0.624001               0.599023   \n",
       "    6753                   0.000982            0.623640               0.621780   \n",
       "    5129                   0.002073            0.623647               0.600953   \n",
       "    4871                   0.000713            0.624099               0.612012   \n",
       "    1014                   0.011096            0.590876               0.619324   \n",
       "    ...                         ...                 ...                    ...   \n",
       "    3742                   0.005380            0.621709               0.604413   \n",
       "    4779                   0.001178            0.623458               0.597799   \n",
       "    2185                   0.002262            0.623507               0.605770   \n",
       "    0                      0.009219            0.622879               0.601453   \n",
       "    4382                   0.034227            0.624128               0.596609   \n",
       "    \n",
       "          Net Income to Stockholder's Equity  Liability to Equity  \\\n",
       "    2888                            0.841582             0.282583   \n",
       "    6753                            0.847107             0.285862   \n",
       "    5129                            0.837459             0.288730   \n",
       "    4871                            0.840511             0.275462   \n",
       "    1014                            0.843304             0.278955   \n",
       "    ...                                  ...                  ...   \n",
       "    3742                            0.841122             0.277233   \n",
       "    4779                            0.839080             0.283092   \n",
       "    2185                            0.840711             0.277635   \n",
       "    0                               0.827890             0.290202   \n",
       "    4382                            0.840597             0.278894   \n",
       "    \n",
       "          Degree of Financial Leverage (DFL)  \\\n",
       "    2888                            0.026882   \n",
       "    6753                            0.026791   \n",
       "    5129                            0.026712   \n",
       "    4871                            0.026943   \n",
       "    1014                            0.026805   \n",
       "    ...                                  ...   \n",
       "    3742                            0.026809   \n",
       "    4779                            0.026405   \n",
       "    2185                            0.026807   \n",
       "    0                               0.026601   \n",
       "    4382                            0.026841   \n",
       "    \n",
       "          Interest Coverage Ratio (Interest expense to EBIT)  Net Income Flag  \\\n",
       "    2888                                           0.565559                 1   \n",
       "    6753                                           0.565158                 1   \n",
       "    5129                                           0.564752                 1   \n",
       "    4871                                           0.565792                 1   \n",
       "    1014                                           0.565221                 1   \n",
       "    ...                                                 ...               ...   \n",
       "    3742                                           0.565244                 1   \n",
       "    4779                                           0.562252                 1   \n",
       "    2185                                           0.565233                 1   \n",
       "    0                                              0.564050                 1   \n",
       "    4382                                           0.565387                 1   \n",
       "    \n",
       "          Equity to Liability  \n",
       "    2888             0.022483  \n",
       "    6753             0.018890  \n",
       "    5129             0.017122  \n",
       "    4871             0.134231  \n",
       "    1014             0.032882  \n",
       "    ...                   ...  \n",
       "    3742             0.048162  \n",
       "    4779             0.021741  \n",
       "    2185             0.043001  \n",
       "    0                0.016469  \n",
       "    4382             0.033213  \n",
       "    \n",
       "    [5456 rows x 95 columns],\n",
       "    4510    0\n",
       "    6396    0\n",
       "    5714    0\n",
       "    2807    0\n",
       "    5929    0\n",
       "           ..\n",
       "    2240    0\n",
       "    959     0\n",
       "    4584    0\n",
       "    2086    0\n",
       "    2624    0\n",
       "    Name: Bankrupt?, Length: 1363, dtype: int64,\n",
       "    2888    0\n",
       "    6753    0\n",
       "    5129    0\n",
       "    4871    0\n",
       "    1014    0\n",
       "           ..\n",
       "    3742    0\n",
       "    4779    0\n",
       "    2185    0\n",
       "    0       1\n",
       "    4382    0\n",
       "    Name: Bankrupt?, Length: 5456, dtype: int64),\n",
       "   0.5: (      ROA(C) before interest and depreciation before interest  \\\n",
       "    1958                                           0.476576         \n",
       "    6462                                           0.468435         \n",
       "    2281                                           0.486472         \n",
       "    2359                                           0.508019         \n",
       "    6044                                           0.543704         \n",
       "    ...                                                 ...         \n",
       "    4042                                           0.509287         \n",
       "    737                                            0.507239         \n",
       "    2086                                           0.526300         \n",
       "    5565                                           0.572759         \n",
       "    4526                                           0.565154         \n",
       "    \n",
       "          ROA(A) before interest and % after tax  \\\n",
       "    1958                                0.541321   \n",
       "    6462                                0.474869   \n",
       "    2281                                0.542630   \n",
       "    2359                                0.582806   \n",
       "    6044                                0.606356   \n",
       "    ...                                      ...   \n",
       "    4042                                0.540231   \n",
       "    737                                 0.568633   \n",
       "    2086                                0.589784   \n",
       "    5565                                0.624291   \n",
       "    4526                                0.611862   \n",
       "    \n",
       "          ROA(B) before interest and depreciation after tax  \\\n",
       "    1958                                           0.525992   \n",
       "    6462                                           0.505113   \n",
       "    2281                                           0.541089   \n",
       "    2359                                           0.564698   \n",
       "    6044                                           0.587237   \n",
       "    ...                                                 ...   \n",
       "    4042                                           0.555383   \n",
       "    737                                            0.556561   \n",
       "    2086                                           0.571712   \n",
       "    5565                                           0.621232   \n",
       "    4526                                           0.598587   \n",
       "    \n",
       "          Operating Gross Margin  Realized Sales Gross Margin  \\\n",
       "    1958                0.596232                     0.596153   \n",
       "    6462                0.636641                     0.636641   \n",
       "    2281                0.608455                     0.608455   \n",
       "    2359                0.613716                     0.613716   \n",
       "    6044                0.600326                     0.600326   \n",
       "    ...                      ...                          ...   \n",
       "    4042                0.648114                     0.648114   \n",
       "    737                 0.613500                     0.613500   \n",
       "    2086                0.617190                     0.617190   \n",
       "    5565                0.615309                     0.615309   \n",
       "    4526                0.612159                     0.612159   \n",
       "    \n",
       "          Operating Profit Rate  Pre-tax net Interest Rate  \\\n",
       "    1958               0.998978                   0.797386   \n",
       "    6462               0.998758                   0.796986   \n",
       "    2281               0.999135                   0.797432   \n",
       "    2359               0.999204                   0.797655   \n",
       "    6044               0.999043                   0.797557   \n",
       "    ...                     ...                        ...   \n",
       "    4042               0.999306                   0.797473   \n",
       "    737                0.999130                   0.797546   \n",
       "    2086               0.999044                   0.797483   \n",
       "    5565               0.999199                   0.797650   \n",
       "    4526               0.999144                   0.797583   \n",
       "    \n",
       "          After-tax net Interest Rate  \\\n",
       "    1958                     0.809310   \n",
       "    6462                     0.808945   \n",
       "    2281                     0.809356   \n",
       "    2359                     0.809565   \n",
       "    6044                     0.809445   \n",
       "    ...                           ...   \n",
       "    4042                     0.809340   \n",
       "    737                      0.809432   \n",
       "    2086                     0.809382   \n",
       "    5565                     0.809526   \n",
       "    4526                     0.809446   \n",
       "    \n",
       "          Non-industry income and expenditure/revenue  \\\n",
       "    1958                                     0.303500   \n",
       "    6462                                     0.303261   \n",
       "    2281                                     0.303250   \n",
       "    2359                                     0.303496   \n",
       "    6044                                     0.303662   \n",
       "    ...                                           ...   \n",
       "    4042                                     0.302964   \n",
       "    737                                      0.303461   \n",
       "    2086                                     0.303530   \n",
       "    5565                                     0.303498   \n",
       "    4526                                     0.303497   \n",
       "    \n",
       "          Continuous interest rate (after tax)  ...  Net Income to Total Assets  \\\n",
       "    1958                              0.781570  ...                    0.797783   \n",
       "    6462                              0.781175  ...                    0.757249   \n",
       "    2281                              0.781701  ...                    0.801440   \n",
       "    2359                              0.781843  ...                    0.821403   \n",
       "    6044                              0.781708  ...                    0.836381   \n",
       "    ...                                    ...  ...                         ...   \n",
       "    4042                              0.781814  ...                    0.798936   \n",
       "    737                               0.781689  ...                    0.811713   \n",
       "    2086                              0.781643  ...                    0.820275   \n",
       "    5565                              0.781802  ...                    0.848227   \n",
       "    4526                              0.781721  ...                    0.840809   \n",
       "    \n",
       "          Total assets to GNP price  No-credit Interval  Gross Profit to Sales  \\\n",
       "    1958                   0.022999            0.623327               0.596231   \n",
       "    6462                   0.000321            0.623674               0.636640   \n",
       "    2281                   0.031183            0.620862               0.608454   \n",
       "    2359                   0.025747            0.621430               0.613713   \n",
       "    6044                   0.004265            0.624852               0.600326   \n",
       "    ...                         ...                 ...                    ...   \n",
       "    4042                   0.001618            0.623981               0.648110   \n",
       "    737                    0.004189            0.624640               0.613502   \n",
       "    2086                   0.000562            0.623743               0.617187   \n",
       "    5565                   0.000703            0.624546               0.615304   \n",
       "    4526                   0.000540            0.624005               0.612159   \n",
       "    \n",
       "          Net Income to Stockholder's Equity  Liability to Equity  \\\n",
       "    1958                            0.840268             0.285948   \n",
       "    6462                            0.835842             0.283700   \n",
       "    2281                            0.840815             0.288389   \n",
       "    2359                            0.843953             0.290217   \n",
       "    6044                            0.842942             0.278409   \n",
       "    ...                                  ...                  ...   \n",
       "    4042                            0.840245             0.277921   \n",
       "    737                             0.841584             0.282178   \n",
       "    2086                            0.843552             0.288868   \n",
       "    5565                            0.843149             0.276635   \n",
       "    4526                            0.843194             0.278197   \n",
       "    \n",
       "          Degree of Financial Leverage (DFL)  \\\n",
       "    1958                            0.028615   \n",
       "    6462                            0.026654   \n",
       "    2281                            0.027130   \n",
       "    2359                            0.026905   \n",
       "    6044                            0.026818   \n",
       "    ...                                  ...   \n",
       "    4042                            0.027293   \n",
       "    737                             0.027058   \n",
       "    2086                            0.027081   \n",
       "    5565                            0.026796   \n",
       "    4526                            0.026816   \n",
       "    \n",
       "          Interest Coverage Ratio (Interest expense to EBIT)  Net Income Flag  \\\n",
       "    1958                                           0.568349                 1   \n",
       "    6462                                           0.564405                 1   \n",
       "    2281                                           0.566383                 1   \n",
       "    2359                                           0.565648                 1   \n",
       "    6044                                           0.565284                 1   \n",
       "    ...                                                 ...               ...   \n",
       "    4042                                           0.566781                 1   \n",
       "    737                                            0.566173                 1   \n",
       "    2086                                           0.566243                 1   \n",
       "    5565                                           0.565182                 1   \n",
       "    4526                                           0.565272                 1   \n",
       "    \n",
       "          Equity to Liability  \n",
       "    1958             0.018824  \n",
       "    6462             0.020966  \n",
       "    2281             0.017294  \n",
       "    2359             0.016463  \n",
       "    6044             0.036199  \n",
       "    ...                   ...  \n",
       "    4042             0.040113  \n",
       "    737              0.023145  \n",
       "    2086             0.017055  \n",
       "    5565             0.059771  \n",
       "    4526             0.037762  \n",
       "    \n",
       "    [3409 rows x 95 columns],\n",
       "          ROA(C) before interest and depreciation before interest  \\\n",
       "    4251                                           0.601862         \n",
       "    3561                                           0.575489         \n",
       "    5896                                           0.540292         \n",
       "    6448                                           0.478380         \n",
       "    3277                                           0.610247         \n",
       "    ...                                                 ...         \n",
       "    823                                            0.528543         \n",
       "    862                                            0.409984         \n",
       "    4982                                           0.515380         \n",
       "    220                                            0.526837         \n",
       "    392                                            0.481353         \n",
       "    \n",
       "          ROA(A) before interest and % after tax  \\\n",
       "    4251                                0.651385   \n",
       "    3561                                0.643371   \n",
       "    5896                                0.566180   \n",
       "    6448                                0.531727   \n",
       "    3277                                0.665667   \n",
       "    ...                                      ...   \n",
       "    823                                 0.579154   \n",
       "    862                                 0.465820   \n",
       "    4982                                0.575338   \n",
       "    220                                 0.578173   \n",
       "    392                                 0.546664   \n",
       "    \n",
       "          ROA(B) before interest and depreciation after tax  \\\n",
       "    4251                                           0.638471   \n",
       "    3561                                           0.633706   \n",
       "    5896                                           0.583918   \n",
       "    6448                                           0.520370   \n",
       "    3277                                           0.677445   \n",
       "    ...                                                 ...   \n",
       "    823                                            0.584988   \n",
       "    862                                            0.453076   \n",
       "    4982                                           0.567215   \n",
       "    220                                            0.580652   \n",
       "    392                                            0.532363   \n",
       "    \n",
       "          Operating Gross Margin  Realized Sales Gross Margin  \\\n",
       "    4251                0.624778                     0.624569   \n",
       "    3561                0.627517                     0.627467   \n",
       "    5896                0.600996                     0.600996   \n",
       "    6448                0.620368                     0.620216   \n",
       "    3277                0.623798                     0.623798   \n",
       "    ...                      ...                          ...   \n",
       "    823                 0.618321                     0.618321   \n",
       "    862                 0.615986                     0.610408   \n",
       "    4982                0.602084                     0.602084   \n",
       "    220                 0.605493                     0.605493   \n",
       "    392                 0.598373                     0.598373   \n",
       "    \n",
       "          Operating Profit Rate  Pre-tax net Interest Rate  \\\n",
       "    4251               0.999269                   0.797778   \n",
       "    3561               0.999212                   0.797768   \n",
       "    5896               0.999052                   0.797438   \n",
       "    6448               0.999021                   0.797409   \n",
       "    3277               0.999325                   0.797816   \n",
       "    ...                     ...                        ...   \n",
       "    823                0.999147                   0.797641   \n",
       "    862                0.998773                   0.796980   \n",
       "    4982               0.999066                   0.797490   \n",
       "    220                0.999030                   0.797449   \n",
       "    392                0.998977                   0.797472   \n",
       "    \n",
       "          After-tax net Interest Rate  \\\n",
       "    4251                     0.809607   \n",
       "    3561                     0.809656   \n",
       "    5896                     0.809362   \n",
       "    6448                     0.809309   \n",
       "    3277                     0.809719   \n",
       "    ...                           ...   \n",
       "    823                      0.809549   \n",
       "    862                      0.808932   \n",
       "    4982                     0.809408   \n",
       "    220                      0.809364   \n",
       "    392                      0.809379   \n",
       "    \n",
       "          Non-industry income and expenditure/revenue  \\\n",
       "    4251                                     0.303576   \n",
       "    3561                                     0.303677   \n",
       "    5896                                     0.303437   \n",
       "    6448                                     0.303449   \n",
       "    3277                                     0.303526   \n",
       "    ...                                           ...   \n",
       "    823                                      0.303591   \n",
       "    862                                      0.303220   \n",
       "    4982                                     0.303497   \n",
       "    220                                      0.303501   \n",
       "    392                                      0.303652   \n",
       "    \n",
       "          Continuous interest rate (after tax)  ...  Net Income to Total Assets  \\\n",
       "    4251                              0.781880  ...                    0.864362   \n",
       "    3561                              0.781941  ...                    0.853503   \n",
       "    5896                              0.781624  ...                    0.809295   \n",
       "    6448                              0.781564  ...                    0.796407   \n",
       "    3277                              0.781988  ...                    0.861016   \n",
       "    ...                                    ...  ...                         ...   \n",
       "    823                               0.781819  ...                    0.818540   \n",
       "    862                               0.781136  ...                    0.755300   \n",
       "    4982                              0.781674  ...                    0.814999   \n",
       "    220                               0.781627  ...                    0.817154   \n",
       "    392                               0.781611  ...                    0.805529   \n",
       "    \n",
       "          Total assets to GNP price  No-credit Interval  Gross Profit to Sales  \\\n",
       "    4251                   0.002792            0.623999               0.624776   \n",
       "    3561                   0.002066            0.623764               0.627518   \n",
       "    5896                   0.004370            0.624053               0.600992   \n",
       "    6448                   0.000580            0.623909               0.620364   \n",
       "    3277                   0.001062            0.621625               0.623794   \n",
       "    ...                         ...                 ...                    ...   \n",
       "    823                    0.005732            0.623365               0.618317   \n",
       "    862                    0.000281            0.623917               0.615987   \n",
       "    4982                   0.005752            0.620885               0.602080   \n",
       "    220                    0.002776            0.623545               0.605493   \n",
       "    392                    0.029484            0.623348               0.598368   \n",
       "    \n",
       "          Net Income to Stockholder's Equity  Liability to Equity  \\\n",
       "    4251                            0.844118             0.276656   \n",
       "    3561                            0.843793             0.277464   \n",
       "    5896                            0.841581             0.284693   \n",
       "    6448                            0.840068             0.276733   \n",
       "    3277                            0.844647             0.278269   \n",
       "    ...                                  ...                  ...   \n",
       "    823                             0.841979             0.280431   \n",
       "    862                             0.837483             0.277132   \n",
       "    4982                            0.842739             0.288475   \n",
       "    220                             0.841912             0.280789   \n",
       "    392                             0.840695             0.277912   \n",
       "    \n",
       "          Degree of Financial Leverage (DFL)  \\\n",
       "    4251                            0.026791   \n",
       "    3561                            0.026796   \n",
       "    5896                            0.027618   \n",
       "    6448                            0.026825   \n",
       "    3277                            0.026824   \n",
       "    ...                                  ...   \n",
       "    823                             0.026833   \n",
       "    862                             0.026766   \n",
       "    4982                            0.026938   \n",
       "    220                             0.027092   \n",
       "    392                             0.026792   \n",
       "    \n",
       "          Interest Coverage Ratio (Interest expense to EBIT)  Net Income Flag  \\\n",
       "    4251                                           0.565160                 1   \n",
       "    3561                                           0.565182                 1   \n",
       "    5896                                           0.567370                 1   \n",
       "    6448                                           0.565317                 1   \n",
       "    3277                                           0.565311                 1   \n",
       "    ...                                                 ...               ...   \n",
       "    823                                            0.565352                 1   \n",
       "    862                                            0.565034                 1   \n",
       "    4982                                           0.565774                 1   \n",
       "    220                                            0.566274                 1   \n",
       "    392                                            0.565165                 1   \n",
       "    \n",
       "          Equity to Liability  \n",
       "    4251             0.059262  \n",
       "    3561             0.045022  \n",
       "    5896             0.019900  \n",
       "    6448             0.057425  \n",
       "    3277             0.037216  \n",
       "    ...                   ...  \n",
       "    823              0.027067  \n",
       "    862              0.049738  \n",
       "    4982             0.017250  \n",
       "    220              0.026082  \n",
       "    392              0.040194  \n",
       "    \n",
       "    [3410 rows x 95 columns],\n",
       "    1958    0\n",
       "    6462    0\n",
       "    2281    0\n",
       "    2359    0\n",
       "    6044    0\n",
       "           ..\n",
       "    4042    0\n",
       "    737     0\n",
       "    2086    0\n",
       "    5565    0\n",
       "    4526    0\n",
       "    Name: Bankrupt?, Length: 3409, dtype: int64,\n",
       "    4251    0\n",
       "    3561    0\n",
       "    5896    0\n",
       "    6448    0\n",
       "    3277    0\n",
       "           ..\n",
       "    823     0\n",
       "    862     0\n",
       "    4982    0\n",
       "    220     0\n",
       "    392     0\n",
       "    Name: Bankrupt?, Length: 3410, dtype: int64),\n",
       "   0.8: (      ROA(C) before interest and depreciation before interest  \\\n",
       "    5557                                           0.446400         \n",
       "    4839                                           0.510213         \n",
       "    6283                                           0.555989         \n",
       "    4387                                           0.377614         \n",
       "    6254                                           0.451129         \n",
       "    ...                                                 ...         \n",
       "    6500                                           0.436942         \n",
       "    2257                                           0.405548         \n",
       "    2086                                           0.526300         \n",
       "    5565                                           0.572759         \n",
       "    4526                                           0.565154         \n",
       "    \n",
       "          ROA(A) before interest and % after tax  \\\n",
       "    5557                                0.480975   \n",
       "    4839                                0.568415   \n",
       "    6283                                0.587604   \n",
       "    4387                                0.423953   \n",
       "    6254                                0.501799   \n",
       "    ...                                      ...   \n",
       "    6500                                0.490951   \n",
       "    2257                                0.450392   \n",
       "    2086                                0.589784   \n",
       "    5565                                0.624291   \n",
       "    4526                                0.611862   \n",
       "    \n",
       "          ROA(B) before interest and depreciation after tax  \\\n",
       "    5557                                           0.487767   \n",
       "    4839                                           0.556400   \n",
       "    6283                                           0.598747   \n",
       "    4387                                           0.417421   \n",
       "    6254                                           0.494405   \n",
       "    ...                                                 ...   \n",
       "    6500                                           0.482413   \n",
       "    2257                                           0.452219   \n",
       "    2086                                           0.571712   \n",
       "    5565                                           0.621232   \n",
       "    4526                                           0.598587   \n",
       "    \n",
       "          Operating Gross Margin  Realized Sales Gross Margin  \\\n",
       "    5557                0.607374                     0.607497   \n",
       "    4839                0.607316                     0.607295   \n",
       "    6283                0.610631                     0.610631   \n",
       "    4387                0.596153                     0.596521   \n",
       "    6254                0.607619                     0.607619   \n",
       "    ...                      ...                          ...   \n",
       "    6500                0.607987                     0.607951   \n",
       "    2257                0.569437                     0.569437   \n",
       "    2086                0.617190                     0.617190   \n",
       "    5565                0.615309                     0.615309   \n",
       "    4526                0.612159                     0.612159   \n",
       "    \n",
       "          Operating Profit Rate  Pre-tax net Interest Rate  \\\n",
       "    5557               0.998941                   0.797153   \n",
       "    4839               0.999025                   0.797792   \n",
       "    6283               0.999124                   0.797564   \n",
       "    4387               0.998812                   0.796982   \n",
       "    6254               0.999070                   0.797280   \n",
       "    ...                     ...                        ...   \n",
       "    6500               0.998921                   0.797265   \n",
       "    2257               0.998382                   0.794724   \n",
       "    2086               0.999044                   0.797483   \n",
       "    5565               0.999199                   0.797650   \n",
       "    4526               0.999144                   0.797583   \n",
       "    \n",
       "          After-tax net Interest Rate  \\\n",
       "    5557                     0.809093   \n",
       "    4839                     0.809607   \n",
       "    6283                     0.809446   \n",
       "    4387                     0.808924   \n",
       "    6254                     0.809187   \n",
       "    ...                           ...   \n",
       "    6500                     0.809187   \n",
       "    2257                     0.806807   \n",
       "    2086                     0.809382   \n",
       "    5565                     0.809526   \n",
       "    4526                     0.809446   \n",
       "    \n",
       "          Non-industry income and expenditure/revenue  \\\n",
       "    5557                                     0.303169   \n",
       "    4839                                     0.304110   \n",
       "    6283                                     0.303504   \n",
       "    4387                                     0.303142   \n",
       "    6254                                     0.303122   \n",
       "    ...                                           ...   \n",
       "    6500                                     0.303408   \n",
       "    2257                                     0.300096   \n",
       "    2086                                     0.303530   \n",
       "    5565                                     0.303498   \n",
       "    4526                                     0.303497   \n",
       "    \n",
       "          Continuous interest rate (after tax)  ...  Net Income to Total Assets  \\\n",
       "    5557                              0.781336  ...                    0.762124   \n",
       "    4839                              0.781883  ...                    0.816127   \n",
       "    6283                              0.781756  ...                    0.826592   \n",
       "    4387                              0.781173  ...                    0.729441   \n",
       "    6254                              0.781457  ...                    0.778362   \n",
       "    ...                                    ...  ...                         ...   \n",
       "    6500                              0.781435  ...                    0.767650   \n",
       "    2257                              0.779423  ...                    0.745278   \n",
       "    2086                              0.781643  ...                    0.820275   \n",
       "    5565                              0.781802  ...                    0.848227   \n",
       "    4526                              0.781721  ...                    0.840809   \n",
       "    \n",
       "          Total assets to GNP price  No-credit Interval  Gross Profit to Sales  \\\n",
       "    5557                   0.000600            0.623910               0.607374   \n",
       "    4839                   0.003316            0.624539               0.607317   \n",
       "    6283                   0.002296            0.624415               0.610631   \n",
       "    4387                   0.002758            0.623922               0.596148   \n",
       "    6254                   0.002582            0.624549               0.607619   \n",
       "    ...                         ...                 ...                    ...   \n",
       "    6500                   0.000978            0.623608               0.607985   \n",
       "    2257                   0.007713            0.617547               0.569437   \n",
       "    2086                   0.000562            0.623743               0.617187   \n",
       "    5565                   0.000703            0.624546               0.615304   \n",
       "    4526                   0.000540            0.624005               0.612159   \n",
       "    \n",
       "          Net Income to Stockholder's Equity  Liability to Equity  \\\n",
       "    5557                            0.836488             0.283202   \n",
       "    4839                            0.841214             0.276450   \n",
       "    6283                            0.842167             0.278067   \n",
       "    4387                            0.835453             0.278006   \n",
       "    6254                            0.839168             0.275215   \n",
       "    ...                                  ...                  ...   \n",
       "    6500                            0.834479             0.296390   \n",
       "    2257                            0.834922             0.282625   \n",
       "    2086                            0.843552             0.288868   \n",
       "    5565                            0.843149             0.276635   \n",
       "    4526                            0.843194             0.278197   \n",
       "    \n",
       "          Degree of Financial Leverage (DFL)  \\\n",
       "    5557                            0.026665   \n",
       "    4839                            0.026800   \n",
       "    6283                            0.026833   \n",
       "    4387                            0.026768   \n",
       "    6254                            0.026791   \n",
       "    ...                                  ...   \n",
       "    6500                            0.026615   \n",
       "    2257                            0.026722   \n",
       "    2086                            0.027081   \n",
       "    5565                            0.026796   \n",
       "    4526                            0.026816   \n",
       "    \n",
       "          Interest Coverage Ratio (Interest expense to EBIT)  Net Income Flag  \\\n",
       "    5557                                           0.564474                 1   \n",
       "    4839                                           0.565199                 1   \n",
       "    6283                                           0.565350                 1   \n",
       "    4387                                           0.565045                 1   \n",
       "    6254                                           0.565158                 1   \n",
       "    ...                                                 ...               ...   \n",
       "    6500                                           0.564153                 1   \n",
       "    2257                                           0.564808                 1   \n",
       "    2086                                           0.566243                 1   \n",
       "    5565                                           0.565182                 1   \n",
       "    4526                                           0.565272                 1   \n",
       "    \n",
       "          Equity to Liability  \n",
       "    5557             0.021593  \n",
       "    4839             0.064953  \n",
       "    6283             0.038828  \n",
       "    4387             0.039345  \n",
       "    6254             0.191443  \n",
       "    ...                   ...  \n",
       "    6500             0.014691  \n",
       "    2257             0.022417  \n",
       "    2086             0.017055  \n",
       "    5565             0.059771  \n",
       "    4526             0.037762  \n",
       "    \n",
       "    [5455 rows x 95 columns],\n",
       "          ROA(C) before interest and depreciation before interest  \\\n",
       "    4488                                           0.574514         \n",
       "    2195                                           0.479988         \n",
       "    4150                                           0.499196         \n",
       "    1117                                           0.500609         \n",
       "    1179                                           0.360796         \n",
       "    ...                                                 ...         \n",
       "    5687                                           0.528055         \n",
       "    1893                                           0.480378         \n",
       "    5763                                           0.456247         \n",
       "    4703                                           0.460440         \n",
       "    1547                                           0.464242         \n",
       "    \n",
       "          ROA(A) before interest and % after tax  \\\n",
       "    4488                                0.642826   \n",
       "    2195                                0.534671   \n",
       "    4150                                0.533908   \n",
       "    1117                                0.555113   \n",
       "    1179                                0.400403   \n",
       "    ...                                      ...   \n",
       "    5687                                0.581062   \n",
       "    1893                                0.545955   \n",
       "    5763                                0.520552   \n",
       "    4703                                0.497983   \n",
       "    1547                                0.532708   \n",
       "    \n",
       "          ROA(B) before interest and depreciation after tax  \\\n",
       "    4488                                           0.627014   \n",
       "    2195                                           0.529043   \n",
       "    4150                                           0.543391   \n",
       "    1117                                           0.543980   \n",
       "    1179                                           0.398094   \n",
       "    ...                                                 ...   \n",
       "    5687                                           0.577279   \n",
       "    1893                                           0.532309   \n",
       "    5763                                           0.509342   \n",
       "    4703                                           0.523904   \n",
       "    1547                                           0.513357   \n",
       "    \n",
       "          Operating Gross Margin  Realized Sales Gross Margin  \\\n",
       "    4488                0.601270                     0.601270   \n",
       "    2195                0.598589                     0.598589   \n",
       "    4150                0.605933                     0.605933   \n",
       "    1117                0.601875                     0.601875   \n",
       "    1179                0.597025                     0.597025   \n",
       "    ...                      ...                          ...   \n",
       "    5687                0.611035                     0.610913   \n",
       "    1893                0.605010                     0.605010   \n",
       "    5763                0.604924                     0.604700   \n",
       "    4703                0.599720                     0.599893   \n",
       "    1547                0.653966                     0.650694   \n",
       "    \n",
       "          Operating Profit Rate  Pre-tax net Interest Rate  \\\n",
       "    4488               0.999051                   0.797484   \n",
       "    2195               0.998907                   0.797383   \n",
       "    4150               0.998983                   0.797392   \n",
       "    1117               0.999009                   0.797427   \n",
       "    1179               0.998804                   0.796708   \n",
       "    ...                     ...                        ...   \n",
       "    5687               0.999098                   0.797636   \n",
       "    1893               0.998999                   0.797399   \n",
       "    5763               0.998995                   0.797360   \n",
       "    4703               0.998704                   0.796862   \n",
       "    1547               0.999001                   0.797426   \n",
       "    \n",
       "          After-tax net Interest Rate  \\\n",
       "    4488                     0.809396   \n",
       "    2195                     0.809310   \n",
       "    4150                     0.809312   \n",
       "    1117                     0.809338   \n",
       "    1179                     0.808651   \n",
       "    ...                           ...   \n",
       "    5687                     0.809507   \n",
       "    1893                     0.809327   \n",
       "    5763                     0.809290   \n",
       "    4703                     0.808940   \n",
       "    1547                     0.809326   \n",
       "    \n",
       "          Non-industry income and expenditure/revenue  \\\n",
       "    4488                                     0.303519   \n",
       "    2195                                     0.303643   \n",
       "    4150                                     0.303499   \n",
       "    1117                                     0.303506   \n",
       "    1179                                     0.302679   \n",
       "    ...                                           ...   \n",
       "    5687                                     0.303685   \n",
       "    1893                                     0.303478   \n",
       "    5763                                     0.303418   \n",
       "    4703                                     0.303157   \n",
       "    1547                                     0.303522   \n",
       "    \n",
       "          Continuous interest rate (after tax)  ...  Net Income to Total Assets  \\\n",
       "    4488                              0.781661  ...                    0.853422   \n",
       "    2195                              0.781569  ...                    0.796381   \n",
       "    4150                              0.781574  ...                    0.797545   \n",
       "    1117                              0.781597  ...                    0.808696   \n",
       "    1179                              0.780851  ...                    0.701107   \n",
       "    ...                                    ...  ...                         ...   \n",
       "    5687                              0.781780  ...                    0.820005   \n",
       "    1893                              0.781587  ...                    0.801701   \n",
       "    5763                              0.781546  ...                    0.788773   \n",
       "    4703                              0.781356  ...                    0.774238   \n",
       "    1547                              0.781542  ...                    0.797126   \n",
       "    \n",
       "          Total assets to GNP price  No-credit Interval  Gross Profit to Sales  \\\n",
       "    4488                   0.007175            0.624243               0.601268   \n",
       "    2195                   0.000647            0.623675               0.598586   \n",
       "    4150                   0.001210            0.623799               0.605931   \n",
       "    1117                   0.000933            0.624085               0.601874   \n",
       "    1179                   0.010522            0.623389               0.597026   \n",
       "    ...                         ...                 ...                    ...   \n",
       "    5687                   0.001907            0.623748               0.611034   \n",
       "    1893                   0.001934            0.623800               0.605008   \n",
       "    5763                   0.000671            0.623781               0.604921   \n",
       "    4703                   0.005828            0.626311               0.599717   \n",
       "    1547                   0.002610            0.624005               0.653962   \n",
       "    \n",
       "          Net Income to Stockholder's Equity  Liability to Equity  \\\n",
       "    4488                            0.844143             0.278354   \n",
       "    2195                            0.840068             0.277343   \n",
       "    4150                            0.840150             0.277935   \n",
       "    1117                            0.840929             0.278109   \n",
       "    1179                            0.830591             0.282426   \n",
       "    ...                                  ...                  ...   \n",
       "    5687                            0.842121             0.280529   \n",
       "    1893                            0.840652             0.283392   \n",
       "    5763                            0.839235             0.284241   \n",
       "    4703                            0.838595             0.277659   \n",
       "    1547                            0.840098             0.275085   \n",
       "    \n",
       "          Degree of Financial Leverage (DFL)  \\\n",
       "    4488                            0.026791   \n",
       "    2195                            0.033635   \n",
       "    4150                            0.026924   \n",
       "    1117                            0.026863   \n",
       "    1179                            0.026670   \n",
       "    ...                                  ...   \n",
       "    5687                            0.026857   \n",
       "    1893                            0.027619   \n",
       "    5763                            0.026626   \n",
       "    4703                            0.026718   \n",
       "    1547                            0.026791   \n",
       "    \n",
       "          Interest Coverage Ratio (Interest expense to EBIT)  Net Income Flag  \\\n",
       "    4488                                           0.565158                 1   \n",
       "    2195                                           0.569523                 1   \n",
       "    4150                                           0.565723                 1   \n",
       "    1117                                           0.565479                 1   \n",
       "    1179                                           0.564509                 1   \n",
       "    ...                                                 ...               ...   \n",
       "    5687                                           0.565456                 1   \n",
       "    1893                                           0.567372                 1   \n",
       "    5763                                           0.564223                 1   \n",
       "    4703                                           0.564783                 1   \n",
       "    1547                                           0.565158                 1   \n",
       "    \n",
       "          Equity to Liability  \n",
       "    4488             0.036589  \n",
       "    2195             0.046597  \n",
       "    4150             0.039983  \n",
       "    1117             0.038475  \n",
       "    1179             0.022732  \n",
       "    ...                   ...  \n",
       "    5687             0.026785  \n",
       "    1893             0.021345  \n",
       "    5763             0.020358  \n",
       "    4703             0.042743  \n",
       "    1547             0.250244  \n",
       "    \n",
       "    [1364 rows x 95 columns],\n",
       "    5557    0\n",
       "    4839    0\n",
       "    6283    0\n",
       "    4387    0\n",
       "    6254    0\n",
       "           ..\n",
       "    6500    1\n",
       "    2257    0\n",
       "    2086    0\n",
       "    5565    0\n",
       "    4526    0\n",
       "    Name: Bankrupt?, Length: 5455, dtype: int64,\n",
       "    4488    0\n",
       "    2195    0\n",
       "    4150    0\n",
       "    1117    0\n",
       "    1179    1\n",
       "           ..\n",
       "    5687    0\n",
       "    1893    0\n",
       "    5763    0\n",
       "    4703    0\n",
       "    1547    0\n",
       "    Name: Bankrupt?, Length: 1364, dtype: int64)},\n",
       "  42: {0.2: (      ROA(C) before interest and depreciation before interest  \\\n",
       "    5319                                           0.672598         \n",
       "    3554                                           0.495637         \n",
       "    266                                            0.494272         \n",
       "    3285                                           0.348169         \n",
       "    1509                                           0.404378         \n",
       "    ...                                                 ...         \n",
       "    5559                                           0.533954         \n",
       "    377                                            0.599132         \n",
       "    3838                                           0.506947         \n",
       "    5535                                           0.522254         \n",
       "    360                                            0.472773         \n",
       "    \n",
       "          ROA(A) before interest and % after tax  \\\n",
       "    5319                                0.695432   \n",
       "    3554                                0.559584   \n",
       "    266                                 0.542248   \n",
       "    3285                                0.276984   \n",
       "    1509                                0.459442   \n",
       "    ...                                      ...   \n",
       "    5559                                0.594581   \n",
       "    377                                 0.638247   \n",
       "    3838                                0.548517   \n",
       "    5535                                0.589784   \n",
       "    360                                 0.538541   \n",
       "    \n",
       "          ROA(B) before interest and depreciation after tax  \\\n",
       "    5319                                           0.690401   \n",
       "    3554                                           0.546496   \n",
       "    266                                            0.542213   \n",
       "    3285                                           0.389207   \n",
       "    1509                                           0.449703   \n",
       "    ...                                                 ...   \n",
       "    5559                                           0.580117   \n",
       "    377                                            0.637240   \n",
       "    3838                                           0.557417   \n",
       "    5535                                           0.577547   \n",
       "    360                                            0.526045   \n",
       "    \n",
       "          Operating Gross Margin  Realized Sales Gross Margin  \\\n",
       "    5319                0.627848                     0.627848   \n",
       "    3554                0.618220                     0.618220   \n",
       "    266                 0.604145                     0.604145   \n",
       "    3285                0.617291                     0.617291   \n",
       "    1509                0.601342                     0.601342   \n",
       "    ...                      ...                          ...   \n",
       "    5559                0.610278                     0.610235   \n",
       "    377                 0.628396                     0.628396   \n",
       "    3838                0.596585                     0.596585   \n",
       "    5535                0.607806                     0.607806   \n",
       "    360                 0.599720                     0.599901   \n",
       "    \n",
       "          Operating Profit Rate  Pre-tax net Interest Rate  \\\n",
       "    5319               0.999396                   0.797911   \n",
       "    3554               0.999031                   0.797469   \n",
       "    266                0.999026                   0.797399   \n",
       "    3285               0.998563                   0.796240   \n",
       "    1509               0.998526                   0.797110   \n",
       "    ...                     ...                        ...   \n",
       "    5559               0.999073                   0.797520   \n",
       "    377                0.999358                   0.797843   \n",
       "    3838               0.998982                   0.797391   \n",
       "    5535               0.999024                   0.797798   \n",
       "    360                0.998959                   0.797407   \n",
       "    \n",
       "          After-tax net Interest Rate  \\\n",
       "    5319                     0.809679   \n",
       "    3554                     0.809388   \n",
       "    266                      0.809307   \n",
       "    3285                     0.808234   \n",
       "    1509                     0.809081   \n",
       "    ...                           ...   \n",
       "    5559                     0.809414   \n",
       "    377                      0.809670   \n",
       "    3838                     0.809322   \n",
       "    5535                     0.809681   \n",
       "    360                      0.809332   \n",
       "    \n",
       "          Non-industry income and expenditure/revenue  \\\n",
       "    5319                                     0.303542   \n",
       "    3554                                     0.303534   \n",
       "    266                                      0.303422   \n",
       "    3285                                     0.302366   \n",
       "    1509                                     0.303962   \n",
       "    ...                                           ...   \n",
       "    5559                                     0.303535   \n",
       "    377                                      0.303503   \n",
       "    3838                                     0.303500   \n",
       "    5535                                     0.304123   \n",
       "    360                                      0.303575   \n",
       "    \n",
       "          Continuous interest rate (after tax)  ...  Net Income to Total Assets  \\\n",
       "    5319                              0.781964  ...                    0.883510   \n",
       "    3554                              0.781633  ...                    0.812459   \n",
       "    266                               0.781586  ...                    0.796078   \n",
       "    3285                              0.780821  ...                    0.668053   \n",
       "    1509                              0.781240  ...                    0.758479   \n",
       "    ...                                    ...  ...                         ...   \n",
       "    5559                              0.781680  ...                    0.825736   \n",
       "    377                               0.781956  ...                    0.852854   \n",
       "    3838                              0.781581  ...                    0.803213   \n",
       "    5535                              0.781966  ...                    0.829506   \n",
       "    360                               0.781579  ...                    0.800013   \n",
       "    \n",
       "          Total assets to GNP price  No-credit Interval  Gross Profit to Sales  \\\n",
       "    5319                   0.001483            0.624497               0.627846   \n",
       "    3554                   0.001721            0.623971               0.618219   \n",
       "    266                    0.002817            0.623653               0.604141   \n",
       "    3285                   0.001157            0.623815               0.617287   \n",
       "    1509                   0.000229            0.623751               0.601338   \n",
       "    ...                         ...                 ...                    ...   \n",
       "    5559                   0.001111            0.623772               0.610274   \n",
       "    377                    0.000792            0.624292               0.628397   \n",
       "    3838                   0.001037            0.633712               0.596581   \n",
       "    5535                   0.003583            0.623813               0.607806   \n",
       "    360                    0.002171            0.624355               0.599716   \n",
       "    \n",
       "          Net Income to Stockholder's Equity  Liability to Equity  \\\n",
       "    5319                            0.845723             0.277420   \n",
       "    3554                            0.840980             0.276267   \n",
       "    266                             0.840053             0.282058   \n",
       "    3285                            0.832796             0.276230   \n",
       "    1509                            0.837291             0.278642   \n",
       "    ...                                  ...                  ...   \n",
       "    5559                            0.843770             0.286110   \n",
       "    377                             0.843691             0.277311   \n",
       "    3838                            0.840882             0.284753   \n",
       "    5535                            0.842189             0.277295   \n",
       "    360                             0.840272             0.276271   \n",
       "    \n",
       "          Degree of Financial Leverage (DFL)  \\\n",
       "    5319                            0.026797   \n",
       "    3554                            0.026791   \n",
       "    266                             0.028093   \n",
       "    3285                            0.026788   \n",
       "    1509                            0.026791   \n",
       "    ...                                  ...   \n",
       "    5559                            0.026888   \n",
       "    377                             0.026829   \n",
       "    3838                            0.027418   \n",
       "    5535                            0.026867   \n",
       "    360                             0.027059   \n",
       "    \n",
       "          Interest Coverage Ratio (Interest expense to EBIT)  Net Income Flag  \\\n",
       "    5319                                           0.565186                 1   \n",
       "    3554                                           0.565158                 1   \n",
       "    266                                            0.567939                 1   \n",
       "    3285                                           0.565141                 1   \n",
       "    1509                                           0.565158                 1   \n",
       "    ...                                                 ...               ...   \n",
       "    5559                                           0.565581                 1   \n",
       "    377                                            0.565334                 1   \n",
       "    3838                                           0.567034                 1   \n",
       "    5535                                           0.565496                 1   \n",
       "    360                                            0.566178                 1   \n",
       "    \n",
       "          Equity to Liability  \n",
       "    5319             0.045577  \n",
       "    3554             0.071292  \n",
       "    266              0.023355  \n",
       "    3285             0.072751  \n",
       "    1509             0.034675  \n",
       "    ...                   ...  \n",
       "    5559             0.018702  \n",
       "    377              0.047044  \n",
       "    3838             0.019843  \n",
       "    5535             0.047264  \n",
       "    360              0.071134  \n",
       "    \n",
       "    [1363 rows x 95 columns],\n",
       "          ROA(C) before interest and depreciation before interest  \\\n",
       "    3344                                           0.472871         \n",
       "    2588                                           0.492322         \n",
       "    4138                                           0.427924         \n",
       "    6170                                           0.480232         \n",
       "    3558                                           0.577000         \n",
       "    ...                                                 ...         \n",
       "    2116                                           0.504363         \n",
       "    1167                                           0.524399         \n",
       "    4800                                           0.511334         \n",
       "    373                                            0.440550         \n",
       "    4398                                           0.572174         \n",
       "    \n",
       "          ROA(A) before interest and % after tax  \\\n",
       "    3344                                0.497002   \n",
       "    2588                                0.553260   \n",
       "    4138                                0.525294   \n",
       "    6170                                0.528347   \n",
       "    3558                                0.626254   \n",
       "    ...                                      ...   \n",
       "    2116                                0.561873   \n",
       "    1167                                0.574302   \n",
       "    4800                                0.565853   \n",
       "    373                                 0.497492   \n",
       "    4398                                0.627944   \n",
       "    \n",
       "          ROA(B) before interest and depreciation after tax  \\\n",
       "    3344                                           0.504845   \n",
       "    2588                                           0.548691   \n",
       "    4138                                           0.510627   \n",
       "    6170                                           0.522726   \n",
       "    3558                                           0.629798   \n",
       "    ...                                                 ...   \n",
       "    2116                                           0.559238   \n",
       "    1167                                           0.569891   \n",
       "    4800                                           0.557739   \n",
       "    373                                            0.467102   \n",
       "    4398                                           0.606349   \n",
       "    \n",
       "          Operating Gross Margin  Realized Sales Gross Margin  \\\n",
       "    3344                0.600585                     0.600585   \n",
       "    2588                0.618494                     0.618494   \n",
       "    4138                0.603980                     0.603980   \n",
       "    6170                0.607280                     0.607280   \n",
       "    3558                0.611727                     0.610531   \n",
       "    ...                      ...                          ...   \n",
       "    2116                0.600023                     0.600023   \n",
       "    1167                0.615381                     0.615546   \n",
       "    4800                0.608095                     0.608095   \n",
       "    373                 0.593955                     0.593955   \n",
       "    4398                0.617175                     0.616995   \n",
       "    \n",
       "          Operating Profit Rate  Pre-tax net Interest Rate  \\\n",
       "    3344               0.998872                   0.797241   \n",
       "    2588               0.999121                   0.797451   \n",
       "    4138               0.998874                   0.797296   \n",
       "    6170               0.999016                   0.797392   \n",
       "    3558               0.999161                   0.797730   \n",
       "    ...                     ...                        ...   \n",
       "    2116               0.999041                   0.797424   \n",
       "    1167               0.999178                   0.797708   \n",
       "    4800               0.999063                   0.797610   \n",
       "    373                0.998857                   0.797233   \n",
       "    4398               0.999252                   0.797789   \n",
       "    \n",
       "          After-tax net Interest Rate  \\\n",
       "    3344                     0.809119   \n",
       "    2588                     0.809378   \n",
       "    4138                     0.809292   \n",
       "    6170                     0.809302   \n",
       "    3558                     0.809602   \n",
       "    ...                           ...   \n",
       "    2116                     0.809344   \n",
       "    1167                     0.809575   \n",
       "    4800                     0.809472   \n",
       "    373                      0.808984   \n",
       "    4398                     0.809607   \n",
       "    \n",
       "          Non-industry income and expenditure/revenue  \\\n",
       "    3344                                     0.303467   \n",
       "    2588                                     0.303314   \n",
       "    4138                                     0.303560   \n",
       "    6170                                     0.303429   \n",
       "    3558                                     0.303718   \n",
       "    ...                                           ...   \n",
       "    2116                                     0.303434   \n",
       "    1167                                     0.303644   \n",
       "    4800                                     0.303714   \n",
       "    373                                      0.303487   \n",
       "    4398                                     0.303630   \n",
       "    \n",
       "          Continuous interest rate (after tax)  ...  Net Income to Total Assets  \\\n",
       "    3344                              0.781362  ...                    0.773069   \n",
       "    2588                              0.781641  ...                    0.807400   \n",
       "    4138                              0.781537  ...                    0.792871   \n",
       "    6170                              0.781563  ...                    0.794361   \n",
       "    3558                              0.781883  ...                    0.841267   \n",
       "    ...                                    ...  ...                         ...   \n",
       "    2116                              0.781604  ...                    0.803412   \n",
       "    1167                              0.781819  ...                    0.820866   \n",
       "    4800                              0.781733  ...                    0.814404   \n",
       "    373                               0.781058  ...                    0.772558   \n",
       "    4398                              0.781862  ...                    0.851214   \n",
       "    \n",
       "          Total assets to GNP price  No-credit Interval  Gross Profit to Sales  \\\n",
       "    3344                   0.000915            0.622968               0.600582   \n",
       "    2588                   0.000822            0.623872               0.618490   \n",
       "    4138                   0.000815            0.623774               0.603975   \n",
       "    6170                   0.000582            0.624056               0.607278   \n",
       "    3558                   0.005638            0.611917               0.611724   \n",
       "    ...                         ...                 ...                    ...   \n",
       "    2116                   0.004128            0.627145               0.600018   \n",
       "    1167                   0.034910            0.696240               0.615380   \n",
       "    4800                   0.002297            0.623631               0.608096   \n",
       "    373                    0.001336            0.622424               0.593952   \n",
       "    4398                   0.003375            0.625265               0.617174   \n",
       "    \n",
       "          Net Income to Stockholder's Equity  Liability to Equity  \\\n",
       "    3344                            0.837018             0.287105   \n",
       "    2588                            0.840772             0.277276   \n",
       "    4138                            0.839835             0.277661   \n",
       "    6170                            0.839955             0.275842   \n",
       "    3558                            0.843097             0.277787   \n",
       "    ...                                  ...                  ...   \n",
       "    2116                            0.841275             0.291902   \n",
       "    1167                            0.841347             0.275626   \n",
       "    4800                            0.841391             0.278617   \n",
       "    373                             0.838030             0.280452   \n",
       "    4398                            0.843112             0.276076   \n",
       "    \n",
       "          Degree of Financial Leverage (DFL)  \\\n",
       "    3344                            0.026534   \n",
       "    2588                            0.026945   \n",
       "    4138                            0.026700   \n",
       "    6170                            0.026853   \n",
       "    3558                            0.026817   \n",
       "    ...                                  ...   \n",
       "    2116                            0.028422   \n",
       "    1167                            0.026810   \n",
       "    4800                            0.026802   \n",
       "    373                             0.026418   \n",
       "    4398                            0.026791   \n",
       "    \n",
       "          Interest Coverage Ratio (Interest expense to EBIT)  Net Income Flag  \\\n",
       "    3344                                           0.563539                 1   \n",
       "    2588                                           0.565800                 1   \n",
       "    4138                                           0.564684                 1   \n",
       "    6170                                           0.565436                 1   \n",
       "    3558                                           0.565278                 1   \n",
       "    ...                                                 ...               ...   \n",
       "    2116                                           0.568216                 1   \n",
       "    1167                                           0.565246                 1   \n",
       "    4800                                           0.565209                 1   \n",
       "    373                                            0.562411                 1   \n",
       "    4398                                           0.565159                 1   \n",
       "    \n",
       "          Equity to Liability  \n",
       "    3344             0.018023  \n",
       "    2588             0.047539  \n",
       "    4138             0.042724  \n",
       "    6170             0.093639  \n",
       "    3558             0.041401  \n",
       "    ...                   ...  \n",
       "    2116             0.015853  \n",
       "    1167             0.112744  \n",
       "    4800             0.034829  \n",
       "    373              0.027008  \n",
       "    4398             0.079631  \n",
       "    \n",
       "    [5456 rows x 95 columns],\n",
       "    5319    0\n",
       "    3554    0\n",
       "    266     0\n",
       "    3285    0\n",
       "    1509    0\n",
       "           ..\n",
       "    5559    0\n",
       "    377     0\n",
       "    3838    0\n",
       "    5535    0\n",
       "    360     0\n",
       "    Name: Bankrupt?, Length: 1363, dtype: int64,\n",
       "    3344    0\n",
       "    2588    0\n",
       "    4138    0\n",
       "    6170    0\n",
       "    3558    0\n",
       "           ..\n",
       "    2116    0\n",
       "    1167    0\n",
       "    4800    0\n",
       "    373     0\n",
       "    4398    0\n",
       "    Name: Bankrupt?, Length: 5456, dtype: int64),\n",
       "   0.5: (      ROA(C) before interest and depreciation before interest  \\\n",
       "    4713                                           0.570711         \n",
       "    1984                                           0.484035         \n",
       "    89                                             0.468581         \n",
       "    678                                            0.484668         \n",
       "    3631                                           0.529372         \n",
       "    ...                                                 ...         \n",
       "    2623                                           0.586847         \n",
       "    5119                                           0.473456         \n",
       "    332                                            0.497489         \n",
       "    360                                            0.472773         \n",
       "    2903                                           0.551748         \n",
       "    \n",
       "          ROA(A) before interest and % after tax  \\\n",
       "    4713                                0.646478   \n",
       "    1984                                0.518753   \n",
       "    89                                  0.529165   \n",
       "    678                                 0.545028   \n",
       "    3631                                0.601068   \n",
       "    ...                                      ...   \n",
       "    2623                                0.642172   \n",
       "    5119                                0.490733   \n",
       "    332                                 0.555549   \n",
       "    360                                 0.538541   \n",
       "    2903                                0.561382   \n",
       "    \n",
       "          ROA(B) before interest and depreciation after tax  \\\n",
       "    4713                                           0.630226   \n",
       "    1984                                           0.540232   \n",
       "    89                                             0.522244   \n",
       "    678                                            0.543980   \n",
       "    3631                                           0.587398   \n",
       "    ...                                                 ...   \n",
       "    2623                                           0.623374   \n",
       "    5119                                           0.515285   \n",
       "    332                                            0.548370   \n",
       "    360                                            0.526045   \n",
       "    2903                                           0.597248   \n",
       "    \n",
       "          Operating Gross Margin  Realized Sales Gross Margin  \\\n",
       "    4713                0.611280                     0.610941   \n",
       "    1984                0.618566                     0.618566   \n",
       "    89                  0.598899                     0.598899   \n",
       "    678                 0.608037                     0.608037   \n",
       "    3631                0.626479                     0.626479   \n",
       "    ...                      ...                          ...   \n",
       "    2623                0.609774                     0.609759   \n",
       "    5119                0.608527                     0.608527   \n",
       "    332                 0.598553                     0.598553   \n",
       "    360                 0.599720                     0.599901   \n",
       "    2903                0.619164                     0.619092   \n",
       "    \n",
       "          Operating Profit Rate  Pre-tax net Interest Rate  \\\n",
       "    4713               0.999135                   0.797604   \n",
       "    1984               0.998847                   0.797216   \n",
       "    89                 0.998960                   0.797370   \n",
       "    678                0.998978                   0.797391   \n",
       "    3631               0.999279                   0.797627   \n",
       "    ...                     ...                        ...   \n",
       "    2623               0.999064                   0.797540   \n",
       "    5119               0.999061                   0.797306   \n",
       "    332                0.998946                   0.797547   \n",
       "    360                0.998959                   0.797407   \n",
       "    2903               0.999112                   0.797448   \n",
       "    \n",
       "          After-tax net Interest Rate  \\\n",
       "    4713                     0.809512   \n",
       "    1984                     0.809204   \n",
       "    89                       0.809299   \n",
       "    678                      0.809343   \n",
       "    3631                     0.809546   \n",
       "    ...                           ...   \n",
       "    2623                     0.809426   \n",
       "    5119                     0.809213   \n",
       "    332                      0.809464   \n",
       "    360                      0.809332   \n",
       "    2903                     0.809381   \n",
       "    \n",
       "          Non-industry income and expenditure/revenue  \\\n",
       "    4713                                     0.303553   \n",
       "    1984                                     0.303477   \n",
       "    89                                       0.303509   \n",
       "    678                                      0.303508   \n",
       "    3631                                     0.303292   \n",
       "    ...                                           ...   \n",
       "    2623                                     0.303589   \n",
       "    5119                                     0.303185   \n",
       "    332                                      0.303848   \n",
       "    360                                      0.303575   \n",
       "    2903                                     0.303328   \n",
       "    \n",
       "          Continuous interest rate (after tax)  ...  Net Income to Total Assets  \\\n",
       "    4713                              0.781787  ...                    0.855155   \n",
       "    1984                              0.781709  ...                    0.788436   \n",
       "    89                                0.781564  ...                    0.794000   \n",
       "    678                               0.781602  ...                    0.799786   \n",
       "    3631                              0.781811  ...                    0.834079   \n",
       "    ...                                    ...  ...                         ...   \n",
       "    2623                              0.781686  ...                    0.856548   \n",
       "    5119                              0.781463  ...                    0.769971   \n",
       "    332                               0.781730  ...                    0.808561   \n",
       "    360                               0.781579  ...                    0.800013   \n",
       "    2903                              0.781706  ...                    0.804942   \n",
       "    \n",
       "          Total assets to GNP price  No-credit Interval  Gross Profit to Sales  \\\n",
       "    4713                   0.000801            0.624185               0.611278   \n",
       "    1984                   0.000355            0.624425               0.618562   \n",
       "    89                     0.005715            0.624173               0.598898   \n",
       "    678                    0.002811            0.623311               0.608037   \n",
       "    3631                   0.005433            0.624297               0.626476   \n",
       "    ...                         ...                 ...                    ...   \n",
       "    2623                   0.000987            0.623850               0.609770   \n",
       "    5119                   0.000553            0.623857               0.608522   \n",
       "    332                    0.122128            0.618947               0.598552   \n",
       "    360                    0.002171            0.624355               0.599716   \n",
       "    2903                   0.013233            0.623925               0.619164   \n",
       "    \n",
       "          Net Income to Stockholder's Equity  Liability to Equity  \\\n",
       "    4713                            0.843648             0.276849   \n",
       "    1984                            0.839672             0.275122   \n",
       "    89                              0.839894             0.278864   \n",
       "    678                             0.840479             0.284536   \n",
       "    3631                            0.842164             0.276094   \n",
       "    ...                                  ...                  ...   \n",
       "    2623                            0.843796             0.277000   \n",
       "    5119                            0.838033             0.279201   \n",
       "    332                             0.841026             0.279334   \n",
       "    360                             0.840272             0.276271   \n",
       "    2903                            0.841410             0.290011   \n",
       "    \n",
       "          Degree of Financial Leverage (DFL)  \\\n",
       "    4713                            0.026792   \n",
       "    1984                            0.026791   \n",
       "    89                              0.026172   \n",
       "    678                             0.031708   \n",
       "    3631                            0.026798   \n",
       "    ...                                  ...   \n",
       "    2623                            0.026791   \n",
       "    5119                            0.026557   \n",
       "    332                             0.026992   \n",
       "    360                             0.027059   \n",
       "    2903                            0.028012   \n",
       "    \n",
       "          Interest Coverage Ratio (Interest expense to EBIT)  Net Income Flag  \\\n",
       "    4713                                           0.565161                 1   \n",
       "    1984                                           0.565158                 1   \n",
       "    89                                             0.558027                 1   \n",
       "    678                                            0.569306                 1   \n",
       "    3631                                           0.565189                 1   \n",
       "    ...                                                 ...               ...   \n",
       "    2623                                           0.565159                 1   \n",
       "    5119                                           0.563727                 1   \n",
       "    332                                            0.565963                 1   \n",
       "    360                                            0.566178                 1   \n",
       "    2903                                           0.567859                 1   \n",
       "    \n",
       "          Equity to Liability  \n",
       "    4713             0.054892  \n",
       "    1984             0.229864  \n",
       "    89               0.033376  \n",
       "    678              0.020055  \n",
       "    3631             0.078744  \n",
       "    ...                   ...  \n",
       "    2623             0.051988  \n",
       "    5119             0.031650  \n",
       "    332              0.031039  \n",
       "    360              0.071134  \n",
       "    2903             0.016546  \n",
       "    \n",
       "    [3409 rows x 95 columns],\n",
       "          ROA(C) before interest and depreciation before interest  \\\n",
       "    2077                                           0.500268         \n",
       "    4472                                           0.626822         \n",
       "    6400                                           0.491737         \n",
       "    5459                                           0.456979         \n",
       "    5104                                           0.520012         \n",
       "    ...                                                 ...         \n",
       "    555                                            0.456101         \n",
       "    5715                                           0.484620         \n",
       "    5223                                           0.598547         \n",
       "    2179                                           0.506069         \n",
       "    2194                                           0.485984         \n",
       "    \n",
       "          ROA(A) before interest and % after tax  \\\n",
       "    2077                                0.565798   \n",
       "    4472                                0.691234   \n",
       "    6400                                0.557839   \n",
       "    5459                                0.502072   \n",
       "    5104                                0.582861   \n",
       "    ...                                      ...   \n",
       "    555                                 0.506705   \n",
       "    5715                                0.548681   \n",
       "    5223                                0.662669   \n",
       "    2179                                0.562745   \n",
       "    2194                                0.559311   \n",
       "    \n",
       "          ROA(B) before interest and depreciation after tax  \\\n",
       "    2077                                           0.545479   \n",
       "    4472                                           0.680283   \n",
       "    6400                                           0.540018   \n",
       "    5459                                           0.503935   \n",
       "    5104                                           0.579046   \n",
       "    ...                                                 ...   \n",
       "    555                                            0.502382   \n",
       "    5715                                           0.535200   \n",
       "    5223                                           0.648375   \n",
       "    2179                                           0.559827   \n",
       "    2194                                           0.538198   \n",
       "    \n",
       "          Operating Gross Margin  Realized Sales Gross Margin  \\\n",
       "    2077                0.597025                     0.597025   \n",
       "    4472                0.617636                     0.617730   \n",
       "    6400                0.602927                     0.602927   \n",
       "    5459                0.594640                     0.594640   \n",
       "    5104                0.610307                     0.610307   \n",
       "    ...                      ...                          ...   \n",
       "    555                 0.599187                     0.599187   \n",
       "    5715                0.604261                     0.604261   \n",
       "    5223                0.599713                     0.599735   \n",
       "    2179                0.600722                     0.600722   \n",
       "    2194                0.599021                     0.599021   \n",
       "    \n",
       "          Operating Profit Rate  Pre-tax net Interest Rate  \\\n",
       "    2077               0.998992                   0.797428   \n",
       "    4472               0.999245                   0.797729   \n",
       "    6400               0.999007                   0.797445   \n",
       "    5459               0.998885                   0.797299   \n",
       "    5104               0.999046                   0.797459   \n",
       "    ...                     ...                        ...   \n",
       "    555                0.998862                   0.797264   \n",
       "    5715               0.999020                   0.797440   \n",
       "    5223               0.999029                   0.797492   \n",
       "    2179               0.999026                   0.797459   \n",
       "    2194               0.999005                   0.797446   \n",
       "    \n",
       "          After-tax net Interest Rate  \\\n",
       "    2077                     0.809341   \n",
       "    4472                     0.809607   \n",
       "    6400                     0.809356   \n",
       "    5459                     0.809217   \n",
       "    5104                     0.809390   \n",
       "    ...                           ...   \n",
       "    555                      0.809196   \n",
       "    5715                     0.809353   \n",
       "    5223                     0.809402   \n",
       "    2179                     0.809374   \n",
       "    2194                     0.809364   \n",
       "    \n",
       "          Non-industry income and expenditure/revenue  \\\n",
       "    2077                                     0.303543   \n",
       "    4472                                     0.303541   \n",
       "    6400                                     0.303543   \n",
       "    5459                                     0.303541   \n",
       "    5104                                     0.303486   \n",
       "    ...                                           ...   \n",
       "    555                                      0.303530   \n",
       "    5715                                     0.303506   \n",
       "    5223                                     0.303577   \n",
       "    2179                                     0.303527   \n",
       "    2194                                     0.303548   \n",
       "    \n",
       "          Continuous interest rate (after tax)  ...  Net Income to Total Assets  \\\n",
       "    2077                              0.781597  ...                    0.815040   \n",
       "    4472                              0.781895  ...                    0.880281   \n",
       "    6400                              0.781615  ...                    0.816155   \n",
       "    5459                              0.781425  ...                    0.778199   \n",
       "    5104                              0.781664  ...                    0.824166   \n",
       "    ...                                    ...  ...                         ...   \n",
       "    555                               0.781446  ...                    0.780194   \n",
       "    5715                              0.781593  ...                    0.803351   \n",
       "    5223                              0.781667  ...                    0.861971   \n",
       "    2179                              0.781637  ...                    0.810491   \n",
       "    2194                              0.781616  ...                    0.813723   \n",
       "    \n",
       "          Total assets to GNP price  No-credit Interval  Gross Profit to Sales  \\\n",
       "    2077                   0.000843            0.624039               0.597027   \n",
       "    4472                   0.002145            0.624413               0.617635   \n",
       "    6400                   0.001191            0.624136               0.602925   \n",
       "    5459                   0.000898            0.623971               0.594640   \n",
       "    5104                   0.000497            0.623917               0.610309   \n",
       "    ...                         ...                 ...                    ...   \n",
       "    555                    0.002413            0.623344               0.599189   \n",
       "    5715                   0.004121            0.623693               0.604260   \n",
       "    5223                   0.024571            0.624185               0.599710   \n",
       "    2179                   0.002701            0.621591               0.600718   \n",
       "    2194                   0.001314            0.624386               0.599023   \n",
       "    \n",
       "          Net Income to Stockholder's Equity  Liability to Equity  \\\n",
       "    2077                            0.842096             0.283582   \n",
       "    4472                            0.844907             0.276383   \n",
       "    6400                            0.841120             0.275768   \n",
       "    5459                            0.837777             0.286443   \n",
       "    5104                            0.842312             0.279670   \n",
       "    ...                                  ...                  ...   \n",
       "    555                             0.838960             0.277951   \n",
       "    5715                            0.840719             0.281285   \n",
       "    5223                            0.846294             0.281716   \n",
       "    2179                            0.841737             0.284880   \n",
       "    2194                            0.841308             0.278348   \n",
       "    \n",
       "          Degree of Financial Leverage (DFL)  \\\n",
       "    2077                            0.026792   \n",
       "    4472                            0.026791   \n",
       "    6400                            0.026799   \n",
       "    5459                            0.026646   \n",
       "    5104                            0.026871   \n",
       "    ...                                  ...   \n",
       "    555                             0.026669   \n",
       "    5715                            0.027296   \n",
       "    5223                            0.026795   \n",
       "    2179                            0.027133   \n",
       "    2194                            0.026796   \n",
       "    \n",
       "          Interest Coverage Ratio (Interest expense to EBIT)  Net Income Flag  \\\n",
       "    2077                                           0.565162                 1   \n",
       "    4472                                           0.565158                 1   \n",
       "    6400                                           0.565195                 1   \n",
       "    5459                                           0.564356                 1   \n",
       "    5104                                           0.565512                 1   \n",
       "    ...                                                 ...               ...   \n",
       "    555                                            0.564499                 1   \n",
       "    5715                                           0.566788                 1   \n",
       "    5223                                           0.565176                 1   \n",
       "    2179                                           0.566389                 1   \n",
       "    2194                                           0.565182                 1   \n",
       "    \n",
       "          Equity to Liability  \n",
       "    2077             0.021108  \n",
       "    4472             0.067111  \n",
       "    6400             0.099342  \n",
       "    5459             0.018462  \n",
       "    5104             0.029636  \n",
       "    ...                   ...  \n",
       "    555              0.039842  \n",
       "    5715             0.024890  \n",
       "    5223             0.023992  \n",
       "    2179             0.019723  \n",
       "    2194             0.036633  \n",
       "    \n",
       "    [3410 rows x 95 columns],\n",
       "    4713    0\n",
       "    1984    0\n",
       "    89      0\n",
       "    678     0\n",
       "    3631    0\n",
       "           ..\n",
       "    2623    0\n",
       "    5119    0\n",
       "    332     0\n",
       "    360     0\n",
       "    2903    0\n",
       "    Name: Bankrupt?, Length: 3409, dtype: int64,\n",
       "    2077    0\n",
       "    4472    0\n",
       "    6400    0\n",
       "    5459    0\n",
       "    5104    0\n",
       "           ..\n",
       "    555     0\n",
       "    5715    0\n",
       "    5223    0\n",
       "    2179    0\n",
       "    2194    0\n",
       "    Name: Bankrupt?, Length: 3410, dtype: int64),\n",
       "   0.8: (      ROA(C) before interest and depreciation before interest  \\\n",
       "    318                                            0.493784         \n",
       "    5796                                           0.534393         \n",
       "    4454                                           0.526398         \n",
       "    2225                                           0.469702         \n",
       "    3249                                           0.391557         \n",
       "    ...                                                 ...         \n",
       "    4688                                           0.550090         \n",
       "    1078                                           0.481597         \n",
       "    6687                                           0.622288         \n",
       "    2623                                           0.586847         \n",
       "    665                                            0.500951         \n",
       "    \n",
       "          ROA(A) before interest and % after tax  \\\n",
       "    318                                 0.550153   \n",
       "    5796                                0.590765   \n",
       "    4454                                0.586895   \n",
       "    2225                                0.536851   \n",
       "    3249                                0.443197   \n",
       "    ...                                      ...   \n",
       "    4688                                0.563890   \n",
       "    1078                                0.528129   \n",
       "    6687                                0.707697   \n",
       "    2623                                0.642172   \n",
       "    665                                 0.566616   \n",
       "    \n",
       "          ROA(B) before interest and depreciation after tax  \\\n",
       "    318                                            0.544622   \n",
       "    5796                                           0.573425   \n",
       "    4454                                           0.566519   \n",
       "    2225                                           0.521066   \n",
       "    3249                                           0.432464   \n",
       "    ...                                                 ...   \n",
       "    4688                                           0.593501   \n",
       "    1078                                           0.530007   \n",
       "    6687                                           0.689330   \n",
       "    2623                                           0.623374   \n",
       "    665                                            0.550244   \n",
       "    \n",
       "          Operating Gross Margin  Realized Sales Gross Margin  \\\n",
       "    318                 0.598524                     0.598524   \n",
       "    5796                0.599302                     0.599173   \n",
       "    4454                0.606740                     0.606740   \n",
       "    2225                0.595375                     0.595375   \n",
       "    3249                0.664495                     0.664495   \n",
       "    ...                      ...                          ...   \n",
       "    4688                0.602221                     0.602221   \n",
       "    1078                0.605933                     0.605954   \n",
       "    6687                0.614293                     0.603353   \n",
       "    2623                0.609774                     0.609759   \n",
       "    665                 0.608952                     0.608837   \n",
       "    \n",
       "          Operating Profit Rate  Pre-tax net Interest Rate  \\\n",
       "    318                0.998980                   0.797443   \n",
       "    5796               0.999023                   0.797454   \n",
       "    4454               0.999103                   0.797606   \n",
       "    2225               0.998967                   0.797390   \n",
       "    3249               0.995856                   0.794096   \n",
       "    ...                     ...                        ...   \n",
       "    4688               0.999046                   0.797482   \n",
       "    1078               0.999021                   0.797349   \n",
       "    6687               0.998882                   0.799178   \n",
       "    2623               0.999064                   0.797540   \n",
       "    665                0.999027                   0.797460   \n",
       "    \n",
       "          After-tax net Interest Rate  \\\n",
       "    318                      0.809355   \n",
       "    5796                     0.809359   \n",
       "    4454                     0.809470   \n",
       "    2225                     0.809313   \n",
       "    3249                     0.806216   \n",
       "    ...                           ...   \n",
       "    4688                     0.809400   \n",
       "    1078                     0.809262   \n",
       "    6687                     0.811001   \n",
       "    2623                     0.809426   \n",
       "    665                      0.809367   \n",
       "    \n",
       "          Non-industry income and expenditure/revenue  \\\n",
       "    318                                      0.303595   \n",
       "    5796                                     0.303524   \n",
       "    4454                                     0.303622   \n",
       "    2225                                     0.303530   \n",
       "    3249                                     0.304281   \n",
       "    ...                                           ...   \n",
       "    4688                                     0.303527   \n",
       "    1078                                     0.303343   \n",
       "    6687                                     0.306831   \n",
       "    2623                                     0.303589   \n",
       "    665                                      0.303527   \n",
       "    \n",
       "          Continuous interest rate (after tax)  ...  Net Income to Total Assets  \\\n",
       "    318                               0.781616  ...                    0.806631   \n",
       "    5796                              0.781621  ...                    0.827723   \n",
       "    4454                              0.781718  ...                    0.828627   \n",
       "    2225                              0.781572  ...                    0.797846   \n",
       "    3249                              0.777918  ...                    0.756573   \n",
       "    ...                                    ...  ...                         ...   \n",
       "    4688                              0.781665  ...                    0.811639   \n",
       "    1078                              0.781612  ...                    0.791904   \n",
       "    6687                              0.783383  ...                    0.875503   \n",
       "    2623                              0.781686  ...                    0.856548   \n",
       "    665                               0.781623  ...                    0.811462   \n",
       "    \n",
       "          Total assets to GNP price  No-credit Interval  Gross Profit to Sales  \\\n",
       "    318                    0.001637            0.623661               0.598521   \n",
       "    5796                   0.001079            0.624307               0.599298   \n",
       "    4454                   0.002505            0.624714               0.606739   \n",
       "    2225                   0.003100            0.624621               0.595370   \n",
       "    3249                   0.000198            0.624242               0.664491   \n",
       "    ...                         ...                 ...                    ...   \n",
       "    4688                   0.318807            0.623799               0.602217   \n",
       "    1078                   0.001990            0.623473               0.605932   \n",
       "    6687                   0.002238            0.624557               0.614294   \n",
       "    2623                   0.000987            0.623850               0.609770   \n",
       "    665                    0.002435            0.623780               0.608950   \n",
       "    \n",
       "          Net Income to Stockholder's Equity  Liability to Equity  \\\n",
       "    318                             0.840649             0.276281   \n",
       "    5796                            0.843248             0.282615   \n",
       "    4454                            0.841982             0.276632   \n",
       "    2225                            0.840248             0.283786   \n",
       "    3249                            0.838115             0.275114   \n",
       "    ...                                  ...                  ...   \n",
       "    4688                            0.841515             0.281613   \n",
       "    1078                            0.839643             0.282249   \n",
       "    6687                            0.844092             0.275407   \n",
       "    2623                            0.843796             0.277000   \n",
       "    665                             0.841359             0.280314   \n",
       "    \n",
       "          Degree of Financial Leverage (DFL)  \\\n",
       "    318                             0.026814   \n",
       "    5796                            0.026852   \n",
       "    4454                            0.026791   \n",
       "    2225                            0.027673   \n",
       "    3249                            0.026791   \n",
       "    ...                                  ...   \n",
       "    4688                            0.026865   \n",
       "    1078                            0.025451   \n",
       "    6687                            0.026794   \n",
       "    2623                            0.026791   \n",
       "    665                             0.027077   \n",
       "    \n",
       "          Interest Coverage Ratio (Interest expense to EBIT)  Net Income Flag  \\\n",
       "    318                                            0.565265                 1   \n",
       "    5796                                           0.565433                 1   \n",
       "    4454                                           0.565159                 1   \n",
       "    2225                                           0.567450                 1   \n",
       "    3249                                           0.565158                 1   \n",
       "    ...                                                 ...               ...   \n",
       "    4688                                           0.565486                 1   \n",
       "    1078                                           0.588994                 1   \n",
       "    6687                                           0.565172                 1   \n",
       "    2623                                           0.565159                 1   \n",
       "    665                                            0.566231                 1   \n",
       "    \n",
       "          Equity to Liability  \n",
       "    318              0.070742  \n",
       "    5796             0.022433  \n",
       "    4454             0.059856  \n",
       "    2225             0.020864  \n",
       "    3249             0.233952  \n",
       "    ...                   ...  \n",
       "    4688             0.024197  \n",
       "    1078             0.023023  \n",
       "    6687             0.143685  \n",
       "    2623             0.051988  \n",
       "    665              0.027417  \n",
       "    \n",
       "    [5455 rows x 95 columns],\n",
       "          ROA(C) before interest and depreciation before interest  \\\n",
       "    1244                                           0.503242         \n",
       "    6303                                           0.485984         \n",
       "    4712                                           0.554380         \n",
       "    3273                                           0.663920         \n",
       "    6430                                           0.450641         \n",
       "    ...                                                 ...         \n",
       "    4163                                           0.485010         \n",
       "    635                                            0.482328         \n",
       "    6086                                           0.522352         \n",
       "    2308                                           0.480330         \n",
       "    652                                            0.450544         \n",
       "    \n",
       "          ROA(A) before interest and % after tax  \\\n",
       "    1244                                0.556149   \n",
       "    6303                                0.547754   \n",
       "    4712                                0.618513   \n",
       "    3273                                0.692324   \n",
       "    6430                                0.509976   \n",
       "    ...                                      ...   \n",
       "    4163                                0.571849   \n",
       "    635                                 0.539304   \n",
       "    6086                                0.580844   \n",
       "    2308                                0.547372   \n",
       "    652                                 0.521860   \n",
       "    \n",
       "          ROA(B) before interest and depreciation after tax  \\\n",
       "    1244                                           0.552278   \n",
       "    6303                                           0.530649   \n",
       "    4712                                           0.609562   \n",
       "    3273                                           0.709246   \n",
       "    6430                                           0.495423   \n",
       "    ...                                                 ...   \n",
       "    4163                                           0.533166   \n",
       "    635                                            0.533915   \n",
       "    6086                                           0.563895   \n",
       "    2308                                           0.530917   \n",
       "    652                                            0.509342   \n",
       "    \n",
       "          Operating Gross Margin  Realized Sales Gross Margin  \\\n",
       "    1244                0.609399                     0.609399   \n",
       "    6303                0.598812                     0.598812   \n",
       "    4712                0.607857                     0.607886   \n",
       "    3273                0.630097                     0.630097   \n",
       "    6430                0.650492                     0.650226   \n",
       "    ...                      ...                          ...   \n",
       "    4163                0.596009                     0.596016   \n",
       "    635                 0.601508                     0.601594   \n",
       "    6086                0.599101                     0.599101   \n",
       "    2308                0.596672                     0.596600   \n",
       "    652                 0.595367                     0.595367   \n",
       "    \n",
       "          Operating Profit Rate  Pre-tax net Interest Rate  \\\n",
       "    1244               0.999043                   0.797445   \n",
       "    6303               0.999002                   0.797424   \n",
       "    4712               0.999043                   0.797758   \n",
       "    3273               0.999314                   0.797808   \n",
       "    6430               0.998738                   0.797212   \n",
       "    ...                     ...                        ...   \n",
       "    4163               0.998993                   0.797445   \n",
       "    635                0.998971                   0.797374   \n",
       "    6086               0.999025                   0.797482   \n",
       "    2308               0.998990                   0.797422   \n",
       "    652                0.998903                   0.797253   \n",
       "    \n",
       "          After-tax net Interest Rate  \\\n",
       "    1244                     0.809349   \n",
       "    6303                     0.809331   \n",
       "    4712                     0.809638   \n",
       "    3273                     0.809651   \n",
       "    6430                     0.809081   \n",
       "    ...                           ...   \n",
       "    4163                     0.809361   \n",
       "    635                      0.809312   \n",
       "    6086                     0.809378   \n",
       "    2308                     0.809339   \n",
       "    652                      0.809222   \n",
       "    \n",
       "          Non-industry income and expenditure/revenue  \\\n",
       "    1244                                     0.303466   \n",
       "    6303                                     0.303516   \n",
       "    4712                                     0.304012   \n",
       "    3273                                     0.303533   \n",
       "    6430                                     0.303697   \n",
       "    ...                                           ...   \n",
       "    4163                                     0.303570   \n",
       "    635                                      0.303494   \n",
       "    6086                                     0.303570   \n",
       "    2308                                     0.303536   \n",
       "    652                                      0.303422   \n",
       "    \n",
       "          Continuous interest rate (after tax)  ...  Net Income to Total Assets  \\\n",
       "    1244                              0.781609  ...                    0.805667   \n",
       "    6303                              0.781591  ...                    0.803448   \n",
       "    4712                              0.781922  ...                    0.839238   \n",
       "    3273                              0.781935  ...                    0.879037   \n",
       "    6430                              0.781240  ...                    0.782600   \n",
       "    ...                                    ...  ...                         ...   \n",
       "    4163                              0.781590  ...                    0.817094   \n",
       "    635                               0.781570  ...                    0.796868   \n",
       "    6086                              0.781642  ...                    0.824578   \n",
       "    2308                              0.781598  ...                    0.804941   \n",
       "    652                               0.781478  ...                    0.785460   \n",
       "    \n",
       "          Total assets to GNP price  No-credit Interval  Gross Profit to Sales  \\\n",
       "    1244                   0.000830            0.623746               0.609399   \n",
       "    6303                   0.001949            0.623652               0.598810   \n",
       "    4712                   0.002042            0.623843               0.607852   \n",
       "    3273                   0.001139            0.624215               0.630092   \n",
       "    6430                   0.000845            0.623938               0.650488   \n",
       "    ...                         ...                 ...                    ...   \n",
       "    4163                   0.128326            0.624345               0.596005   \n",
       "    635                    0.001333            0.623546               0.601509   \n",
       "    6086                   0.002461            0.624393               0.599101   \n",
       "    2308                   0.007575            0.623754               0.596672   \n",
       "    652                    0.021615            0.623690               0.595363   \n",
       "    \n",
       "          Net Income to Stockholder's Equity  Liability to Equity  \\\n",
       "    1244                            0.841004             0.282359   \n",
       "    6303                            0.840585             0.278525   \n",
       "    4712                            0.843206             0.278607   \n",
       "    3273                            0.844936             0.276559   \n",
       "    6430                            0.839382             0.275173   \n",
       "    ...                                  ...                  ...   \n",
       "    4163                            0.841934             0.280973   \n",
       "    635                             0.840141             0.283866   \n",
       "    6086                            0.842427             0.280082   \n",
       "    2308                            0.841049             0.284223   \n",
       "    652                             0.838732             0.286043   \n",
       "    \n",
       "          Degree of Financial Leverage (DFL)  \\\n",
       "    1244                            0.027273   \n",
       "    6303                            0.027098   \n",
       "    4712                            0.026816   \n",
       "    3273                            0.026805   \n",
       "    6430                            0.026709   \n",
       "    ...                                  ...   \n",
       "    4163                            0.026812   \n",
       "    635                             0.022002   \n",
       "    6086                            0.026797   \n",
       "    2308                            0.026808   \n",
       "    652                             0.026271   \n",
       "    \n",
       "          Interest Coverage Ratio (Interest expense to EBIT)  Net Income Flag  \\\n",
       "    1244                                           0.566736                 1   \n",
       "    6303                                           0.566292                 1   \n",
       "    4712                                           0.565273                 1   \n",
       "    3273                                           0.565222                 1   \n",
       "    6430                                           0.564734                 1   \n",
       "    ...                                                 ...               ...   \n",
       "    4163                                           0.565254                 1   \n",
       "    635                                            0.571624                 1   \n",
       "    6086                                           0.565185                 1   \n",
       "    2308                                           0.565239                 1   \n",
       "    652                                            0.560278                 1   \n",
       "    \n",
       "          Equity to Liability  \n",
       "    1244             0.022839  \n",
       "    6303             0.035415  \n",
       "    4712             0.034892  \n",
       "    3273             0.061798  \n",
       "    6430             0.207130  \n",
       "    ...                   ...  \n",
       "    4163             0.025617  \n",
       "    635              0.020771  \n",
       "    6086             0.028154  \n",
       "    2308             0.020377  \n",
       "    652              0.018752  \n",
       "    \n",
       "    [1364 rows x 95 columns],\n",
       "    318     0\n",
       "    5796    0\n",
       "    4454    0\n",
       "    2225    0\n",
       "    3249    0\n",
       "           ..\n",
       "    4688    0\n",
       "    1078    0\n",
       "    6687    0\n",
       "    2623    0\n",
       "    665     0\n",
       "    Name: Bankrupt?, Length: 5455, dtype: int64,\n",
       "    1244    0\n",
       "    6303    0\n",
       "    4712    0\n",
       "    3273    0\n",
       "    6430    0\n",
       "           ..\n",
       "    4163    0\n",
       "    635     0\n",
       "    6086    0\n",
       "    2308    0\n",
       "    652     0\n",
       "    Name: Bankrupt?, Length: 1364, dtype: int64)},\n",
       "  99: {0.2: (      ROA(C) before interest and depreciation before interest  \\\n",
       "    550                                            0.428752         \n",
       "    3034                                           0.437820         \n",
       "    18                                             0.504071         \n",
       "    4346                                           0.486423         \n",
       "    3524                                           0.531809         \n",
       "    ...                                                 ...         \n",
       "    1875                                           0.507629         \n",
       "    4626                                           0.643641         \n",
       "    3558                                           0.577000         \n",
       "    435                                            0.437820         \n",
       "    6692                                           0.578560         \n",
       "    \n",
       "          ROA(A) before interest and % after tax  \\\n",
       "    550                                 0.470617   \n",
       "    3034                                0.501090   \n",
       "    18                                  0.559802   \n",
       "    4346                                0.548245   \n",
       "    3524                                0.610772   \n",
       "    ...                                      ...   \n",
       "    1875                                0.562309   \n",
       "    4626                                0.715493   \n",
       "    3558                                0.626254   \n",
       "    435                                 0.451483   \n",
       "    6692                                0.611699   \n",
       "    \n",
       "          ROA(B) before interest and depreciation after tax  \\\n",
       "    550                                            0.475561   \n",
       "    3034                                           0.497136   \n",
       "    18                                             0.558649   \n",
       "    4346                                           0.537502   \n",
       "    3524                                           0.592912   \n",
       "    ...                                                 ...   \n",
       "    1875                                           0.558702   \n",
       "    4626                                           0.724503   \n",
       "    3558                                           0.629798   \n",
       "    435                                            0.485465   \n",
       "    6692                                           0.610150   \n",
       "    \n",
       "          Operating Gross Margin  Realized Sales Gross Margin  \\\n",
       "    550                 0.589400                     0.589400   \n",
       "    3034                0.622897                     0.622897   \n",
       "    18                  0.598344                     0.598344   \n",
       "    4346                0.602120                     0.602142   \n",
       "    3524                0.599295                     0.599295   \n",
       "    ...                      ...                          ...   \n",
       "    1875                0.600794                     0.600823   \n",
       "    4626                0.611042                     0.611042   \n",
       "    3558                0.611727                     0.610531   \n",
       "    435                 0.591706                     0.591706   \n",
       "    6692                0.615208                     0.615006   \n",
       "    \n",
       "          Operating Profit Rate  Pre-tax net Interest Rate  \\\n",
       "    550                0.998872                   0.797253   \n",
       "    3034               0.998876                   0.797267   \n",
       "    18                 0.998989                   0.797412   \n",
       "    4346               0.998992                   0.797434   \n",
       "    3524               0.999037                   0.797451   \n",
       "    ...                     ...                        ...   \n",
       "    1875               0.999019                   0.797412   \n",
       "    4626               0.999188                   0.797663   \n",
       "    3558               0.999161                   0.797730   \n",
       "    435                0.998861                   0.797099   \n",
       "    6692               0.999142                   0.797680   \n",
       "    \n",
       "          After-tax net Interest Rate  \\\n",
       "    550                      0.809196   \n",
       "    3034                     0.809227   \n",
       "    18                       0.809334   \n",
       "    4346                     0.809348   \n",
       "    3524                     0.809376   \n",
       "    ...                           ...   \n",
       "    1875                     0.809337   \n",
       "    4626                     0.809590   \n",
       "    3558                     0.809602   \n",
       "    435                      0.809035   \n",
       "    6692                     0.809517   \n",
       "    \n",
       "          Non-industry income and expenditure/revenue  \\\n",
       "    550                                      0.303489   \n",
       "    3034                                     0.303504   \n",
       "    18                                       0.303523   \n",
       "    4346                                     0.303554   \n",
       "    3524                                     0.303490   \n",
       "    ...                                           ...   \n",
       "    1875                                     0.303460   \n",
       "    4626                                     0.303543   \n",
       "    3558                                     0.303718   \n",
       "    435                                      0.303243   \n",
       "    6692                                     0.303671   \n",
       "    \n",
       "          Continuous interest rate (after tax)  ...  Net Income to Total Assets  \\\n",
       "    550                               0.781453  ...                    0.753398   \n",
       "    3034                              0.781478  ...                    0.778212   \n",
       "    18                                0.781588  ...                    0.806264   \n",
       "    4346                              0.781609  ...                    0.805548   \n",
       "    3524                              0.781637  ...                    0.826060   \n",
       "    ...                                    ...  ...                         ...   \n",
       "    1875                              0.781600  ...                    0.811383   \n",
       "    4626                              0.781868  ...                    0.874132   \n",
       "    3558                              0.781883  ...                    0.841267   \n",
       "    435                               0.781421  ...                    0.743379   \n",
       "    6692                              0.781802  ...                    0.832089   \n",
       "    \n",
       "          Total assets to GNP price  No-credit Interval  Gross Profit to Sales  \\\n",
       "    550                    0.007980            0.627632               0.589398   \n",
       "    3034                   0.000538            0.623851               0.622893   \n",
       "    18                     0.004238            0.623339               0.598345   \n",
       "    4346                   0.002869            0.623757               0.602120   \n",
       "    3524                   0.000945            0.624871               0.599292   \n",
       "    ...                         ...                 ...                    ...   \n",
       "    1875                   0.013698            0.624026               0.600795   \n",
       "    4626                   0.000311            0.637491               0.611041   \n",
       "    3558                   0.005638            0.611917               0.611724   \n",
       "    435                    0.003693            0.623154               0.591705   \n",
       "    6692                   0.000444            0.624122               0.615208   \n",
       "    \n",
       "          Net Income to Stockholder's Equity  Liability to Equity  \\\n",
       "    550                             0.836579             0.279788   \n",
       "    3034                            0.839039             0.276203   \n",
       "    18                              0.840955             0.280839   \n",
       "    4346                            0.840712             0.278144   \n",
       "    3524                            0.844212             0.288027   \n",
       "    ...                                  ...                  ...   \n",
       "    1875                            0.841327             0.280075   \n",
       "    4626                            0.844474             0.276239   \n",
       "    3558                            0.843097             0.277787   \n",
       "    435                             0.835567             0.280329   \n",
       "    6692                            0.842516             0.277940   \n",
       "    \n",
       "          Degree of Financial Leverage (DFL)  \\\n",
       "    550                             0.026702   \n",
       "    3034                            0.026791   \n",
       "    18                              0.027637   \n",
       "    4346                            0.026874   \n",
       "    3524                            0.026791   \n",
       "    ...                                  ...   \n",
       "    1875                            0.027020   \n",
       "    4626                            0.026802   \n",
       "    3558                            0.026817   \n",
       "    435                             0.026748   \n",
       "    6692                            0.026837   \n",
       "    \n",
       "          Interest Coverage Ratio (Interest expense to EBIT)  Net Income Flag  \\\n",
       "    550                                            0.564693                 1   \n",
       "    3034                                           0.565158                 1   \n",
       "    18                                             0.567399                 1   \n",
       "    4346                                           0.565525                 1   \n",
       "    3524                                           0.565158                 1   \n",
       "    ...                                                 ...               ...   \n",
       "    1875                                           0.566054                 1   \n",
       "    4626                                           0.565210                 1   \n",
       "    3558                                           0.565278                 1   \n",
       "    435                                            0.564942                 1   \n",
       "    6692                                           0.565366                 1   \n",
       "    \n",
       "          Equity to Liability  \n",
       "    550              0.029187  \n",
       "    3034             0.073852  \n",
       "    18               0.025953  \n",
       "    4346             0.038184  \n",
       "    3524             0.017485  \n",
       "    ...                   ...  \n",
       "    1875             0.028179  \n",
       "    4626             0.072386  \n",
       "    3558             0.041401  \n",
       "    435              0.027372  \n",
       "    6692             0.039935  \n",
       "    \n",
       "    [1363 rows x 95 columns],\n",
       "          ROA(C) before interest and depreciation before interest  \\\n",
       "    3082                                           0.577487         \n",
       "    5997                                           0.538098         \n",
       "    232                                            0.345781         \n",
       "    2490                                           0.412178         \n",
       "    4662                                           0.485546         \n",
       "    ...                                                 ...         \n",
       "    1205                                           0.504607         \n",
       "    1250                                           0.482670         \n",
       "    6755                                           0.525130         \n",
       "    1332                                           0.453469         \n",
       "    1571                                           0.425876         \n",
       "    \n",
       "          ROA(A) before interest and % after tax  \\\n",
       "    3082                                0.613552   \n",
       "    5997                                0.593655   \n",
       "    232                                 0.393153   \n",
       "    2490                                0.474270   \n",
       "    4662                                0.511230   \n",
       "    ...                                      ...   \n",
       "    1205                                0.556258   \n",
       "    1250                                0.534943   \n",
       "    6755                                0.551461   \n",
       "    1332                                0.513029   \n",
       "    1571                                0.472634   \n",
       "    \n",
       "          ROA(B) before interest and depreciation after tax  \\\n",
       "    3082                                           0.617645   \n",
       "    5997                                           0.576637   \n",
       "    232                                            0.386584   \n",
       "    2490                                           0.457733   \n",
       "    4662                                           0.531827   \n",
       "    ...                                                 ...   \n",
       "    1205                                           0.558595   \n",
       "    1250                                           0.536164   \n",
       "    6755                                           0.574602   \n",
       "    1332                                           0.499866   \n",
       "    1571                                           0.475828   \n",
       "    \n",
       "          Operating Gross Margin  Realized Sales Gross Margin  \\\n",
       "    3082                0.637426                     0.637390   \n",
       "    5997                0.604571                     0.604571   \n",
       "    232                 0.586618                     0.586618   \n",
       "    2490                0.000000                     0.000000   \n",
       "    4662                0.607424                     0.607424   \n",
       "    ...                      ...                          ...   \n",
       "    1205                0.603259                     0.603259   \n",
       "    1250                0.600131                     0.600146   \n",
       "    6755                0.623099                     0.623099   \n",
       "    1332                0.594906                     0.594906   \n",
       "    1571                0.598856                     0.598856   \n",
       "    \n",
       "          Operating Profit Rate  Pre-tax net Interest Rate  \\\n",
       "    3082               0.999312                   0.797713   \n",
       "    5997               0.999014                   0.797633   \n",
       "    232                0.998705                   0.795845   \n",
       "    2490               0.988045                   0.784312   \n",
       "    4662               0.998986                   0.797335   \n",
       "    ...                     ...                        ...   \n",
       "    1205               0.999027                   0.797437   \n",
       "    1250               0.998997                   0.797343   \n",
       "    6755               0.999130                   0.797502   \n",
       "    1332               0.998918                   0.797330   \n",
       "    1571               0.998655                   0.796918   \n",
       "    \n",
       "          After-tax net Interest Rate  \\\n",
       "    3082                     0.809545   \n",
       "    5997                     0.809484   \n",
       "    232                      0.807862   \n",
       "    2490                     0.796607   \n",
       "    4662                     0.809254   \n",
       "    ...                           ...   \n",
       "    1205                     0.809354   \n",
       "    1250                     0.809269   \n",
       "    6755                     0.809414   \n",
       "    1332                     0.809257   \n",
       "    1571                     0.808930   \n",
       "    \n",
       "          Non-industry income and expenditure/revenue  \\\n",
       "    3082                                     0.303372   \n",
       "    5997                                     0.303857   \n",
       "    232                                      0.301379   \n",
       "    2490                                     0.303526   \n",
       "    4662                                     0.303394   \n",
       "    ...                                           ...   \n",
       "    1205                                     0.303486   \n",
       "    1250                                     0.303386   \n",
       "    6755                                     0.303384   \n",
       "    1332                                     0.303527   \n",
       "    1571                                     0.303358   \n",
       "    \n",
       "          Continuous interest rate (after tax)  ...  Net Income to Total Assets  \\\n",
       "    3082                              0.781834  ...                    0.839896   \n",
       "    5997                              0.781756  ...                    0.827532   \n",
       "    232                               0.780007  ...                    0.707756   \n",
       "    2490                              0.767874  ...                    0.766285   \n",
       "    4662                              0.781582  ...                    0.783517   \n",
       "    ...                                    ...  ...                         ...   \n",
       "    1205                              0.781615  ...                    0.805466   \n",
       "    1250                              0.781527  ...                    0.790864   \n",
       "    6755                              0.781722  ...                    0.806106   \n",
       "    1332                              0.781511  ...                    0.780123   \n",
       "    1571                              0.781156  ...                    0.765001   \n",
       "    \n",
       "          Total assets to GNP price  No-credit Interval  Gross Profit to Sales  \\\n",
       "    3082                   0.000674            0.623748               0.637426   \n",
       "    5997                   0.002359            0.623907               0.604569   \n",
       "    232                    0.002074            0.619739               0.586617   \n",
       "    2490                   0.002466            0.626786               0.000000   \n",
       "    4662                   0.000658            0.623772               0.607425   \n",
       "    ...                         ...                 ...                    ...   \n",
       "    1205                   0.002003            0.623309               0.603261   \n",
       "    1250                   0.029459            0.625679               0.600132   \n",
       "    6755                   0.001866            0.624078               0.623098   \n",
       "    1332                   0.001240            0.623408               0.594906   \n",
       "    1571                   0.000516            0.623654               0.598854   \n",
       "    \n",
       "          Net Income to Stockholder's Equity  Liability to Equity  \\\n",
       "    3082                            0.843524             0.279491   \n",
       "    5997                            0.842199             0.277917   \n",
       "    232                             0.827501             0.288556   \n",
       "    2490                            0.838652             0.274813   \n",
       "    4662                            0.839118             0.278757   \n",
       "    ...                                  ...                  ...   \n",
       "    1205                            0.841249             0.286358   \n",
       "    1250                            0.839467             0.284310   \n",
       "    6755                            0.840896             0.280200   \n",
       "    1332                            0.837297             0.293054   \n",
       "    1571                            0.837738             0.278789   \n",
       "    \n",
       "          Degree of Financial Leverage (DFL)  \\\n",
       "    3082                            0.026895   \n",
       "    5997                            0.026795   \n",
       "    232                             0.026706   \n",
       "    2490                            0.026789   \n",
       "    4662                            0.026657   \n",
       "    ...                                  ...   \n",
       "    1205                            0.027422   \n",
       "    1250                            0.024462   \n",
       "    6755                            0.027013   \n",
       "    1332                            0.026356   \n",
       "    1571                            0.026699   \n",
       "    \n",
       "          Interest Coverage Ratio (Interest expense to EBIT)  Net Income Flag  \\\n",
       "    3082                                           0.565608                 1   \n",
       "    5997                                           0.565177                 1   \n",
       "    232                                            0.564714                 1   \n",
       "    2490                                           0.565148                 1   \n",
       "    4662                                           0.564429                 1   \n",
       "    ...                                                 ...               ...   \n",
       "    1205                                           0.567042                 1   \n",
       "    1250                                           0.574384                 1   \n",
       "    6755                                           0.566032                 1   \n",
       "    1332                                           0.561637                 1   \n",
       "    1571                                           0.564679                 1   \n",
       "    \n",
       "          Equity to Liability  \n",
       "    3082             0.030358  \n",
       "    5997             0.040146  \n",
       "    232              0.017208  \n",
       "    2490             0.743588  \n",
       "    4662             0.033984  \n",
       "    ...                   ...  \n",
       "    1205             0.018522  \n",
       "    1250             0.020286  \n",
       "    6755             0.027774  \n",
       "    1332             0.015501  \n",
       "    1571             0.033798  \n",
       "    \n",
       "    [5456 rows x 95 columns],\n",
       "    550     0\n",
       "    3034    0\n",
       "    18      0\n",
       "    4346    0\n",
       "    3524    0\n",
       "           ..\n",
       "    1875    0\n",
       "    4626    0\n",
       "    3558    0\n",
       "    435     0\n",
       "    6692    0\n",
       "    Name: Bankrupt?, Length: 1363, dtype: int64,\n",
       "    3082    0\n",
       "    5997    0\n",
       "    232     1\n",
       "    2490    0\n",
       "    4662    0\n",
       "           ..\n",
       "    1205    0\n",
       "    1250    0\n",
       "    6755    0\n",
       "    1332    0\n",
       "    1571    0\n",
       "    Name: Bankrupt?, Length: 5456, dtype: int64),\n",
       "   0.5: (      ROA(C) before interest and depreciation before interest  \\\n",
       "    6727                                           0.512114         \n",
       "    2724                                           0.491347         \n",
       "    2403                                           0.489689         \n",
       "    4994                                           0.392239         \n",
       "    2529                                           0.523278         \n",
       "    ...                                                 ...         \n",
       "    4358                                           0.417248         \n",
       "    1078                                           0.481597         \n",
       "    4187                                           0.504022         \n",
       "    6692                                           0.578560         \n",
       "    1817                                           0.533418         \n",
       "    \n",
       "          ROA(A) before interest and % after tax  \\\n",
       "    6727                                0.563618   \n",
       "    2724                                0.539086   \n",
       "    2403                                0.539904   \n",
       "    4994                                0.460423   \n",
       "    2529                                0.583406   \n",
       "    ...                                      ...   \n",
       "    4358                                0.483101   \n",
       "    1078                                0.528129   \n",
       "    4187                                0.570759   \n",
       "    6692                                0.611699   \n",
       "    1817                                0.582316   \n",
       "    \n",
       "          ROA(B) before interest and depreciation after tax  \\\n",
       "    6727                                           0.555597   \n",
       "    2724                                           0.547781   \n",
       "    2403                                           0.543070   \n",
       "    4994                                           0.434980   \n",
       "    2529                                           0.568285   \n",
       "    ...                                                 ...   \n",
       "    4358                                           0.471974   \n",
       "    1078                                           0.530007   \n",
       "    4187                                           0.556186   \n",
       "    6692                                           0.610150   \n",
       "    1817                                           0.578189   \n",
       "    \n",
       "          Operating Gross Margin  Realized Sales Gross Margin  \\\n",
       "    6727                0.612635                     0.612635   \n",
       "    2724                0.601183                     0.601183   \n",
       "    2403                0.634032                     0.634032   \n",
       "    4994                0.599410                     0.599980   \n",
       "    2529                0.623532                     0.623532   \n",
       "    ...                      ...                          ...   \n",
       "    4358                0.601724                     0.601839   \n",
       "    1078                0.605933                     0.605954   \n",
       "    4187                0.598783                     0.598783   \n",
       "    6692                0.615208                     0.615006   \n",
       "    1817                0.616397                     0.616397   \n",
       "    \n",
       "          Operating Profit Rate  Pre-tax net Interest Rate  \\\n",
       "    6727               0.999117                   0.797566   \n",
       "    2724               0.998985                   0.797383   \n",
       "    2403               0.999457                   0.797516   \n",
       "    4994               0.998891                   0.797023   \n",
       "    2529               0.999313                   0.797733   \n",
       "    ...                     ...                        ...   \n",
       "    4358               0.998843                   0.797229   \n",
       "    1078               0.999021                   0.797349   \n",
       "    4187               0.998978                   0.797411   \n",
       "    6692               0.999142                   0.797680   \n",
       "    1817               0.999129                   0.797586   \n",
       "    \n",
       "          After-tax net Interest Rate  \\\n",
       "    6727                     0.809430   \n",
       "    2724                     0.809316   \n",
       "    2403                     0.809435   \n",
       "    4994                     0.808965   \n",
       "    2529                     0.809593   \n",
       "    ...                           ...   \n",
       "    4358                     0.809181   \n",
       "    1078                     0.809262   \n",
       "    4187                     0.809333   \n",
       "    6692                     0.809517   \n",
       "    1817                     0.809471   \n",
       "    \n",
       "          Non-industry income and expenditure/revenue  \\\n",
       "    6727                                     0.303523   \n",
       "    2724                                     0.303479   \n",
       "    2403                                     0.302725   \n",
       "    4994                                     0.303047   \n",
       "    2529                                     0.303407   \n",
       "    ...                                           ...   \n",
       "    4358                                     0.303507   \n",
       "    1078                                     0.303343   \n",
       "    4187                                     0.303544   \n",
       "    6692                                     0.303671   \n",
       "    1817                                     0.303533   \n",
       "    \n",
       "          Continuous interest rate (after tax)  ...  Net Income to Total Assets  \\\n",
       "    6727                              0.781708  ...                    0.810813   \n",
       "    2724                              0.781564  ...                    0.797106   \n",
       "    2403                              0.782239  ...                    0.799345   \n",
       "    4994                              0.781127  ...                    0.752078   \n",
       "    2529                              0.781808  ...                    0.825290   \n",
       "    ...                                    ...  ...                         ...   \n",
       "    4358                              0.781429  ...                    0.762560   \n",
       "    1078                              0.781612  ...                    0.791904   \n",
       "    4187                              0.781590  ...                    0.817583   \n",
       "    6692                              0.781802  ...                    0.832089   \n",
       "    1817                              0.781736  ...                    0.825649   \n",
       "    \n",
       "          Total assets to GNP price  No-credit Interval  Gross Profit to Sales  \\\n",
       "    6727                   0.002144            0.623476               0.612634   \n",
       "    2724                   0.001530            0.623628               0.601184   \n",
       "    2403                   0.005450            0.619269               0.634032   \n",
       "    4994                   0.000459            0.623785               0.599412   \n",
       "    2529                   0.007579            0.625594               0.623528   \n",
       "    ...                         ...                 ...                    ...   \n",
       "    4358                   0.001488            0.623640               0.601720   \n",
       "    1078                   0.001990            0.623473               0.605932   \n",
       "    4187                   0.011530            0.623809               0.598784   \n",
       "    6692                   0.000444            0.624122               0.615208   \n",
       "    1817                   0.001234            0.624147               0.616398   \n",
       "    \n",
       "          Net Income to Stockholder's Equity  Liability to Equity  \\\n",
       "    6727                            0.841197             0.279281   \n",
       "    2724                            0.840120             0.277995   \n",
       "    2403                            0.840314             0.279664   \n",
       "    4994                            0.837138             0.277600   \n",
       "    2529                            0.841684             0.276138   \n",
       "    ...                                  ...                  ...   \n",
       "    4358                            0.835654             0.286998   \n",
       "    1078                            0.839643             0.282249   \n",
       "    4187                            0.842155             0.282152   \n",
       "    6692                            0.842516             0.277940   \n",
       "    1817                            0.841884             0.277015   \n",
       "    \n",
       "          Degree of Financial Leverage (DFL)  \\\n",
       "    6727                            0.026793   \n",
       "    2724                            0.043423   \n",
       "    2403                            0.027858   \n",
       "    4994                            0.026776   \n",
       "    2529                            0.026803   \n",
       "    ...                                  ...   \n",
       "    4358                            0.026657   \n",
       "    1078                            0.025451   \n",
       "    4187                            0.026853   \n",
       "    6692                            0.026837   \n",
       "    1817                            0.026791   \n",
       "    \n",
       "          Interest Coverage Ratio (Interest expense to EBIT)  Net Income Flag  \\\n",
       "    6727                                           0.565166                 1   \n",
       "    2724                                           0.569896                 1   \n",
       "    2403                                           0.567689                 1   \n",
       "    4994                                           0.565086                 1   \n",
       "    2529                                           0.565213                 1   \n",
       "    ...                                                 ...               ...   \n",
       "    4358                                           0.564425                 1   \n",
       "    1078                                           0.588994                 1   \n",
       "    4187                                           0.565435                 1   \n",
       "    6692                                           0.565366                 1   \n",
       "    1817                                           0.565158                 1   \n",
       "    \n",
       "          Equity to Liability  \n",
       "    6727             0.031277  \n",
       "    2724             0.039447  \n",
       "    2403             0.029661  \n",
       "    4994             0.043395  \n",
       "    2529             0.076664  \n",
       "    ...                   ...  \n",
       "    4358             0.018091  \n",
       "    1078             0.023023  \n",
       "    4187             0.023189  \n",
       "    6692             0.039935  \n",
       "    1817             0.051715  \n",
       "    \n",
       "    [3409 rows x 95 columns],\n",
       "          ROA(C) before interest and depreciation before interest  \\\n",
       "    3062                                           0.476868         \n",
       "    4985                                           0.408375         \n",
       "    908                                            0.543460         \n",
       "    415                                            0.511822         \n",
       "    5204                                           0.484083         \n",
       "    ...                                                 ...         \n",
       "    6478                                           0.488422         \n",
       "    5091                                           0.452299         \n",
       "    3267                                           0.476820         \n",
       "    2000                                           0.348608         \n",
       "    5188                                           0.539658         \n",
       "    \n",
       "          ROA(A) before interest and % after tax  \\\n",
       "    3062                                0.539468   \n",
       "    4985                                0.452191   \n",
       "    908                                 0.601941   \n",
       "    415                                 0.566997   \n",
       "    5204                                0.552769   \n",
       "    ...                                      ...   \n",
       "    6478                                0.560674   \n",
       "    5091                                0.477322   \n",
       "    3267                                0.517881   \n",
       "    2000                                0.334932   \n",
       "    5188                                0.596326   \n",
       "    \n",
       "          ROA(B) before interest and depreciation after tax  \\\n",
       "    3062                                           0.526474   \n",
       "    4985                                           0.450452   \n",
       "    908                                            0.584881   \n",
       "    415                                            0.559345   \n",
       "    5204                                           0.537663   \n",
       "    ...                                                 ...   \n",
       "    6478                                           0.543230   \n",
       "    5091                                           0.492692   \n",
       "    3267                                           0.530489   \n",
       "    2000                                           0.345950   \n",
       "    5188                                           0.576690   \n",
       "    \n",
       "          Operating Gross Margin  Realized Sales Gross Margin  \\\n",
       "    3062                0.628108                     0.628101   \n",
       "    4985                0.588355                     0.588355   \n",
       "    908                 0.606048                     0.606149   \n",
       "    415                 0.601306                     0.601306   \n",
       "    5204                0.606084                     0.606084   \n",
       "    ...                      ...                          ...   \n",
       "    6478                0.631092                     0.630587   \n",
       "    5091                0.599036                     0.600045   \n",
       "    3267                0.600837                     0.600542   \n",
       "    2000                0.602747                     0.602747   \n",
       "    5188                0.605111                     0.605111   \n",
       "    \n",
       "          Operating Profit Rate  Pre-tax net Interest Rate  \\\n",
       "    3062               0.998987                   0.797442   \n",
       "    4985               0.998780                   0.797150   \n",
       "    908                0.999051                   0.797585   \n",
       "    415                0.999030                   0.797462   \n",
       "    5204               0.999028                   0.797422   \n",
       "    ...                     ...                        ...   \n",
       "    6478               0.999259                   0.797519   \n",
       "    5091               0.998776                   0.797019   \n",
       "    3267               0.998947                   0.797264   \n",
       "    2000               0.998745                   0.797081   \n",
       "    5188               0.999058                   0.797520   \n",
       "    \n",
       "          After-tax net Interest Rate  \\\n",
       "    3062                     0.809345   \n",
       "    4985                     0.809091   \n",
       "    908                      0.809459   \n",
       "    415                      0.809367   \n",
       "    5204                     0.809345   \n",
       "    ...                           ...   \n",
       "    6478                     0.809438   \n",
       "    5091                     0.808887   \n",
       "    3267                     0.809198   \n",
       "    2000                     0.808965   \n",
       "    5188                     0.809405   \n",
       "    \n",
       "          Non-industry income and expenditure/revenue  \\\n",
       "    3062                                     0.303578   \n",
       "    4985                                     0.303503   \n",
       "    908                                      0.303694   \n",
       "    415                                      0.303523   \n",
       "    5204                                     0.303457   \n",
       "    ...                                           ...   \n",
       "    6478                                     0.303145   \n",
       "    5091                                     0.303280   \n",
       "    3267                                     0.303352   \n",
       "    2000                                     0.303454   \n",
       "    5188                                     0.303566   \n",
       "    \n",
       "          Continuous interest rate (after tax)  ...  Net Income to Total Assets  \\\n",
       "    3062                              0.781600  ...                    0.800461   \n",
       "    4985                              0.781331  ...                    0.753803   \n",
       "    908                               0.781729  ...                    0.836071   \n",
       "    415                               0.781628  ...                    0.815212   \n",
       "    5204                              0.781599  ...                    0.807690   \n",
       "    ...                                    ...  ...                         ...   \n",
       "    6478                              0.781693  ...                    0.812408   \n",
       "    5091                              0.781106  ...                    0.761121   \n",
       "    3267                              0.781447  ...                    0.784212   \n",
       "    2000                              0.781203  ...                    0.659323   \n",
       "    5188                              0.781666  ...                    0.830511   \n",
       "    \n",
       "          Total assets to GNP price  No-credit Interval  Gross Profit to Sales  \\\n",
       "    3062                   0.002329            0.623878               0.628107   \n",
       "    4985                   0.001973            0.623935               0.588352   \n",
       "    908                    0.000650            0.623849               0.606043   \n",
       "    415                    0.002827            0.624019               0.601303   \n",
       "    5204                   0.000656            0.624044               0.606081   \n",
       "    ...                         ...                 ...                    ...   \n",
       "    6478                   0.000598            0.623892               0.631088   \n",
       "    5091                   0.000907            0.617107               0.599037   \n",
       "    3267                   0.002877            0.624787               0.600834   \n",
       "    2000                   0.000222            0.623715               0.602749   \n",
       "    5188                   0.002225            0.624411               0.605106   \n",
       "    \n",
       "          Net Income to Stockholder's Equity  Liability to Equity  \\\n",
       "    3062                            0.840322             0.277069   \n",
       "    4985                            0.837660             0.276205   \n",
       "    908                             0.842788             0.277935   \n",
       "    415                             0.841669             0.280248   \n",
       "    5204                            0.840833             0.277790   \n",
       "    ...                                  ...                  ...   \n",
       "    6478                            0.841220             0.278398   \n",
       "    5091                            0.836996             0.280662   \n",
       "    3267                            0.839138             0.279145   \n",
       "    2000                            0.824903             0.284034   \n",
       "    5188                            0.842240             0.277238   \n",
       "    \n",
       "          Degree of Financial Leverage (DFL)  \\\n",
       "    3062                            0.026937   \n",
       "    4985                            0.026791   \n",
       "    908                             0.026809   \n",
       "    415                             0.026879   \n",
       "    5204                            0.026860   \n",
       "    ...                                  ...   \n",
       "    6478                            0.026877   \n",
       "    5091                            0.026648   \n",
       "    3267                            0.026282   \n",
       "    2000                            0.026772   \n",
       "    5188                            0.026795   \n",
       "    \n",
       "          Interest Coverage Ratio (Interest expense to EBIT)  Net Income Flag  \\\n",
       "    3062                                           0.565768                 1   \n",
       "    4985                                           0.565157                 1   \n",
       "    908                                            0.565244                 1   \n",
       "    415                                            0.565545                 1   \n",
       "    5204                                           0.565468                 1   \n",
       "    ...                                                 ...               ...   \n",
       "    6478                                           0.565539                 1   \n",
       "    5091                                           0.564370                 1   \n",
       "    3267                                           0.560473                 1   \n",
       "    2000                                           0.565065                 1   \n",
       "    5188                                           0.565178                 1   \n",
       "    \n",
       "          Equity to Liability  \n",
       "    3062             0.050778  \n",
       "    4985             0.073778  \n",
       "    908              0.039980  \n",
       "    415              0.027622  \n",
       "    5204             0.041372  \n",
       "    ...                   ...  \n",
       "    6478             0.036280  \n",
       "    5091             0.026417  \n",
       "    3267             0.031919  \n",
       "    2000             0.020582  \n",
       "    5188             0.048097  \n",
       "    \n",
       "    [3410 rows x 95 columns],\n",
       "    6727    0\n",
       "    2724    0\n",
       "    2403    0\n",
       "    4994    0\n",
       "    2529    0\n",
       "           ..\n",
       "    4358    0\n",
       "    1078    0\n",
       "    4187    0\n",
       "    6692    0\n",
       "    1817    0\n",
       "    Name: Bankrupt?, Length: 3409, dtype: int64,\n",
       "    3062    0\n",
       "    4985    0\n",
       "    908     0\n",
       "    415     0\n",
       "    5204    0\n",
       "           ..\n",
       "    6478    0\n",
       "    5091    0\n",
       "    3267    0\n",
       "    2000    1\n",
       "    5188    0\n",
       "    Name: Bankrupt?, Length: 3410, dtype: int64),\n",
       "   0.8: (      ROA(C) before interest and depreciation before interest  \\\n",
       "    4264                                           0.407400         \n",
       "    6436                                           0.525764         \n",
       "    1989                                           0.485107         \n",
       "    3291                                           0.516160         \n",
       "    344                                            0.483888         \n",
       "    ...                                                 ...         \n",
       "    4358                                           0.417248         \n",
       "    4941                                           0.561156         \n",
       "    4187                                           0.504022         \n",
       "    3185                                           0.383172         \n",
       "    1817                                           0.533418         \n",
       "    \n",
       "          ROA(A) before interest and % after tax  \\\n",
       "    4264                                0.442652   \n",
       "    6436                                0.581280   \n",
       "    1989                                0.544265   \n",
       "    3291                                0.580462   \n",
       "    344                                 0.547863   \n",
       "    ...                                      ...   \n",
       "    4358                                0.483101   \n",
       "    4941                                0.551025   \n",
       "    4187                                0.570759   \n",
       "    3185                                0.437473   \n",
       "    1817                                0.582316   \n",
       "    \n",
       "          ROA(B) before interest and depreciation after tax  \\\n",
       "    4264                                           0.438086   \n",
       "    6436                                           0.568660   \n",
       "    1989                                           0.531720   \n",
       "    3291                                           0.566465   \n",
       "    344                                            0.536699   \n",
       "    ...                                                 ...   \n",
       "    4358                                           0.471974   \n",
       "    4941                                           0.601906   \n",
       "    4187                                           0.556186   \n",
       "    3185                                           0.430162   \n",
       "    1817                                           0.578189   \n",
       "    \n",
       "          Operating Gross Margin  Realized Sales Gross Margin  \\\n",
       "    4264                0.609349                     0.609320   \n",
       "    6436                0.607871                     0.607871   \n",
       "    1989                0.603461                     0.603468   \n",
       "    3291                0.595411                     0.595411   \n",
       "    344                 0.599994                     0.599994   \n",
       "    ...                      ...                          ...   \n",
       "    4358                0.601724                     0.601839   \n",
       "    4941                0.608304                     0.608304   \n",
       "    4187                0.598783                     0.598783   \n",
       "    3185                0.587908                     0.588319   \n",
       "    1817                0.616397                     0.616397   \n",
       "    \n",
       "          Operating Profit Rate  Pre-tax net Interest Rate  \\\n",
       "    4264               0.998786                   0.797106   \n",
       "    6436               0.999073                   0.797517   \n",
       "    1989               0.999015                   0.797407   \n",
       "    3291               0.998984                   0.797399   \n",
       "    344                0.998992                   0.797496   \n",
       "    ...                     ...                        ...   \n",
       "    4358               0.998843                   0.797229   \n",
       "    4941               0.999111                   0.797449   \n",
       "    4187               0.998978                   0.797411   \n",
       "    3185               0.998625                   0.795355   \n",
       "    1817               0.999129                   0.797586   \n",
       "    \n",
       "          After-tax net Interest Rate  \\\n",
       "    4264                     0.808996   \n",
       "    6436                     0.809405   \n",
       "    1989                     0.809323   \n",
       "    3291                     0.809322   \n",
       "    344                      0.809406   \n",
       "    ...                           ...   \n",
       "    4358                     0.809181   \n",
       "    4941                     0.809393   \n",
       "    4187                     0.809333   \n",
       "    3185                     0.807452   \n",
       "    1817                     0.809471   \n",
       "    \n",
       "          Non-industry income and expenditure/revenue  \\\n",
       "    4264                                     0.303413   \n",
       "    6436                                     0.303529   \n",
       "    1989                                     0.303460   \n",
       "    3291                                     0.303510   \n",
       "    344                                      0.303662   \n",
       "    ...                                           ...   \n",
       "    4358                                     0.303507   \n",
       "    4941                                     0.303331   \n",
       "    4187                                     0.303544   \n",
       "    3185                                     0.300689   \n",
       "    1817                                     0.303533   \n",
       "    \n",
       "          Continuous interest rate (after tax)  ...  Net Income to Total Assets  \\\n",
       "    4264                              0.781230  ...                    0.727838   \n",
       "    6436                              0.781667  ...                    0.822730   \n",
       "    1989                              0.781576  ...                    0.798981   \n",
       "    3291                              0.781581  ...                    0.817023   \n",
       "    344                               0.781651  ...                    0.805924   \n",
       "    ...                                    ...  ...                         ...   \n",
       "    4358                              0.781429  ...                    0.762560   \n",
       "    4941                              0.781681  ...                    0.810099   \n",
       "    4187                              0.781590  ...                    0.817583   \n",
       "    3185                              0.779563  ...                    0.735119   \n",
       "    1817                              0.781736  ...                    0.825649   \n",
       "    \n",
       "          Total assets to GNP price  No-credit Interval  Gross Profit to Sales  \\\n",
       "    4264                   0.000782            0.623797               0.609344   \n",
       "    6436                   0.001143            0.623627               0.607868   \n",
       "    1989                   0.001906            0.623813               0.603461   \n",
       "    3291                   0.001200            0.623435               0.595410   \n",
       "    344                    0.033828            0.621534               0.599991   \n",
       "    ...                         ...                 ...                    ...   \n",
       "    4358                   0.001488            0.623640               0.601720   \n",
       "    4941                   0.009458            0.623457               0.608299   \n",
       "    4187                   0.011530            0.623809               0.598784   \n",
       "    3185                   0.006008            0.624290               0.587907   \n",
       "    1817                   0.001234            0.624147               0.616398   \n",
       "    \n",
       "          Net Income to Stockholder's Equity  Liability to Equity  \\\n",
       "    4264                            0.831255             0.286656   \n",
       "    6436                            0.842560             0.281623   \n",
       "    1989                            0.840348             0.282668   \n",
       "    3291                            0.844430             0.298076   \n",
       "    344                             0.840758             0.278438   \n",
       "    ...                                  ...                  ...   \n",
       "    4358                            0.835654             0.286998   \n",
       "    4941                            0.841037             0.278217   \n",
       "    4187                            0.842155             0.282152   \n",
       "    3185                            0.836667             0.276059   \n",
       "    1817                            0.841884             0.277015   \n",
       "    \n",
       "          Degree of Financial Leverage (DFL)  \\\n",
       "    4264                            0.026645   \n",
       "    6436                            0.026794   \n",
       "    1989                            0.028244   \n",
       "    3291                            0.026983   \n",
       "    344                             0.026809   \n",
       "    ...                                  ...   \n",
       "    4358                            0.026657   \n",
       "    4941                            0.027223   \n",
       "    4187                            0.026853   \n",
       "    3185                            0.026772   \n",
       "    1817                            0.026791   \n",
       "    \n",
       "          Interest Coverage Ratio (Interest expense to EBIT)  Net Income Flag  \\\n",
       "    4264                                           0.564353                 1   \n",
       "    6436                                           0.565170                 1   \n",
       "    1989                                           0.568075                 1   \n",
       "    3291                                           0.565932                 1   \n",
       "    344                                            0.565244                 1   \n",
       "    ...                                                 ...               ...   \n",
       "    4358                                           0.564425                 1   \n",
       "    4941                                           0.566621                 1   \n",
       "    4187                                           0.565435                 1   \n",
       "    3185                                           0.565064                 1   \n",
       "    1817                                           0.565158                 1   \n",
       "    \n",
       "          Equity to Liability  \n",
       "    4264             0.018316  \n",
       "    6436             0.024178  \n",
       "    1989             0.022353  \n",
       "    3291             0.014369  \n",
       "    344              0.036001  \n",
       "    ...                   ...  \n",
       "    4358             0.018091  \n",
       "    4941             0.037614  \n",
       "    4187             0.023189  \n",
       "    3185             0.080511  \n",
       "    1817             0.051715  \n",
       "    \n",
       "    [5455 rows x 95 columns],\n",
       "          ROA(C) before interest and depreciation before interest  \\\n",
       "    182                                            0.519037         \n",
       "    255                                            0.547994         \n",
       "    4436                                           0.483596         \n",
       "    6103                                           0.488276         \n",
       "    5753                                           0.495442         \n",
       "    ...                                                 ...         \n",
       "    409                                            0.499342         \n",
       "    474                                            0.507483         \n",
       "    6804                                           0.478672         \n",
       "    2152                                           0.449130         \n",
       "    1119                                           0.454346         \n",
       "    \n",
       "          ROA(A) before interest and % after tax  \\\n",
       "    182                                 0.579645   \n",
       "    255                                 0.603140   \n",
       "    4436                                0.543938   \n",
       "    6103                                0.538868   \n",
       "    5753                                0.528238   \n",
       "    ...                                      ...   \n",
       "    409                                 0.558003   \n",
       "    474                                 0.547263   \n",
       "    6804                                0.544701   \n",
       "    2152                                0.541158   \n",
       "    1119                                0.514119   \n",
       "    \n",
       "          ROA(B) before interest and depreciation after tax  \\\n",
       "    182                                            0.570641   \n",
       "    255                                            0.592698   \n",
       "    4436                                           0.531667   \n",
       "    6103                                           0.534290   \n",
       "    5753                                           0.541410   \n",
       "    ...                                                 ...   \n",
       "    409                                            0.548156   \n",
       "    474                                            0.553188   \n",
       "    6804                                           0.530703   \n",
       "    2152                                           0.500294   \n",
       "    1119                                           0.505809   \n",
       "    \n",
       "          Operating Gross Margin  Realized Sales Gross Margin  \\\n",
       "    182                 0.606682                     0.606624   \n",
       "    255                 0.614444                     0.614444   \n",
       "    4436                0.596621                     0.596571   \n",
       "    6103                0.599569                     0.599663   \n",
       "    5753                0.604117                     0.604117   \n",
       "    ...                      ...                          ...   \n",
       "    409                 0.605810                     0.606084   \n",
       "    474                 0.596448                     0.596448   \n",
       "    6804                0.600744                     0.600744   \n",
       "    2152                0.597890                     0.597890   \n",
       "    1119                0.595850                     0.595894   \n",
       "    \n",
       "          Operating Profit Rate  Pre-tax net Interest Rate  \\\n",
       "    182                0.999036                   0.797490   \n",
       "    255                0.999173                   0.797714   \n",
       "    4436               0.998964                   0.797387   \n",
       "    6103               0.998972                   0.797392   \n",
       "    5753               0.998924                   0.797355   \n",
       "    ...                     ...                        ...   \n",
       "    409                0.999043                   0.797477   \n",
       "    474                0.998991                   0.797393   \n",
       "    6804               0.999006                   0.797423   \n",
       "    2152               0.998953                   0.797391   \n",
       "    1119               0.998888                   0.797128   \n",
       "    \n",
       "          After-tax net Interest Rate  \\\n",
       "    182                      0.809398   \n",
       "    255                      0.809561   \n",
       "    4436                     0.809312   \n",
       "    6103                     0.809313   \n",
       "    5753                     0.809283   \n",
       "    ...                           ...   \n",
       "    409                      0.809378   \n",
       "    474                      0.809318   \n",
       "    6804                     0.809344   \n",
       "    2152                     0.809319   \n",
       "    1119                     0.809069   \n",
       "    \n",
       "          Non-industry income and expenditure/revenue  \\\n",
       "    182                                      0.303562   \n",
       "    255                                      0.303664   \n",
       "    4436                                     0.303531   \n",
       "    6103                                     0.303523   \n",
       "    5753                                     0.303558   \n",
       "    ...                                           ...   \n",
       "    409                                      0.303523   \n",
       "    474                                      0.303485   \n",
       "    6804                                     0.303506   \n",
       "    2152                                     0.303559   \n",
       "    1119                                     0.303236   \n",
       "    \n",
       "          Continuous interest rate (after tax)  ...  Net Income to Total Assets  \\\n",
       "    182                               0.781664  ...                    0.822927   \n",
       "    255                               0.781841  ...                    0.832671   \n",
       "    4436                              0.781569  ...                    0.799448   \n",
       "    6103                              0.781565  ...                    0.797447   \n",
       "    5753                              0.781563  ...                    0.791492   \n",
       "    ...                                    ...  ...                         ...   \n",
       "    409                               0.781643  ...                    0.810357   \n",
       "    474                               0.781577  ...                    0.800601   \n",
       "    6804                              0.781605  ...                    0.804195   \n",
       "    2152                              0.781365  ...                    0.796984   \n",
       "    1119                              0.781324  ...                    0.781570   \n",
       "    \n",
       "          Total assets to GNP price  No-credit Interval  Gross Profit to Sales  \\\n",
       "    182                    0.001219            0.623847               0.606683   \n",
       "    255                    0.011333            0.623890               0.614440   \n",
       "    4436                   0.000352            0.623824               0.596617   \n",
       "    6103                   0.001313            0.624583               0.599571   \n",
       "    5753                   0.000490            0.623950               0.604118   \n",
       "    ...                         ...                 ...                    ...   \n",
       "    409                    0.003299            0.623724               0.605810   \n",
       "    474                    0.003993            0.625135               0.596443   \n",
       "    6804                   0.003066            0.623762               0.600740   \n",
       "    2152                   0.028592            0.622056               0.597889   \n",
       "    1119                   0.010464            0.619045               0.595852   \n",
       "    \n",
       "          Net Income to Stockholder's Equity  Liability to Equity  \\\n",
       "    182                             0.842246             0.279848   \n",
       "    255                             0.842372             0.277218   \n",
       "    4436                            0.840706             0.295460   \n",
       "    6103                            0.840184             0.281912   \n",
       "    5753                            0.839631             0.281321   \n",
       "    ...                                  ...                  ...   \n",
       "    409                             0.841301             0.280671   \n",
       "    474                             0.840625             0.286153   \n",
       "    6804                            0.840497             0.276053   \n",
       "    2152                            0.840129             0.280343   \n",
       "    1119                            0.838237             0.286143   \n",
       "    \n",
       "          Degree of Financial Leverage (DFL)  \\\n",
       "    182                             0.026841   \n",
       "    255                             0.026858   \n",
       "    4436                            0.028089   \n",
       "    6103                            0.028806   \n",
       "    5753                            0.025877   \n",
       "    ...                                  ...   \n",
       "    409                             0.026923   \n",
       "    474                             0.028366   \n",
       "    6804                            0.026791   \n",
       "    2152                            0.035016   \n",
       "    1119                            0.026359   \n",
       "    \n",
       "          Interest Coverage Ratio (Interest expense to EBIT)  Net Income Flag  \\\n",
       "    182                                            0.565384                 1   \n",
       "    255                                            0.565460                 1   \n",
       "    4436                                           0.567935                 1   \n",
       "    6103                                           0.568464                 1   \n",
       "    5753                                           0.532957                 1   \n",
       "    ...                                                 ...               ...   \n",
       "    409                                            0.565717                 1   \n",
       "    474                                            0.568173                 1   \n",
       "    6804                                           0.565159                 1   \n",
       "    2152                                           0.569624                 1   \n",
       "    1119                                           0.561673                 1   \n",
       "    \n",
       "          Equity to Liability  \n",
       "    182              0.028967  \n",
       "    255              0.048387  \n",
       "    4436             0.014890  \n",
       "    6103             0.023620  \n",
       "    5753             0.024810  \n",
       "    ...                   ...  \n",
       "    409              0.026394  \n",
       "    474              0.018670  \n",
       "    6804             0.080805  \n",
       "    2152             0.027330  \n",
       "    1119             0.018678  \n",
       "    \n",
       "    [1364 rows x 95 columns],\n",
       "    4264    1\n",
       "    6436    0\n",
       "    1989    0\n",
       "    3291    0\n",
       "    344     0\n",
       "           ..\n",
       "    4358    0\n",
       "    4941    0\n",
       "    4187    0\n",
       "    3185    0\n",
       "    1817    0\n",
       "    Name: Bankrupt?, Length: 5455, dtype: int64,\n",
       "    182     0\n",
       "    255     0\n",
       "    4436    0\n",
       "    6103    0\n",
       "    5753    0\n",
       "           ..\n",
       "    409     0\n",
       "    474     0\n",
       "    6804    0\n",
       "    2152    0\n",
       "    1119    0\n",
       "    Name: Bankrupt?, Length: 1364, dtype: int64)}},\n",
       " 'gender': {0: {0.2: (        char_1  char_2  char_3  char_4  char_5  char_6  char_7  char_8  \\\n",
       "    98134      3.0     0.0    13.0    13.0    24.0    11.0    24.0    13.0   \n",
       "    16973      3.0     0.0    19.0    -1.0    -1.0    -1.0    -1.0    -1.0   \n",
       "    92461     11.0     4.0     9.0     0.0    -1.0    -1.0    -1.0    -1.0   \n",
       "    91908      9.0     0.0    12.0    24.0    17.0     8.0     4.0    -1.0   \n",
       "    84403      9.0     0.0    12.0     4.0    13.0     0.0    -1.0    -1.0   \n",
       "    ...        ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "    14564     10.0     8.0     4.0    17.0    14.0    13.0    -1.0    -1.0   \n",
       "    135896     2.0     0.0    24.0    11.0     8.0    12.0    -1.0    -1.0   \n",
       "    76451     25.0    24.0    11.0     8.0    24.0     0.0     7.0    -1.0   \n",
       "    73074     11.0     0.0    19.0    20.0    13.0     8.0     0.0    -1.0   \n",
       "    9707      18.0     7.0     0.0    12.0     8.0    17.0    -1.0    -1.0   \n",
       "    \n",
       "            char_9  char_10  ...  char_18  char_19  char_20  char_21  char_22  \\\n",
       "    98134     13.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    16973     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    92461     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    91908     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    84403     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    ...        ...      ...  ...      ...      ...      ...      ...      ...   \n",
       "    14564     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    135896    -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    76451     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    73074     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    9707      -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    \n",
       "            char_23  char_24  char_25   Count   Probability  \n",
       "    98134      -1.0     -1.0     -1.0     5.0  1.368370e-08  \n",
       "    16973      -1.0     -1.0     -1.0   558.0  1.527100e-06  \n",
       "    92461      -1.0     -1.0     -1.0     6.0  1.642040e-08  \n",
       "    91908      -1.0     -1.0     -1.0     6.0  1.642040e-08  \n",
       "    84403      -1.0     -1.0     -1.0    10.0  2.736740e-08  \n",
       "    ...         ...      ...      ...     ...           ...  \n",
       "    14564      -1.0     -1.0     -1.0   710.0  1.943090e-06  \n",
       "    135896     -1.0     -1.0     -1.0     1.0  2.736740e-09  \n",
       "    76451      -1.0     -1.0     -1.0    15.0  4.105110e-08  \n",
       "    73074      -1.0     -1.0     -1.0    17.0  4.652460e-08  \n",
       "    9707       -1.0     -1.0     -1.0  1319.0  3.609760e-06  \n",
       "    \n",
       "    [29453 rows x 27 columns],\n",
       "            char_1  char_2  char_3  char_4  char_5  char_6  char_7  char_8  \\\n",
       "    78044     12.0     4.0    17.0    17.0     8.0     0.0    13.0    -1.0   \n",
       "    24254     10.0     7.0     8.0    17.0     0.0    -1.0    -1.0    -1.0   \n",
       "    40172      3.0     7.0     0.0    13.0    20.0    18.0     7.0    -1.0   \n",
       "    136243     2.0    14.0    11.0    -1.0    -1.0    -1.0    -1.0    -1.0   \n",
       "    7833      11.0     8.0     4.0    18.0    11.0    -1.0    -1.0    -1.0   \n",
       "    ...        ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "    61715     22.0    14.0    11.0     5.0    17.0     0.0    12.0    -1.0   \n",
       "    76331     19.0     0.0    21.0     8.0     0.0     7.0    -1.0    -1.0   \n",
       "    109252    17.0     4.0    25.0    14.0    13.0    -1.0    -1.0    -1.0   \n",
       "    44005     11.0     8.0    13.0    18.0     8.0    -1.0    -1.0    -1.0   \n",
       "    74544     11.0    24.0    13.0     3.0    25.0     4.0    -1.0    -1.0   \n",
       "    \n",
       "            char_9  char_10  ...  char_18  char_19  char_20  char_21  char_22  \\\n",
       "    78044     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    24254     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    40172     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    136243    -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    7833      -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    ...        ...      ...  ...      ...      ...      ...      ...      ...   \n",
       "    61715     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    76331     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    109252    -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    44005     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    74544     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    \n",
       "            char_23  char_24  char_25   Count   Probability  \n",
       "    78044      -1.0     -1.0     -1.0    13.0  3.557760e-08  \n",
       "    24254      -1.0     -1.0     -1.0   304.0  8.319690e-07  \n",
       "    40172      -1.0     -1.0     -1.0   107.0  2.928310e-07  \n",
       "    136243     -1.0     -1.0     -1.0     1.0  2.736740e-09  \n",
       "    7833       -1.0     -1.0     -1.0  1826.0  4.997290e-06  \n",
       "    ...         ...      ...      ...     ...           ...  \n",
       "    61715      -1.0     -1.0     -1.0    32.0  8.757570e-08  \n",
       "    76331      -1.0     -1.0     -1.0    15.0  4.105110e-08  \n",
       "    109252     -1.0     -1.0     -1.0     5.0  1.368370e-08  \n",
       "    44005      -1.0     -1.0     -1.0    85.0  2.326230e-07  \n",
       "    74544      -1.0     -1.0     -1.0    16.0  4.378790e-08  \n",
       "    \n",
       "    [117816 rows x 27 columns],\n",
       "    98134     0\n",
       "    16973     1\n",
       "    92461     0\n",
       "    91908     0\n",
       "    84403     0\n",
       "             ..\n",
       "    14564     1\n",
       "    135896    1\n",
       "    76451     0\n",
       "    73074     0\n",
       "    9707      1\n",
       "    Name: Gender, Length: 29453, dtype: int64,\n",
       "    78044     0\n",
       "    24254     0\n",
       "    40172     1\n",
       "    136243    1\n",
       "    7833      0\n",
       "             ..\n",
       "    61715     1\n",
       "    76331     0\n",
       "    109252    1\n",
       "    44005     0\n",
       "    74544     0\n",
       "    Name: Gender, Length: 117816, dtype: int64),\n",
       "   0.5: (        char_1  char_2  char_3  char_4  char_5  char_6  char_7  char_8  \\\n",
       "    119803     3.0    17.0     0.0     6.0     0.0    -1.0    -1.0    -1.0   \n",
       "    43061      0.0    19.0     8.0    11.0    11.0     0.0    -1.0    -1.0   \n",
       "    114741     9.0     0.0    24.0    10.0     4.0     1.0    -1.0    -1.0   \n",
       "    127057    13.0     0.0    17.0     8.0     2.0    10.0    14.0    -1.0   \n",
       "    112365     0.0    17.0     2.0     7.0     0.0    -1.0    -1.0    -1.0   \n",
       "    ...        ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "    85373     18.0     7.0     0.0    13.0     3.0     0.0    11.0    -1.0   \n",
       "    110118    19.0    24.0    25.0     4.0    17.0    -1.0    -1.0    -1.0   \n",
       "    73508      1.0    11.0     4.0    18.0    18.0    14.0    13.0    -1.0   \n",
       "    145000    18.0    14.0    12.0     8.0     4.0    17.0    -1.0    -1.0   \n",
       "    50186     10.0    14.0     1.0     8.0    13.0    -1.0    -1.0    -1.0   \n",
       "    \n",
       "            char_9  char_10  ...  char_18  char_19  char_20  char_21  char_22  \\\n",
       "    119803    -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    43061     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    114741    -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    127057    11.0      4.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    112365    -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    ...        ...      ...  ...      ...      ...      ...      ...      ...   \n",
       "    85373     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    110118    -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    73508     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    145000    -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    50186     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    \n",
       "            char_23  char_24  char_25  Count   Probability  \n",
       "    119803     -1.0     -1.0     -1.0    1.0  2.736740e-09  \n",
       "    43061      -1.0     -1.0     -1.0   90.0  2.463070e-07  \n",
       "    114741     -1.0     -1.0     -1.0    2.0  5.473480e-09  \n",
       "    127057     -1.0     -1.0     -1.0    1.0  2.736740e-09  \n",
       "    112365     -1.0     -1.0     -1.0    2.0  5.473480e-09  \n",
       "    ...         ...      ...      ...    ...           ...  \n",
       "    85373      -1.0     -1.0     -1.0   10.0  2.736740e-08  \n",
       "    110118     -1.0     -1.0     -1.0    5.0  1.368370e-08  \n",
       "    73508      -1.0     -1.0     -1.0   17.0  4.652460e-08  \n",
       "    145000     -1.0     -1.0     -1.0    1.0  2.736740e-09  \n",
       "    50186      -1.0     -1.0     -1.0   60.0  1.642040e-07  \n",
       "    \n",
       "    [73634 rows x 27 columns],\n",
       "            char_1  char_2  char_3  char_4  char_5  char_6  char_7  char_8  \\\n",
       "    78350      0.0    24.0    14.0    14.0     1.0    -1.0    -1.0    -1.0   \n",
       "    129314    17.0    20.0    15.0     0.0    12.0    -1.0    -1.0    -1.0   \n",
       "    44505      5.0     8.0    13.0     2.0     7.0    -1.0    -1.0    -1.0   \n",
       "    79561     15.0     0.0    19.0    17.0     0.0     2.0     8.0     0.0   \n",
       "    111471    11.0    14.0     4.0     4.0    13.0    -1.0    -1.0    -1.0   \n",
       "    ...        ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "    146320    21.0     0.0    13.0     1.0     8.0     0.0    10.0    -1.0   \n",
       "    23200      9.0    20.0    11.0    11.0     8.0     0.0    13.0     0.0   \n",
       "    45275      8.0     2.0     7.0     4.0    11.0    11.0     4.0    -1.0   \n",
       "    25006      2.0     7.0     0.0    13.0     8.0    24.0     0.0     7.0   \n",
       "    31580     10.0     7.0    17.0     8.0    25.0    -1.0    -1.0    -1.0   \n",
       "    \n",
       "            char_9  char_10  ...  char_18  char_19  char_20  char_21  char_22  \\\n",
       "    78350     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    129314    -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    44505     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    79561     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    111471    -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    ...        ...      ...  ...      ...      ...      ...      ...      ...   \n",
       "    146320    -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    23200     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    45275     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    25006     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    31580     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    \n",
       "            char_23  char_24  char_25  Count   Probability  \n",
       "    78350      -1.0     -1.0     -1.0   13.0  3.557760e-08  \n",
       "    129314     -1.0     -1.0     -1.0    1.0  2.736740e-09  \n",
       "    44505      -1.0     -1.0     -1.0   83.0  2.271490e-07  \n",
       "    79561      -1.0     -1.0     -1.0   12.0  3.284090e-08  \n",
       "    111471     -1.0     -1.0     -1.0    3.0  8.210220e-09  \n",
       "    ...         ...      ...      ...    ...           ...  \n",
       "    146320     -1.0     -1.0     -1.0    1.0  2.736740e-09  \n",
       "    23200      -1.0     -1.0     -1.0  330.0  9.031240e-07  \n",
       "    45275      -1.0     -1.0     -1.0   79.0  2.162030e-07  \n",
       "    25006      -1.0     -1.0     -1.0  287.0  7.854450e-07  \n",
       "    31580      -1.0     -1.0     -1.0  184.0  5.035600e-07  \n",
       "    \n",
       "    [73635 rows x 27 columns],\n",
       "    119803    0\n",
       "    43061     1\n",
       "    114741    1\n",
       "    127057    0\n",
       "    112365    0\n",
       "             ..\n",
       "    85373     0\n",
       "    110118    1\n",
       "    73508     1\n",
       "    145000    1\n",
       "    50186     1\n",
       "    Name: Gender, Length: 73634, dtype: int64,\n",
       "    78350     1\n",
       "    129314    0\n",
       "    44505     1\n",
       "    79561     0\n",
       "    111471    0\n",
       "             ..\n",
       "    146320    1\n",
       "    23200     0\n",
       "    45275     0\n",
       "    25006     0\n",
       "    31580     1\n",
       "    Name: Gender, Length: 73635, dtype: int64),\n",
       "   0.8: (        char_1  char_2  char_3  char_4  char_5  char_6  char_7  char_8  \\\n",
       "    109287    17.0     8.0    18.0     4.0    -1.0    -1.0    -1.0    -1.0   \n",
       "    106197     3.0     0.0    21.0     8.0     3.0    15.0     0.0    20.0   \n",
       "    21359     13.0     0.0     7.0     4.0     4.0    12.0    -1.0    -1.0   \n",
       "    59148     10.0     4.0    18.0     7.0     0.0    22.0    13.0    13.0   \n",
       "    126160    12.0     4.0     6.0     0.0    13.0    -1.0     9.0     4.0   \n",
       "    ...        ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "    108369    11.0    20.0    10.0     0.0    20.0    18.0    -1.0    -1.0   \n",
       "    18710     10.0    20.0    17.0    18.0    19.0     8.0    13.0    -1.0   \n",
       "    72915      8.0    18.0    18.0     0.0     2.0    -1.0    -1.0    -1.0   \n",
       "    81508     10.0     8.0    13.0    18.0     8.0    13.0     6.0    19.0   \n",
       "    37774     17.0     4.0     7.0     4.0    12.0     0.0    -1.0    -1.0   \n",
       "    \n",
       "            char_9  char_10  ...  char_18  char_19  char_20  char_21  char_22  \\\n",
       "    109287    -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    106197    11.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    21359     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    59148      0.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    126160     0.0     13.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    ...        ...      ...  ...      ...      ...      ...      ...      ...   \n",
       "    108369    -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    18710     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    72915     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    81508     14.0     13.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    37774     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    \n",
       "            char_23  char_24  char_25  Count   Probability  \n",
       "    109287     -1.0     -1.0     -1.0    5.0  1.368370e-08  \n",
       "    106197     -1.0     -1.0     -1.0    5.0  1.368370e-08  \n",
       "    21359      -1.0     -1.0     -1.0  382.0  1.045430e-06  \n",
       "    59148      -1.0     -1.0     -1.0   36.0  9.852270e-08  \n",
       "    126160     -1.0     -1.0     -1.0    1.0  2.736740e-09  \n",
       "    ...         ...      ...      ...    ...           ...  \n",
       "    108369     -1.0     -1.0     -1.0    5.0  1.368370e-08  \n",
       "    18710      -1.0     -1.0     -1.0  474.0  1.297220e-06  \n",
       "    72915      -1.0     -1.0     -1.0   17.0  4.652460e-08  \n",
       "    81508      -1.0     -1.0     -1.0   11.0  3.010410e-08  \n",
       "    37774      -1.0     -1.0     -1.0  124.0  3.393560e-07  \n",
       "    \n",
       "    [117815 rows x 27 columns],\n",
       "            char_1  char_2  char_3  char_4  char_5  char_6  char_7  char_8  \\\n",
       "    98356      3.0     4.0    18.0    12.0     8.0    13.0    -1.0    -1.0   \n",
       "    403        6.0     0.0    21.0     8.0    13.0    -1.0    -1.0    -1.0   \n",
       "    141090    11.0    20.0    13.0     0.0    17.0    -1.0    -1.0    -1.0   \n",
       "    51240      9.0     8.0    25.0    25.0     4.0    11.0    11.0     4.0   \n",
       "    44443     13.0     8.0    10.0    14.0    11.0     4.0    19.0     0.0   \n",
       "    ...        ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "    93865     21.0     0.0    11.0     8.0    17.0     4.0     4.0    -1.0   \n",
       "    10237     15.0     0.0    17.0     0.0    11.0     4.0     4.0    -1.0   \n",
       "    10944      5.0    17.0     0.0    13.0    19.0    25.0    -1.0    -1.0   \n",
       "    16287      0.0     3.0    17.0     0.0    -1.0    -1.0    -1.0    -1.0   \n",
       "    59731     13.0     4.0     8.0    11.0     4.0    -1.0    -1.0    -1.0   \n",
       "    \n",
       "            char_9  char_10  ...  char_18  char_19  char_20  char_21  char_22  \\\n",
       "    98356     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    403       -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    141090    -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    51240     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    44443     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    ...        ...      ...  ...      ...      ...      ...      ...      ...   \n",
       "    93865     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    10237     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    10944     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    16287     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    59731     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    \n",
       "            char_23  char_24  char_25     Count   Probability  \n",
       "    98356      -1.0     -1.0     -1.0       5.0  1.368370e-08  \n",
       "    403        -1.0     -1.0     -1.0  182621.0  4.997860e-04  \n",
       "    141090     -1.0     -1.0     -1.0       1.0  2.736740e-09  \n",
       "    51240      -1.0     -1.0     -1.0      56.0  1.532570e-07  \n",
       "    44443      -1.0     -1.0     -1.0      83.0  2.271490e-07  \n",
       "    ...         ...      ...      ...       ...           ...  \n",
       "    93865      -1.0     -1.0     -1.0       6.0  1.642040e-08  \n",
       "    10237      -1.0     -1.0     -1.0    1215.0  3.325140e-06  \n",
       "    10944      -1.0     -1.0     -1.0    1102.0  3.015890e-06  \n",
       "    16287      -1.0     -1.0     -1.0     593.0  1.622890e-06  \n",
       "    59731      -1.0     -1.0     -1.0      35.0  9.578590e-08  \n",
       "    \n",
       "    [29454 rows x 27 columns],\n",
       "    109287    1\n",
       "    106197    1\n",
       "    21359     1\n",
       "    59148     0\n",
       "    126160    0\n",
       "             ..\n",
       "    108369    1\n",
       "    18710     0\n",
       "    72915     0\n",
       "    81508     0\n",
       "    37774     0\n",
       "    Name: Gender, Length: 117815, dtype: int64,\n",
       "    98356     0\n",
       "    403       1\n",
       "    141090    1\n",
       "    51240     0\n",
       "    44443     0\n",
       "             ..\n",
       "    93865     0\n",
       "    10237     0\n",
       "    10944     1\n",
       "    16287     0\n",
       "    59731     0\n",
       "    Name: Gender, Length: 29454, dtype: int64)},\n",
       "  42: {0.2: (        char_1  char_2  char_3  char_4  char_5  char_6  char_7  char_8  \\\n",
       "    138555     7.0    20.0     8.0     0.0    -1.0    -1.0    -1.0    -1.0   \n",
       "    104607    21.0     4.0    17.0    18.0     7.0    14.0    13.0     3.0   \n",
       "    128019    15.0     0.0    20.0    11.0     0.0    -1.0    11.0     4.0   \n",
       "    59454     13.0    14.0    23.0    23.0    -1.0    -1.0    -1.0    -1.0   \n",
       "    86509     10.0     8.0    17.0     8.0     0.0    13.0    -1.0    -1.0   \n",
       "    ...        ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "    82910      9.0     0.0    18.0    12.0     4.0    13.0    -1.0    -1.0   \n",
       "    22216      3.0     4.0     4.0    15.0    -1.0    -1.0    -1.0    -1.0   \n",
       "    32246     10.0     0.0     4.0    11.0    14.0     1.0    -1.0    -1.0   \n",
       "    56971      8.0    10.0     4.0     2.0     7.0     8.0    -1.0    -1.0   \n",
       "    11841      2.0    11.0     4.0    12.0    12.0     8.0     4.0    -1.0   \n",
       "    \n",
       "            char_9  char_10  ...  char_18  char_19  char_20  char_21  char_22  \\\n",
       "    138555    -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    104607     0.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    128019     4.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    59454     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    86509     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    ...        ...      ...  ...      ...      ...      ...      ...      ...   \n",
       "    82910     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    22216     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    32246     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    56971     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    11841     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    \n",
       "            char_23  char_24  char_25  Count   Probability  \n",
       "    138555     -1.0     -1.0     -1.0    1.0  2.736740e-09  \n",
       "    104607     -1.0     -1.0     -1.0    5.0  1.368370e-08  \n",
       "    128019     -1.0     -1.0     -1.0    1.0  2.736740e-09  \n",
       "    59454      -1.0     -1.0     -1.0   36.0  9.852270e-08  \n",
       "    86509      -1.0     -1.0     -1.0   10.0  2.736740e-08  \n",
       "    ...         ...      ...      ...    ...           ...  \n",
       "    82910      -1.0     -1.0     -1.0   11.0  3.010410e-08  \n",
       "    22216      -1.0     -1.0     -1.0  357.0  9.770160e-07  \n",
       "    32246      -1.0     -1.0     -1.0  176.0  4.816660e-07  \n",
       "    56971      -1.0     -1.0     -1.0   41.0  1.122060e-07  \n",
       "    11841      -1.0     -1.0     -1.0  977.0  2.673800e-06  \n",
       "    \n",
       "    [29453 rows x 27 columns],\n",
       "            char_1  char_2  char_3  char_4  char_5  char_6  char_7  char_8  \\\n",
       "    92619     12.0     0.0     7.0    10.0    24.0    11.0     0.0    -1.0   \n",
       "    43552      9.0     0.0    12.0     8.0    17.0    17.0     0.0    -1.0   \n",
       "    133485    24.0     0.0    10.0     0.0    13.0     3.0     0.0    22.0   \n",
       "    16577      7.0     0.0    17.0    15.0    17.0     4.0     4.0    19.0   \n",
       "    24629      9.0     0.0    18.0     7.0    20.0    13.0    -1.0    -1.0   \n",
       "    ...        ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "    43157      2.0    17.0     8.0    18.0    19.0     4.0    11.0    11.0   \n",
       "    43972      7.0     0.0    20.0    13.0     0.0    13.0     8.0    -1.0   \n",
       "    47805      3.0     4.0    25.0    17.0     0.0    -1.0    -1.0    -1.0   \n",
       "    93443     18.0     7.0     0.0    17.0    11.0    24.0    -1.0    -1.0   \n",
       "    132943    20.0    12.0     8.0    12.0     0.0    -1.0    -1.0    -1.0   \n",
       "    \n",
       "            char_9  char_10  ...  char_18  char_19  char_20  char_21  char_22  \\\n",
       "    92619     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    43552     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    133485     0.0     11.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    16577     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    24629     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    ...        ...      ...  ...      ...      ...      ...      ...      ...   \n",
       "    43157      0.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    43972     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    47805     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    93443     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    132943    -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    \n",
       "            char_23  char_24  char_25  Count   Probability  \n",
       "    92619      -1.0     -1.0     -1.0    6.0  1.642040e-08  \n",
       "    43552      -1.0     -1.0     -1.0   87.0  2.380960e-07  \n",
       "    133485     -1.0     -1.0     -1.0    1.0  2.736740e-09  \n",
       "    16577      -1.0     -1.0     -1.0  578.0  1.581840e-06  \n",
       "    24629      -1.0     -1.0     -1.0  296.0  8.100750e-07  \n",
       "    ...         ...      ...      ...    ...           ...  \n",
       "    43157      -1.0     -1.0     -1.0   89.0  2.435700e-07  \n",
       "    43972      -1.0     -1.0     -1.0   85.0  2.326230e-07  \n",
       "    47805      -1.0     -1.0     -1.0   68.0  1.860980e-07  \n",
       "    93443      -1.0     -1.0     -1.0    6.0  1.642040e-08  \n",
       "    132943     -1.0     -1.0     -1.0    1.0  2.736740e-09  \n",
       "    \n",
       "    [117816 rows x 27 columns],\n",
       "    138555    1\n",
       "    104607    0\n",
       "    128019    0\n",
       "    59454     1\n",
       "    86509     1\n",
       "             ..\n",
       "    82910     1\n",
       "    22216     1\n",
       "    32246     1\n",
       "    56971     1\n",
       "    11841     1\n",
       "    Name: Gender, Length: 29453, dtype: int64,\n",
       "    92619     0\n",
       "    43552     0\n",
       "    133485    0\n",
       "    16577     1\n",
       "    24629     1\n",
       "             ..\n",
       "    43157     0\n",
       "    43972     0\n",
       "    47805     0\n",
       "    93443     0\n",
       "    132943    0\n",
       "    Name: Gender, Length: 117816, dtype: int64),\n",
       "   0.5: (        char_1  char_2  char_3  char_4  char_5  char_6  char_7  char_8  \\\n",
       "    43010     12.0     8.0    10.0     0.0     8.0    11.0     8.0    -1.0   \n",
       "    22630     12.0     0.0    10.0     8.0    13.0    13.0     0.0    -1.0   \n",
       "    55169     12.0     8.0    24.0    14.0    13.0     0.0    -1.0    -1.0   \n",
       "    105026    25.0     4.0    13.0    24.0    -1.0    -1.0    -1.0    -1.0   \n",
       "    73099     11.0    14.0    17.0     0.0    13.0    13.0     0.0    -1.0   \n",
       "    ...        ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "    31713      4.0    11.0    11.0     4.0    13.0    14.0    17.0     0.0   \n",
       "    71391      9.0     0.0    18.0    13.0    14.0    14.0    17.0    -1.0   \n",
       "    18994      9.0     0.0    11.0     4.0    24.0     0.0     7.0    -1.0   \n",
       "    140861    11.0     4.0    14.0    13.0     6.0    -1.0    -1.0    -1.0   \n",
       "    29915     20.0     3.0     0.0    24.0    -1.0    -1.0    -1.0    -1.0   \n",
       "    \n",
       "            char_9  char_10  ...  char_18  char_19  char_20  char_21  char_22  \\\n",
       "    43010     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    22630     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    55169     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    105026    -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    73099     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    ...        ...      ...  ...      ...      ...      ...      ...      ...   \n",
       "    31713     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    71391     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    18994     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    140861    -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    29915     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    \n",
       "            char_23  char_24  char_25  Count   Probability  \n",
       "    43010      -1.0     -1.0     -1.0   90.0  2.463070e-07  \n",
       "    22630      -1.0     -1.0     -1.0  345.0  9.441760e-07  \n",
       "    55169      -1.0     -1.0     -1.0   45.0  1.231530e-07  \n",
       "    105026     -1.0     -1.0     -1.0    5.0  1.368370e-08  \n",
       "    73099      -1.0     -1.0     -1.0   17.0  4.652460e-08  \n",
       "    ...         ...      ...      ...    ...           ...  \n",
       "    31713      -1.0     -1.0     -1.0  182.0  4.980870e-07  \n",
       "    71391      -1.0     -1.0     -1.0   19.0  5.199810e-08  \n",
       "    18994      -1.0     -1.0     -1.0  463.0  1.267110e-06  \n",
       "    140861     -1.0     -1.0     -1.0    1.0  2.736740e-09  \n",
       "    29915      -1.0     -1.0     -1.0  205.0  5.610320e-07  \n",
       "    \n",
       "    [73634 rows x 27 columns],\n",
       "            char_1  char_2  char_3  char_4  char_5  char_6  char_7  char_8  \\\n",
       "    22190     17.0    14.0    22.0    24.0    13.0    -1.0    -1.0    -1.0   \n",
       "    41110     22.0     8.0    13.0    14.0    11.0     0.0    -1.0    -1.0   \n",
       "    2663       5.0     0.0    11.0    11.0    14.0    13.0    -1.0    -1.0   \n",
       "    101395    12.0     0.0     8.0    25.0    11.0     4.0     4.0    -1.0   \n",
       "    134244     0.0     7.0    20.0    17.0     0.0    -1.0    -1.0    -1.0   \n",
       "    ...        ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "    33017      0.0    25.0     0.0    17.0     8.0    14.0    13.0    -1.0   \n",
       "    85204     17.0     0.0     4.0    12.0    14.0    13.0     0.0    -1.0   \n",
       "    28821     15.0     8.0     4.0    17.0     2.0     4.0    -1.0    -1.0   \n",
       "    41987     24.0     0.0    13.0     8.0     0.0     7.0    -1.0    -1.0   \n",
       "    130766    18.0     8.0     4.0    13.0    13.0     0.0    -1.0     9.0   \n",
       "    \n",
       "            char_9  char_10  ...  char_18  char_19  char_20  char_21  char_22  \\\n",
       "    22190     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    41110     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    2663      -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    101395    -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    134244    -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    ...        ...      ...  ...      ...      ...      ...      ...      ...   \n",
       "    33017     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    85204     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    28821     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    41987     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    130766     0.0      8.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    \n",
       "            char_23  char_24  char_25   Count   Probability  \n",
       "    22190      -1.0     -1.0     -1.0   358.0  9.797530e-07  \n",
       "    41110      -1.0     -1.0     -1.0   101.0  2.764110e-07  \n",
       "    2663       -1.0     -1.0     -1.0  9933.0  2.718400e-05  \n",
       "    101395     -1.0     -1.0     -1.0     5.0  1.368370e-08  \n",
       "    134244     -1.0     -1.0     -1.0     1.0  2.736740e-09  \n",
       "    ...         ...      ...      ...     ...           ...  \n",
       "    33017      -1.0     -1.0     -1.0   167.0  4.570360e-07  \n",
       "    85204      -1.0     -1.0     -1.0    10.0  2.736740e-08  \n",
       "    28821      -1.0     -1.0     -1.0   220.0  6.020830e-07  \n",
       "    41987      -1.0     -1.0     -1.0    96.0  2.627270e-07  \n",
       "    130766     -1.0     -1.0     -1.0     1.0  2.736740e-09  \n",
       "    \n",
       "    [73635 rows x 27 columns],\n",
       "    43010     0\n",
       "    22630     0\n",
       "    55169     0\n",
       "    105026    0\n",
       "    73099     0\n",
       "             ..\n",
       "    31713     0\n",
       "    71391     1\n",
       "    18994     0\n",
       "    140861    1\n",
       "    29915     1\n",
       "    Name: Gender, Length: 73634, dtype: int64,\n",
       "    22190     1\n",
       "    41110     0\n",
       "    2663      0\n",
       "    101395    0\n",
       "    134244    1\n",
       "             ..\n",
       "    33017     1\n",
       "    85204     0\n",
       "    28821     0\n",
       "    41987     0\n",
       "    130766    0\n",
       "    Name: Gender, Length: 73635, dtype: int64),\n",
       "   0.8: (        char_1  char_2  char_3  char_4  char_5  char_6  char_7  char_8  \\\n",
       "    133510    24.0     0.0    17.0     8.0     5.0     0.0    11.0     0.0   \n",
       "    69671      6.0    14.0     3.0    14.0     5.0    17.0     4.0     3.0   \n",
       "    122725     9.0     4.0    25.0    25.0     8.0    12.0     0.0    24.0   \n",
       "    18298     19.0     7.0     0.0    17.0    14.0    13.0    -1.0    -1.0   \n",
       "    1645      12.0     8.0     2.0     7.0     0.0     4.0    11.0    -1.0   \n",
       "    ...        ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "    117524     1.0     0.0    17.0     1.0    17.0     0.0    -1.0     4.0   \n",
       "    18994      9.0     0.0    11.0     4.0    24.0     0.0     7.0    -1.0   \n",
       "    43192     10.0     0.0    25.0     8.0    -1.0    -1.0    -1.0    -1.0   \n",
       "    140591    10.0    24.0    11.0     4.0    -1.0     9.0    14.0     4.0   \n",
       "    71625      0.0    18.0     7.0    11.0     4.0     4.0    24.0    -1.0   \n",
       "    \n",
       "            char_9  char_10  ...  char_18  char_19  char_20  char_21  char_22  \\\n",
       "    133510    13.0     19.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    69671     14.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    122725    -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    18298     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    1645      -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    ...        ...      ...  ...      ...      ...      ...      ...      ...   \n",
       "    117524    11.0     11.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    18994     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    43192     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    140591    -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    71625     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    \n",
       "            char_23  char_24  char_25    Count   Probability  \n",
       "    133510     -1.0     -1.0     -1.0      1.0  2.736740e-09  \n",
       "    69671      -1.0     -1.0     -1.0     21.0  5.747160e-08  \n",
       "    122725     -1.0     -1.0     -1.0      1.0  2.736740e-09  \n",
       "    18298      -1.0     -1.0     -1.0    493.0  1.349210e-06  \n",
       "    1645       -1.0     -1.0     -1.0  22860.0  6.256190e-05  \n",
       "    ...         ...      ...      ...      ...           ...  \n",
       "    117524     -1.0     -1.0     -1.0      1.0  2.736740e-09  \n",
       "    18994      -1.0     -1.0     -1.0    463.0  1.267110e-06  \n",
       "    43192      -1.0     -1.0     -1.0     89.0  2.435700e-07  \n",
       "    140591     -1.0     -1.0     -1.0      1.0  2.736740e-09  \n",
       "    71625      -1.0     -1.0     -1.0     18.0  4.926130e-08  \n",
       "    \n",
       "    [117815 rows x 27 columns],\n",
       "            char_1  char_2  char_3  char_4  char_5  char_6  char_7  char_8  \\\n",
       "    82904      9.0     0.0    17.0    16.0    20.0     0.0    21.0     8.0   \n",
       "    127998    15.0     0.0    19.0    17.0     4.0    19.0     0.0    17.0   \n",
       "    76315     18.0    24.0    13.0     3.0     8.0     4.0    -1.0    -1.0   \n",
       "    66962      9.0     4.0    13.0    17.0     8.0    -1.0    -1.0    -1.0   \n",
       "    91262      2.0    11.0     4.0    21.0     4.0    19.0    19.0     4.0   \n",
       "    ...        ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "    98413      3.0     8.0    13.0    13.0     4.0     4.0    13.0    -1.0   \n",
       "    53304     12.0     0.0     7.0    13.0     8.0    24.0     0.0    -1.0   \n",
       "    70238     11.0    14.0    13.0    -1.0    -1.0    -1.0    -1.0    -1.0   \n",
       "    138249     7.0     0.0    17.0     0.0    11.0     0.0     1.0    17.0   \n",
       "    13488     12.0     0.0    17.0     6.0     4.0     0.0    20.0    23.0   \n",
       "    \n",
       "            char_9  char_10  ...  char_18  char_19  char_20  char_21  char_22  \\\n",
       "    82904     20.0     18.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    127998    -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    76315     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    66962     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    91262     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    ...        ...      ...  ...      ...      ...      ...      ...      ...   \n",
       "    98413     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    53304     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    70238     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    138249    14.0     18.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    13488     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    \n",
       "            char_23  char_24  char_25  Count   Probability  \n",
       "    82904      -1.0     -1.0     -1.0   11.0  3.010410e-08  \n",
       "    127998     -1.0     -1.0     -1.0    1.0  2.736740e-09  \n",
       "    76315      -1.0     -1.0     -1.0   15.0  4.105110e-08  \n",
       "    66962      -1.0     -1.0     -1.0   24.0  6.568180e-08  \n",
       "    91262      -1.0     -1.0     -1.0    6.0  1.642040e-08  \n",
       "    ...         ...      ...      ...    ...           ...  \n",
       "    98413      -1.0     -1.0     -1.0    5.0  1.368370e-08  \n",
       "    53304      -1.0     -1.0     -1.0   50.0  1.368370e-07  \n",
       "    70238      -1.0     -1.0     -1.0   20.0  5.473480e-08  \n",
       "    138249     -1.0     -1.0     -1.0    1.0  2.736740e-09  \n",
       "    13488      -1.0     -1.0     -1.0  796.0  2.178450e-06  \n",
       "    \n",
       "    [29454 rows x 27 columns],\n",
       "    133510    0\n",
       "    69671     1\n",
       "    122725    0\n",
       "    18298     1\n",
       "    1645      0\n",
       "             ..\n",
       "    117524    0\n",
       "    18994     0\n",
       "    43192     0\n",
       "    140591    1\n",
       "    71625     0\n",
       "    Name: Gender, Length: 117815, dtype: int64,\n",
       "    82904     1\n",
       "    127998    0\n",
       "    76315     0\n",
       "    66962     1\n",
       "    91262     0\n",
       "             ..\n",
       "    98413     0\n",
       "    53304     0\n",
       "    70238     0\n",
       "    138249    1\n",
       "    13488     0\n",
       "    Name: Gender, Length: 29454, dtype: int64)},\n",
       "  99: {0.2: (        char_1  char_2  char_3  char_4  char_5  char_6  char_7  char_8  \\\n",
       "    139651     9.0    14.0    19.0     8.0    18.0     7.0     2.0     7.0   \n",
       "    44978     19.0    24.0    12.0     4.0     8.0    17.0    -1.0    -1.0   \n",
       "    101103    11.0     8.0    11.0     8.0    17.0    14.0    18.0     4.0   \n",
       "    127789    14.0    13.0     4.0    -1.0    -1.0    -1.0    -1.0    -1.0   \n",
       "    111514    12.0     8.0    11.0     9.0     0.0    -1.0    -1.0    -1.0   \n",
       "    ...        ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "    17984      4.0    12.0     8.0    11.0    11.0     8.0     4.0    -1.0   \n",
       "    96551      0.0    11.0     8.0    18.0    20.0    13.0    -1.0    -1.0   \n",
       "    56164     12.0     0.0    17.0    10.0     4.0     4.0     2.0     4.0   \n",
       "    28816     12.0     0.0    17.0     9.0     0.0    13.0    -1.0    -1.0   \n",
       "    104734    22.0    17.0     0.0    24.0     0.0    13.0    13.0     4.0   \n",
       "    \n",
       "            char_9  char_10  ...  char_18  char_19  char_20  char_21  char_22  \\\n",
       "    139651     0.0     13.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    44978     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    101103    -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    127789    -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    111514    -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    ...        ...      ...  ...      ...      ...      ...      ...      ...   \n",
       "    17984     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    96551     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    56164     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    28816     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    104734    -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    \n",
       "            char_23  char_24  char_25  Count   Probability  \n",
       "    139651     -1.0     -1.0     -1.0    1.0  2.736740e-09  \n",
       "    44978      -1.0     -1.0     -1.0   81.0  2.216760e-07  \n",
       "    101103     -1.0     -1.0     -1.0    5.0  1.368370e-08  \n",
       "    127789     -1.0     -1.0     -1.0    1.0  2.736740e-09  \n",
       "    111514     -1.0     -1.0     -1.0    3.0  8.210220e-09  \n",
       "    ...         ...      ...      ...    ...           ...  \n",
       "    17984      -1.0     -1.0     -1.0  507.0  1.387530e-06  \n",
       "    96551      -1.0     -1.0     -1.0    5.0  1.368370e-08  \n",
       "    56164      -1.0     -1.0     -1.0   43.0  1.176800e-07  \n",
       "    28816      -1.0     -1.0     -1.0  220.0  6.020830e-07  \n",
       "    104734     -1.0     -1.0     -1.0    5.0  1.368370e-08  \n",
       "    \n",
       "    [29453 rows x 27 columns],\n",
       "            char_1  char_2  char_3  char_4  char_5  char_6  char_7  char_8  \\\n",
       "    103325    18.0     7.0     0.0    10.0    24.0     8.0     0.0     7.0   \n",
       "    60220     10.0     0.0    11.0    14.0    11.0     0.0     8.0    13.0   \n",
       "    44864     13.0     0.0    20.0    19.0     8.0     0.0    -1.0    -1.0   \n",
       "    134462     0.0    12.0     0.0    17.0    19.0    -1.0    -1.0    -1.0   \n",
       "    86479     10.0     4.0    13.0     3.0    20.0    -1.0    -1.0    -1.0   \n",
       "    ...        ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "    47375     17.0     7.0     0.0     4.0    11.0    24.0    13.0    -1.0   \n",
       "    53598     10.0     0.0     0.0    11.0     0.0    -1.0    -1.0    -1.0   \n",
       "    42898      3.0     0.0    18.0     2.0     7.0     4.0    11.0    -1.0   \n",
       "    3904      18.0    24.0     3.0    13.0     8.0    -1.0    -1.0    -1.0   \n",
       "    47840     10.0     4.0    13.0     8.0    19.0     7.0     0.0    -1.0   \n",
       "    \n",
       "            char_9  char_10  ...  char_18  char_19  char_20  char_21  char_22  \\\n",
       "    103325    -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    60220      4.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    44864     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    134462    -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    86479     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    ...        ...      ...  ...      ...      ...      ...      ...      ...   \n",
       "    47375     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    53598     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    42898     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    3904      -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    47840     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    \n",
       "            char_23  char_24  char_25   Count   Probability  \n",
       "    103325     -1.0     -1.0     -1.0     5.0  1.368370e-08  \n",
       "    60220      -1.0     -1.0     -1.0    34.0  9.304920e-08  \n",
       "    44864      -1.0     -1.0     -1.0    81.0  2.216760e-07  \n",
       "    134462     -1.0     -1.0     -1.0     1.0  2.736740e-09  \n",
       "    86479      -1.0     -1.0     -1.0    10.0  2.736740e-08  \n",
       "    ...         ...      ...      ...     ...           ...  \n",
       "    47375      -1.0     -1.0     -1.0    70.0  1.915720e-07  \n",
       "    53598      -1.0     -1.0     -1.0    49.0  1.341000e-07  \n",
       "    42898      -1.0     -1.0     -1.0    91.0  2.490430e-07  \n",
       "    3904       -1.0     -1.0     -1.0  5279.0  1.444730e-05  \n",
       "    47840      -1.0     -1.0     -1.0    68.0  1.860980e-07  \n",
       "    \n",
       "    [117816 rows x 27 columns],\n",
       "    139651    1\n",
       "    44978     1\n",
       "    101103    0\n",
       "    127789    0\n",
       "    111514    0\n",
       "             ..\n",
       "    17984     0\n",
       "    96551     0\n",
       "    56164     1\n",
       "    28816     0\n",
       "    104734    0\n",
       "    Name: Gender, Length: 29453, dtype: int64,\n",
       "    103325    0\n",
       "    60220     0\n",
       "    44864     0\n",
       "    134462    1\n",
       "    86479     1\n",
       "             ..\n",
       "    47375     0\n",
       "    53598     0\n",
       "    42898     1\n",
       "    3904      0\n",
       "    47840     0\n",
       "    Name: Gender, Length: 117816, dtype: int64),\n",
       "   0.5: (        char_1  char_2  char_3  char_4  char_5  char_6  char_7  char_8  \\\n",
       "    135370     1.0     4.0    17.0    10.0     8.0    13.0    -1.0    -1.0   \n",
       "    140922    11.0     8.0     3.0     8.0     0.0    -1.0    -1.0    -1.0   \n",
       "    4561      18.0     7.0     4.0    17.0    17.0    24.0    11.0    -1.0   \n",
       "    34755      1.0    17.0     0.0     4.0    11.0    24.0    13.0    13.0   \n",
       "    55815     25.0     1.0     8.0     6.0    13.0     8.0     4.0    22.0   \n",
       "    ...        ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "    93806     19.0    17.0     8.0    13.0     8.0    19.0    24.0    17.0   \n",
       "    90490     18.0     7.0     8.0    21.0    14.0    12.0    -1.0    -1.0   \n",
       "    87506      8.0     3.0     8.0    -1.0    -1.0    -1.0    -1.0    -1.0   \n",
       "    141465    12.0     0.0    18.0     0.0    17.0    17.0     0.0    19.0   \n",
       "    104734    22.0    17.0     0.0    24.0     0.0    13.0    13.0     4.0   \n",
       "    \n",
       "            char_9  char_10  ...  char_18  char_19  char_20  char_21  char_22  \\\n",
       "    135370    -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    140922    -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    4561      -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    34755      4.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    55815     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    ...        ...      ...  ...      ...      ...      ...      ...      ...   \n",
       "    93806     14.0     18.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    90490     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    87506     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    141465    -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    104734    -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    \n",
       "            char_23  char_24  char_25   Count   Probability  \n",
       "    135370     -1.0     -1.0     -1.0     1.0  2.736740e-09  \n",
       "    140922     -1.0     -1.0     -1.0     1.0  2.736740e-09  \n",
       "    4561       -1.0     -1.0     -1.0  4159.0  1.138210e-05  \n",
       "    34755      -1.0     -1.0     -1.0   149.0  4.077740e-07  \n",
       "    55815      -1.0     -1.0     -1.0    44.0  1.204170e-07  \n",
       "    ...         ...      ...      ...     ...           ...  \n",
       "    93806      -1.0     -1.0     -1.0     6.0  1.642040e-08  \n",
       "    90490      -1.0     -1.0     -1.0     7.0  1.915720e-08  \n",
       "    87506      -1.0     -1.0     -1.0     9.0  2.463070e-08  \n",
       "    141465     -1.0     -1.0     -1.0     1.0  2.736740e-09  \n",
       "    104734     -1.0     -1.0     -1.0     5.0  1.368370e-08  \n",
       "    \n",
       "    [73634 rows x 27 columns],\n",
       "            char_1  char_2  char_3  char_4  char_5  char_6  char_7  char_8  \\\n",
       "    141068    11.0    20.0     8.0     6.0     8.0    -1.0     6.0     0.0   \n",
       "    47392     18.0    10.0    24.0    17.0     0.0    -1.0    -1.0    -1.0   \n",
       "    101346    12.0     0.0     3.0     8.0    24.0    18.0    14.0    13.0   \n",
       "    17138     10.0     0.0    24.0    11.0     8.0    13.0    -1.0    -1.0   \n",
       "    69779     11.0     0.0     6.0    17.0     4.0     6.0    14.0    17.0   \n",
       "    ...        ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "    63539      0.0    13.0    18.0     0.0    -1.0    -1.0    -1.0    -1.0   \n",
       "    130712    18.0     7.0    24.0    -1.0     0.0    13.0    13.0    -1.0   \n",
       "    144833    18.0     7.0    24.0     0.0    12.0     0.0    -1.0    -1.0   \n",
       "    6126      11.0     0.0    17.0     7.0    14.0    13.0     3.0     0.0   \n",
       "    136192     2.0     8.0     0.0    13.0    24.0    -1.0    -1.0    -1.0   \n",
       "    \n",
       "            char_9  char_10  ...  char_18  char_19  char_20  char_21  char_22  \\\n",
       "    141068     4.0     19.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    47392     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    101346    -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    17138     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    69779     24.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    ...        ...      ...  ...      ...      ...      ...      ...      ...   \n",
       "    63539     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    130712    -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    144833    -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    6126      -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    136192    -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    \n",
       "            char_23  char_24  char_25   Count   Probability  \n",
       "    141068     -1.0     -1.0     -1.0     1.0  2.736740e-09  \n",
       "    47392      -1.0     -1.0     -1.0    70.0  1.915720e-07  \n",
       "    101346     -1.0     -1.0     -1.0     5.0  1.368370e-08  \n",
       "    17138      -1.0     -1.0     -1.0   550.0  1.505210e-06  \n",
       "    69779      -1.0     -1.0     -1.0    21.0  5.747160e-08  \n",
       "    ...         ...      ...      ...     ...           ...  \n",
       "    63539      -1.0     -1.0     -1.0    28.0  7.662870e-08  \n",
       "    130712     -1.0     -1.0     -1.0     1.0  2.736740e-09  \n",
       "    144833     -1.0     -1.0     -1.0     1.0  2.736740e-09  \n",
       "    6126       -1.0     -1.0     -1.0  2646.0  7.241420e-06  \n",
       "    136192     -1.0     -1.0     -1.0     1.0  2.736740e-09  \n",
       "    \n",
       "    [73635 rows x 27 columns],\n",
       "    135370    1\n",
       "    140922    1\n",
       "    4561      0\n",
       "    34755     0\n",
       "    55815     1\n",
       "             ..\n",
       "    93806     0\n",
       "    90490     1\n",
       "    87506     1\n",
       "    141465    1\n",
       "    104734    0\n",
       "    Name: Gender, Length: 73634, dtype: int64,\n",
       "    141068    1\n",
       "    47392     0\n",
       "    101346    0\n",
       "    17138     1\n",
       "    69779     1\n",
       "             ..\n",
       "    63539     0\n",
       "    130712    0\n",
       "    144833    1\n",
       "    6126      0\n",
       "    136192    1\n",
       "    Name: Gender, Length: 73635, dtype: int64),\n",
       "   0.8: (        char_1  char_2  char_3  char_4  char_5  char_6  char_7  char_8  \\\n",
       "    86249      6.0    17.0     4.0    24.0    19.0    14.0    13.0    -1.0   \n",
       "    130743    18.0     8.0     1.0     0.0    13.0     0.0    25.0    -1.0   \n",
       "    88465     18.0     4.0    13.0     0.0     8.0     3.0    14.0    -1.0   \n",
       "    143062    15.0     7.0     8.0     3.0     8.0     0.0    18.0    -1.0   \n",
       "    30469     19.0    17.0     0.0    13.0     0.0     4.0    -1.0    -1.0   \n",
       "    ...        ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "    131613    19.0     0.0     7.0    11.0     4.0    24.0     0.0     7.0   \n",
       "    86208      5.0     0.0     7.0    12.0     8.0    -1.0    -1.0    -1.0   \n",
       "    43883      4.0     0.0    12.0     4.0    18.0    -1.0    -1.0    -1.0   \n",
       "    40074      2.0     7.0     0.0     8.0    17.0    19.0    24.0    -1.0   \n",
       "    104734    22.0    17.0     0.0    24.0     0.0    13.0    13.0     4.0   \n",
       "    \n",
       "            char_9  char_10  ...  char_18  char_19  char_20  char_21  char_22  \\\n",
       "    86249     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    130743    -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    88465     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    143062    -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    30469     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    ...        ...      ...  ...      ...      ...      ...      ...      ...   \n",
       "    131613    -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    86208     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    43883     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    40074     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    104734    -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    \n",
       "            char_23  char_24  char_25  Count   Probability  \n",
       "    86249      -1.0     -1.0     -1.0   10.0  2.736740e-08  \n",
       "    130743     -1.0     -1.0     -1.0    1.0  2.736740e-09  \n",
       "    88465      -1.0     -1.0     -1.0    8.0  2.189390e-08  \n",
       "    143062     -1.0     -1.0     -1.0    1.0  2.736740e-09  \n",
       "    30469      -1.0     -1.0     -1.0  197.0  5.391380e-07  \n",
       "    ...         ...      ...      ...    ...           ...  \n",
       "    131613     -1.0     -1.0     -1.0    1.0  2.736740e-09  \n",
       "    86208      -1.0     -1.0     -1.0   10.0  2.736740e-08  \n",
       "    43883      -1.0     -1.0     -1.0   86.0  2.353600e-07  \n",
       "    40074      -1.0     -1.0     -1.0  107.0  2.928310e-07  \n",
       "    104734     -1.0     -1.0     -1.0    5.0  1.368370e-08  \n",
       "    \n",
       "    [117815 rows x 27 columns],\n",
       "            char_1  char_2  char_3  char_4  char_5  char_6  char_7  char_8  \\\n",
       "    67420     11.0     8.0    18.0    12.0     0.0    17.0     8.0     4.0   \n",
       "    50436      0.0     0.0    10.0     0.0    17.0    18.0     7.0    -1.0   \n",
       "    63422     12.0     0.0    17.0    10.0     4.0     0.0    11.0    -1.0   \n",
       "    145437    19.0     0.0    11.0     4.0     3.0    14.0    -1.0    -1.0   \n",
       "    102334    13.0    14.0    17.0     8.0    10.0     0.0    -1.0    -1.0   \n",
       "    ...        ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "    88507     20.0    12.0     8.0    19.0    -1.0    -1.0    -1.0    -1.0   \n",
       "    98603      4.0    11.0     4.0    23.0     8.0    -1.0    -1.0    -1.0   \n",
       "    76513      1.0    17.0    24.0    18.0     7.0    14.0    13.0    -1.0   \n",
       "    138569     7.0    20.0    17.0    17.0     0.0     8.0    17.0    -1.0   \n",
       "    100700    10.0    24.0    11.0     8.0     4.0     0.0    13.0    13.0   \n",
       "    \n",
       "            char_9  char_10  ...  char_18  char_19  char_20  char_21  char_22  \\\n",
       "    67420     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    50436     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    63422     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    145437    -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    102334    -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    ...        ...      ...  ...      ...      ...      ...      ...      ...   \n",
       "    88507     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    98603     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    76513     -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    138569    -1.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    100700     0.0     -1.0  ...     -1.0     -1.0     -1.0     -1.0     -1.0   \n",
       "    \n",
       "            char_23  char_24  char_25  Count   Probability  \n",
       "    67420      -1.0     -1.0     -1.0   23.0  6.294500e-08  \n",
       "    50436      -1.0     -1.0     -1.0   59.0  1.614680e-07  \n",
       "    63422      -1.0     -1.0     -1.0   29.0  7.936550e-08  \n",
       "    145437     -1.0     -1.0     -1.0    1.0  2.736740e-09  \n",
       "    102334     -1.0     -1.0     -1.0    5.0  1.368370e-08  \n",
       "    ...         ...      ...      ...    ...           ...  \n",
       "    88507      -1.0     -1.0     -1.0    8.0  2.189390e-08  \n",
       "    98603      -1.0     -1.0     -1.0    5.0  1.368370e-08  \n",
       "    76513      -1.0     -1.0     -1.0   15.0  4.105110e-08  \n",
       "    138569     -1.0     -1.0     -1.0    1.0  2.736740e-09  \n",
       "    100700     -1.0     -1.0     -1.0    5.0  1.368370e-08  \n",
       "    \n",
       "    [29454 rows x 27 columns],\n",
       "    86249     1\n",
       "    130743    0\n",
       "    88465     1\n",
       "    143062    1\n",
       "    30469     0\n",
       "             ..\n",
       "    131613    0\n",
       "    86208     1\n",
       "    43883     1\n",
       "    40074     0\n",
       "    104734    0\n",
       "    Name: Gender, Length: 117815, dtype: int64,\n",
       "    67420     0\n",
       "    50436     1\n",
       "    63422     1\n",
       "    145437    1\n",
       "    102334    0\n",
       "             ..\n",
       "    88507     1\n",
       "    98603     0\n",
       "    76513     1\n",
       "    138569    1\n",
       "    100700    0\n",
       "    Name: Gender, Length: 29454, dtype: int64)}}}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_partitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50ffb03",
   "metadata": {},
   "source": [
    "Check that we do indeed have: 3 datasets * 3 partitions * 3 trials = 27 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "93365c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total splits: 27\n"
     ]
    }
   ],
   "source": [
    "total_splits = 0\n",
    "for dname, seeds_dict in all_partitions.items():\n",
    "    for seed, partitions_dict in seeds_dict.items():\n",
    "        total_splits += len(partitions_dict)  # number of partitions per seed\n",
    "\n",
    "print(\"Total splits:\", total_splits)  # multiply by 3 datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10ea209",
   "metadata": {},
   "source": [
    "# 4. Training models\n",
    "### 4.1 setup: general functions to use "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "aa9fbd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(model, param_grid, X_train, y_train, cv=5):\n",
    "    grid = GridSearchCV(model, param_grid, cv=cv, scoring='accuracy', n_jobs=-1)\n",
    "    grid.fit(X_train, y_train)\n",
    "    best_model = grid.best_estimator_\n",
    "    best_params = grid.best_params_\n",
    "    best_score = grid.best_score_  \n",
    "    return best_model, best_params, best_score\n",
    "\n",
    "def evaluate_model(model, X_train, y_train, X_test, y_test):\n",
    "    train_acc = accuracy_score(y_train, model.predict(X_train))\n",
    "    test_acc = accuracy_score(y_test, model.predict(X_test))\n",
    "    return train_acc, test_acc\n",
    "\n",
    "classifiers = {\n",
    "    \"LogisticRegression\": (LogisticRegression(max_iter=1000), {\"C\":[0.01,0.1,1,10]}),\n",
    "    \"RandomForest\": (RandomForestClassifier(), {\"n_estimators\":[50,100], \"max_depth\":[None,10,20]}),\n",
    "    \"KNN\": (KNeighborsClassifier(), {\"n_neighbors\":[3,5,7]})\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702b0344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset: mushroom\n",
      "  Seed: 0\n",
      "    Train fraction: 0.2\n",
      "      Training classifier: LogisticRegression... done! Train acc: 0.940, Test acc: 0.944\n",
      "      Training classifier: RandomForest... done! Train acc: 1.000, Test acc: 0.999\n",
      "      Training classifier: KNN... done! Train acc: 0.996, Test acc: 0.991\n",
      "    Train fraction: 0.5\n",
      "      Training classifier: LogisticRegression... done! Train acc: 0.942, Test acc: 0.944\n",
      "      Training classifier: RandomForest... done! Train acc: 1.000, Test acc: 1.000\n",
      "      Training classifier: KNN... done! Train acc: 0.999, Test acc: 0.997\n",
      "    Train fraction: 0.8\n",
      "      Training classifier: LogisticRegression... done! Train acc: 0.949, Test acc: 0.941\n",
      "      Training classifier: RandomForest... done! Train acc: 1.000, Test acc: 1.000\n",
      "      Training classifier: KNN... done! Train acc: 1.000, Test acc: 0.999\n",
      "  Seed: 42\n",
      "    Train fraction: 0.2\n",
      "      Training classifier: LogisticRegression... done! Train acc: 0.947, Test acc: 0.946\n",
      "      Training classifier: RandomForest... done! Train acc: 1.000, Test acc: 0.999\n",
      "      Training classifier: KNN... done! Train acc: 0.996, Test acc: 0.988\n",
      "    Train fraction: 0.5\n",
      "      Training classifier: LogisticRegression... done! Train acc: 0.947, Test acc: 0.949\n",
      "      Training classifier: RandomForest... done! Train acc: 1.000, Test acc: 1.000\n",
      "      Training classifier: KNN... done! Train acc: 0.999, Test acc: 0.999\n",
      "    Train fraction: 0.8\n",
      "      Training classifier: LogisticRegression... done! Train acc: 0.945, Test acc: 0.952\n",
      "      Training classifier: RandomForest... done! Train acc: 1.000, Test acc: 1.000\n",
      "      Training classifier: KNN... done! Train acc: 1.000, Test acc: 0.999\n",
      "  Seed: 99\n",
      "    Train fraction: 0.2\n",
      "      Training classifier: LogisticRegression... done! Train acc: 0.957, Test acc: 0.945\n",
      "      Training classifier: RandomForest... done! Train acc: 1.000, Test acc: 1.000\n",
      "      Training classifier: KNN... done! Train acc: 0.996, Test acc: 0.991\n",
      "    Train fraction: 0.5\n",
      "      Training classifier: LogisticRegression... done! Train acc: 0.951, Test acc: 0.945\n",
      "      Training classifier: RandomForest... done! Train acc: 1.000, Test acc: 1.000\n",
      "      Training classifier: KNN... done! Train acc: 1.000, Test acc: 0.999\n",
      "    Train fraction: 0.8\n",
      "      Training classifier: LogisticRegression... done! Train acc: 0.950, Test acc: 0.941\n",
      "      Training classifier: RandomForest... done! Train acc: 1.000, Test acc: 1.000\n",
      "      Training classifier: KNN... done! Train acc: 1.000, Test acc: 0.999\n",
      "Processing dataset: bankrupt\n",
      "  Seed: 0\n",
      "    Train fraction: 0.2\n",
      "      Training classifier: LogisticRegression... done! Train acc: 0.963, Test acc: 0.963\n",
      "      Training classifier: RandomForest... done! Train acc: 1.000, Test acc: 0.969\n",
      "      Training classifier: KNN... done! Train acc: 0.970, Test acc: 0.966\n",
      "    Train fraction: 0.5\n",
      "      Training classifier: LogisticRegression... done! Train acc: 0.965, Test acc: 0.965\n",
      "      Training classifier: RandomForest... done! Train acc: 0.998, Test acc: 0.972\n",
      "      Training classifier: KNN... done! Train acc: 0.969, Test acc: 0.967\n",
      "    Train fraction: 0.8\n",
      "      Training classifier: LogisticRegression..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done! Train acc: 0.968, Test acc: 0.968\n",
      "      Training classifier: RandomForest... done! Train acc: 1.000, Test acc: 0.968\n",
      "      Training classifier: KNN... done! Train acc: 0.968, Test acc: 0.968\n",
      "  Seed: 42\n",
      "    Train fraction: 0.2\n",
      "      Training classifier: LogisticRegression... done! Train acc: 0.963, Test acc: 0.957\n",
      "      Training classifier: RandomForest... done! Train acc: 1.000, Test acc: 0.969\n",
      "      Training classifier: KNN... done! Train acc: 0.969, Test acc: 0.966\n",
      "    Train fraction: 0.5\n",
      "      Training classifier: LogisticRegression... done! Train acc: 0.964, Test acc: 0.964\n",
      "      Training classifier: RandomForest... done! Train acc: 1.000, Test acc: 0.967\n",
      "      Training classifier: KNN... done! Train acc: 0.968, Test acc: 0.968\n",
      "    Train fraction: 0.8\n",
      "      Training classifier: LogisticRegression... done! Train acc: 0.961, Test acc: 0.960\n",
      "      Training classifier: RandomForest... done! Train acc: 0.995, Test acc: 0.972\n",
      "      Training classifier: KNN... done! Train acc: 0.968, Test acc: 0.966\n",
      "  Seed: 99\n",
      "    Train fraction: 0.2\n",
      "      Training classifier: LogisticRegression... done! Train acc: 0.966, Test acc: 0.963\n",
      "      Training classifier: RandomForest... done! Train acc: 1.000, Test acc: 0.968\n",
      "      Training classifier: KNN... done! Train acc: 0.967, Test acc: 0.966\n",
      "    Train fraction: 0.5\n",
      "      Training classifier: LogisticRegression... done! Train acc: 0.967, Test acc: 0.966\n",
      "      Training classifier: RandomForest... done! Train acc: 0.998, Test acc: 0.971\n",
      "      Training classifier: KNN... done! Train acc: 0.968, Test acc: 0.967\n",
      "    Train fraction: 0.8\n",
      "      Training classifier: LogisticRegression... done! Train acc: 0.964, Test acc: 0.962\n",
      "      Training classifier: RandomForest... done! Train acc: 0.999, Test acc: 0.971\n",
      "      Training classifier: KNN... done! Train acc: 0.969, Test acc: 0.963\n",
      "Processing dataset: gender\n",
      "  Seed: 0\n",
      "    Train fraction: 0.2\n",
      "      Training classifier: LogisticRegression..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done! Train acc: 0.610, Test acc: 0.609\n",
      "      Training classifier: RandomForest... done! Train acc: 0.986, Test acc: 0.748\n",
      "      Training classifier: KNN... done! Train acc: 0.710, Test acc: 0.593\n",
      "    Train fraction: 0.5\n",
      "      Training classifier: LogisticRegression..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done! Train acc: 0.610, Test acc: 0.609\n",
      "      Training classifier: RandomForest... done! Train acc: 0.954, Test acc: 0.764\n",
      "      Training classifier: KNN... done! Train acc: 0.718, Test acc: 0.604\n",
      "    Train fraction: 0.8\n",
      "      Training classifier: LogisticRegression..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done! Train acc: 0.610, Test acc: 0.609\n",
      "      Training classifier: RandomForest... done! Train acc: 0.933, Test acc: 0.770\n",
      "      Training classifier: KNN... done! Train acc: 0.725, Test acc: 0.610\n",
      "  Seed: 42\n",
      "    Train fraction: 0.2\n",
      "      Training classifier: LogisticRegression..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done! Train acc: 0.610, Test acc: 0.609\n",
      "      Training classifier: RandomForest... done! Train acc: 0.986, Test acc: 0.749\n",
      "      Training classifier: KNN... done! Train acc: 0.710, Test acc: 0.593\n",
      "    Train fraction: 0.5\n",
      "      Training classifier: LogisticRegression..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done! Train acc: 0.610, Test acc: 0.609\n",
      "      Training classifier: RandomForest... done! Train acc: 0.956, Test acc: 0.763\n",
      "      Training classifier: KNN... done! Train acc: 0.719, Test acc: 0.605\n",
      "    Train fraction: 0.8\n",
      "      Training classifier: LogisticRegression..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done! Train acc: 0.609, Test acc: 0.610\n",
      "      Training classifier: RandomForest... done! Train acc: 0.933, Test acc: 0.769\n",
      "      Training classifier: KNN... done! Train acc: 0.724, Test acc: 0.613\n",
      "  Seed: 99\n",
      "    Train fraction: 0.2\n",
      "      Training classifier: LogisticRegression..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done! Train acc: 0.610, Test acc: 0.609\n",
      "      Training classifier: RandomForest... done! Train acc: 0.987, Test acc: 0.749\n",
      "      Training classifier: KNN... done! Train acc: 0.709, Test acc: 0.592\n",
      "    Train fraction: 0.5\n",
      "      Training classifier: LogisticRegression..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done! Train acc: 0.610, Test acc: 0.610\n",
      "      Training classifier: RandomForest... done! Train acc: 0.953, Test acc: 0.763\n",
      "      Training classifier: KNN... done! Train acc: 0.719, Test acc: 0.604\n",
      "    Train fraction: 0.8\n",
      "      Training classifier: LogisticRegression..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/rebeccachen/miniconda3/envs/cogs118a/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done! Train acc: 0.609, Test acc: 0.610\n",
      "      Training classifier: RandomForest... done! Train acc: 0.934, Test acc: 0.767\n",
      "      Training classifier: KNN... done! Train acc: 0.723, Test acc: 0.615\n"
     ]
    }
   ],
   "source": [
    "# results = []\n",
    "\n",
    "# for dname, seeds_dict in all_partitions.items():\n",
    "#     print(f\"Processing dataset: {dname}\")\n",
    "#     for seed, partitions_dict in seeds_dict.items():\n",
    "#         print(f\"  Seed: {seed}\")\n",
    "#         for frac, split in partitions_dict.items():\n",
    "#             print(f\"    Train fraction: {frac}\")\n",
    "#             X_train, X_test, y_train, y_test = split\n",
    "#             for clf_name, (model, param_grid) in classifiers.items():\n",
    "#                 print(f\"      Training classifier: {clf_name}...\", end=\"\")\n",
    "#                 best_model, best_params, val_score = train_classifier(model, param_grid, X_train, y_train)\n",
    "#                 train_acc, test_acc = evaluate_model(best_model, X_train, y_train, X_test, y_test)\n",
    "                \n",
    "#                 results.append({\n",
    "#                     \"dataset\": dname,\n",
    "#                     \"seed\": seed,\n",
    "#                     \"train_frac\": frac,\n",
    "#                     \"classifier\": clf_name,\n",
    "#                     \"best_params\": best_params,\n",
    "#                     \"val_acc\": val_score,\n",
    "#                     \"train_acc\": train_acc,\n",
    "#                     \"test_acc\": test_acc\n",
    "#                 })\n",
    "#                 print(f\" done! Train acc: {train_acc:.3f}, Test acc: {test_acc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "68203ad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'dataset': 'mushroom',\n",
       "  'seed': 0,\n",
       "  'train_frac': 0.2,\n",
       "  'classifier': 'LogisticRegression',\n",
       "  'best_params': {'C': 1},\n",
       "  'val_acc': np.float64(0.9396467236467236),\n",
       "  'train_acc': 0.9402709359605911,\n",
       "  'test_acc': 0.9436923076923077},\n",
       " {'dataset': 'mushroom',\n",
       "  'seed': 0,\n",
       "  'train_frac': 0.2,\n",
       "  'classifier': 'RandomForest',\n",
       "  'best_params': {'max_depth': None, 'n_estimators': 50},\n",
       "  'val_acc': np.float64(0.9981481481481481),\n",
       "  'train_acc': 1.0,\n",
       "  'test_acc': 0.9987692307692307},\n",
       " {'dataset': 'mushroom',\n",
       "  'seed': 0,\n",
       "  'train_frac': 0.2,\n",
       "  'classifier': 'KNN',\n",
       "  'best_params': {'n_neighbors': 3},\n",
       "  'val_acc': np.float64(0.9821348528015195),\n",
       "  'train_acc': 0.9963054187192119,\n",
       "  'test_acc': 0.9910769230769231},\n",
       " {'dataset': 'mushroom',\n",
       "  'seed': 0,\n",
       "  'train_frac': 0.5,\n",
       "  'classifier': 'LogisticRegression',\n",
       "  'best_params': {'C': 1},\n",
       "  'val_acc': np.float64(0.941901611134338),\n",
       "  'train_acc': 0.9419005416051206,\n",
       "  'test_acc': 0.9441161989167898},\n",
       " {'dataset': 'mushroom',\n",
       "  'seed': 0,\n",
       "  'train_frac': 0.5,\n",
       "  'classifier': 'RandomForest',\n",
       "  'best_params': {'max_depth': None, 'n_estimators': 50},\n",
       "  'val_acc': np.float64(1.0),\n",
       "  'train_acc': 1.0,\n",
       "  'test_acc': 1.0},\n",
       " {'dataset': 'mushroom',\n",
       "  'seed': 0,\n",
       "  'train_frac': 0.5,\n",
       "  'classifier': 'KNN',\n",
       "  'best_params': {'n_neighbors': 3},\n",
       "  'val_acc': np.float64(0.9977844630663055),\n",
       "  'train_acc': 0.9987690792712949,\n",
       "  'test_acc': 0.9970457902511078},\n",
       " {'dataset': 'mushroom',\n",
       "  'seed': 0,\n",
       "  'train_frac': 0.8,\n",
       "  'classifier': 'LogisticRegression',\n",
       "  'best_params': {'C': 1},\n",
       "  'val_acc': np.float64(0.9483004678154794),\n",
       "  'train_acc': 0.9486074780735497,\n",
       "  'test_acc': 0.940923076923077},\n",
       " {'dataset': 'mushroom',\n",
       "  'seed': 0,\n",
       "  'train_frac': 0.8,\n",
       "  'classifier': 'RandomForest',\n",
       "  'best_params': {'max_depth': None, 'n_estimators': 50},\n",
       "  'val_acc': np.float64(1.0),\n",
       "  'train_acc': 1.0,\n",
       "  'test_acc': 1.0},\n",
       " {'dataset': 'mushroom',\n",
       "  'seed': 0,\n",
       "  'train_frac': 0.8,\n",
       "  'classifier': 'KNN',\n",
       "  'best_params': {'n_neighbors': 3},\n",
       "  'val_acc': np.float64(0.99846142002724),\n",
       "  'train_acc': 1.0,\n",
       "  'test_acc': 0.9993846153846154},\n",
       " {'dataset': 'mushroom',\n",
       "  'seed': 42,\n",
       "  'train_frac': 0.2,\n",
       "  'classifier': 'LogisticRegression',\n",
       "  'best_params': {'C': 1},\n",
       "  'val_acc': np.float64(0.9439696106362773),\n",
       "  'train_acc': 0.9470443349753694,\n",
       "  'test_acc': 0.9461538461538461},\n",
       " {'dataset': 'mushroom',\n",
       "  'seed': 42,\n",
       "  'train_frac': 0.2,\n",
       "  'classifier': 'RandomForest',\n",
       "  'best_params': {'max_depth': None, 'n_estimators': 50},\n",
       "  'val_acc': np.float64(0.9993846153846153),\n",
       "  'train_acc': 1.0,\n",
       "  'test_acc': 0.9987692307692307},\n",
       " {'dataset': 'mushroom',\n",
       "  'seed': 42,\n",
       "  'train_frac': 0.2,\n",
       "  'classifier': 'KNN',\n",
       "  'best_params': {'n_neighbors': 3},\n",
       "  'val_acc': np.float64(0.9846058879392213),\n",
       "  'train_acc': 0.9963054187192119,\n",
       "  'test_acc': 0.9883076923076923},\n",
       " {'dataset': 'mushroom',\n",
       "  'seed': 42,\n",
       "  'train_frac': 0.5,\n",
       "  'classifier': 'LogisticRegression',\n",
       "  'best_params': {'C': 1},\n",
       "  'val_acc': np.float64(0.9463326850017267),\n",
       "  'train_acc': 0.9470704086656819,\n",
       "  'test_acc': 0.9487936976858691},\n",
       " {'dataset': 'mushroom',\n",
       "  'seed': 42,\n",
       "  'train_frac': 0.5,\n",
       "  'classifier': 'RandomForest',\n",
       "  'best_params': {'max_depth': None, 'n_estimators': 50},\n",
       "  'val_acc': np.float64(1.0),\n",
       "  'train_acc': 1.0,\n",
       "  'test_acc': 1.0},\n",
       " {'dataset': 'mushroom',\n",
       "  'seed': 42,\n",
       "  'train_frac': 0.5,\n",
       "  'classifier': 'KNN',\n",
       "  'best_params': {'n_neighbors': 3},\n",
       "  'val_acc': np.float64(0.9953214088791134),\n",
       "  'train_acc': 0.999015263417036,\n",
       "  'test_acc': 0.9987690792712949},\n",
       " {'dataset': 'mushroom',\n",
       "  'seed': 42,\n",
       "  'train_frac': 0.8,\n",
       "  'classifier': 'LogisticRegression',\n",
       "  'best_params': {'C': 10},\n",
       "  'val_acc': np.float64(0.9432220050926748),\n",
       "  'train_acc': 0.9450684720726266,\n",
       "  'test_acc': 0.952},\n",
       " {'dataset': 'mushroom',\n",
       "  'seed': 42,\n",
       "  'train_frac': 0.8,\n",
       "  'classifier': 'RandomForest',\n",
       "  'best_params': {'max_depth': None, 'n_estimators': 50},\n",
       "  'val_acc': np.float64(1.0),\n",
       "  'train_acc': 1.0,\n",
       "  'test_acc': 1.0},\n",
       " {'dataset': 'mushroom',\n",
       "  'seed': 42,\n",
       "  'train_frac': 0.8,\n",
       "  'classifier': 'KNN',\n",
       "  'best_params': {'n_neighbors': 3},\n",
       "  'val_acc': np.float64(0.9978457985432581),\n",
       "  'train_acc': 0.9996922603477458,\n",
       "  'test_acc': 0.9987692307692307},\n",
       " {'dataset': 'mushroom',\n",
       "  'seed': 99,\n",
       "  'train_frac': 0.2,\n",
       "  'classifier': 'LogisticRegression',\n",
       "  'best_params': {'C': 10},\n",
       "  'val_acc': np.float64(0.9581329534662867),\n",
       "  'train_acc': 0.9568965517241379,\n",
       "  'test_acc': 0.9446153846153846},\n",
       " {'dataset': 'mushroom',\n",
       "  'seed': 99,\n",
       "  'train_frac': 0.2,\n",
       "  'classifier': 'RandomForest',\n",
       "  'best_params': {'max_depth': None, 'n_estimators': 50},\n",
       "  'val_acc': np.float64(0.9987673314339981),\n",
       "  'train_acc': 1.0,\n",
       "  'test_acc': 1.0},\n",
       " {'dataset': 'mushroom',\n",
       "  'seed': 99,\n",
       "  'train_frac': 0.2,\n",
       "  'classifier': 'KNN',\n",
       "  'best_params': {'n_neighbors': 3},\n",
       "  'val_acc': np.float64(0.9833713200379867),\n",
       "  'train_acc': 0.9963054187192119,\n",
       "  'test_acc': 0.9907692307692307},\n",
       " {'dataset': 'mushroom',\n",
       "  'seed': 99,\n",
       "  'train_frac': 0.5,\n",
       "  'classifier': 'LogisticRegression',\n",
       "  'best_params': {'C': 1},\n",
       "  'val_acc': np.float64(0.947809911596653),\n",
       "  'train_acc': 0.9510093549975381,\n",
       "  'test_acc': 0.9453471196454948},\n",
       " {'dataset': 'mushroom',\n",
       "  'seed': 99,\n",
       "  'train_frac': 0.5,\n",
       "  'classifier': 'RandomForest',\n",
       "  'best_params': {'max_depth': None, 'n_estimators': 50},\n",
       "  'val_acc': np.float64(1.0),\n",
       "  'train_acc': 1.0,\n",
       "  'test_acc': 1.0},\n",
       " {'dataset': 'mushroom',\n",
       "  'seed': 99,\n",
       "  'train_frac': 0.5,\n",
       "  'classifier': 'KNN',\n",
       "  'best_params': {'n_neighbors': 3},\n",
       "  'val_acc': np.float64(0.9963069335126848),\n",
       "  'train_acc': 0.9997538158542589,\n",
       "  'test_acc': 0.9987690792712949},\n",
       " {'dataset': 'mushroom',\n",
       "  'seed': 99,\n",
       "  'train_frac': 0.8,\n",
       "  'classifier': 'LogisticRegression',\n",
       "  'best_params': {'C': 1},\n",
       "  'val_acc': np.float64(0.9486083969917688),\n",
       "  'train_acc': 0.9498384366825665,\n",
       "  'test_acc': 0.940923076923077},\n",
       " {'dataset': 'mushroom',\n",
       "  'seed': 99,\n",
       "  'train_frac': 0.8,\n",
       "  'classifier': 'RandomForest',\n",
       "  'best_params': {'max_depth': None, 'n_estimators': 50},\n",
       "  'val_acc': np.float64(1.0),\n",
       "  'train_acc': 1.0,\n",
       "  'test_acc': 1.0},\n",
       " {'dataset': 'mushroom',\n",
       "  'seed': 99,\n",
       "  'train_frac': 0.8,\n",
       "  'classifier': 'KNN',\n",
       "  'best_params': {'n_neighbors': 3},\n",
       "  'val_acc': np.float64(0.998768638597738),\n",
       "  'train_acc': 1.0,\n",
       "  'test_acc': 0.9993846153846154},\n",
       " {'dataset': 'bankrupt',\n",
       "  'seed': 0,\n",
       "  'train_frac': 0.2,\n",
       "  'classifier': 'LogisticRegression',\n",
       "  'best_params': {'C': 0.01},\n",
       "  'val_acc': np.float64(0.9559954751131222),\n",
       "  'train_acc': 0.962582538517975,\n",
       "  'test_acc': 0.9629765395894428},\n",
       " {'dataset': 'bankrupt',\n",
       "  'seed': 0,\n",
       "  'train_frac': 0.2,\n",
       "  'classifier': 'RandomForest',\n",
       "  'best_params': {'max_depth': 10, 'n_estimators': 50},\n",
       "  'val_acc': np.float64(0.9713935574229691),\n",
       "  'train_acc': 1.0,\n",
       "  'test_acc': 0.969024926686217},\n",
       " {'dataset': 'bankrupt',\n",
       "  'seed': 0,\n",
       "  'train_frac': 0.2,\n",
       "  'classifier': 'KNN',\n",
       "  'best_params': {'n_neighbors': 3},\n",
       "  'val_acc': np.float64(0.9684523809523811),\n",
       "  'train_acc': 0.9699192956713133,\n",
       "  'test_acc': 0.9660923753665689},\n",
       " {'dataset': 'bankrupt',\n",
       "  'seed': 0,\n",
       "  'train_frac': 0.5,\n",
       "  'classifier': 'LogisticRegression',\n",
       "  'best_params': {'C': 0.01},\n",
       "  'val_acc': np.float64(0.9633327735217746),\n",
       "  'train_acc': 0.9650924024640657,\n",
       "  'test_acc': 0.964516129032258},\n",
       " {'dataset': 'bankrupt',\n",
       "  'seed': 0,\n",
       "  'train_frac': 0.5,\n",
       "  'classifier': 'RandomForest',\n",
       "  'best_params': {'max_depth': 10, 'n_estimators': 100},\n",
       "  'val_acc': np.float64(0.9709582682014115),\n",
       "  'train_acc': 0.9976532707538868,\n",
       "  'test_acc': 0.9724340175953079},\n",
       " {'dataset': 'bankrupt',\n",
       "  'seed': 0,\n",
       "  'train_frac': 0.5,\n",
       "  'classifier': 'KNN',\n",
       "  'best_params': {'n_neighbors': 7},\n",
       "  'val_acc': np.float64(0.9680257168817634),\n",
       "  'train_acc': 0.9686124963332355,\n",
       "  'test_acc': 0.9674486803519061},\n",
       " {'dataset': 'bankrupt',\n",
       "  'seed': 0,\n",
       "  'train_frac': 0.8,\n",
       "  'classifier': 'LogisticRegression',\n",
       "  'best_params': {'C': 0.01},\n",
       "  'val_acc': np.float64(0.9657195233730522),\n",
       "  'train_acc': 0.9679193400549955,\n",
       "  'test_acc': 0.967741935483871},\n",
       " {'dataset': 'bankrupt',\n",
       "  'seed': 0,\n",
       "  'train_frac': 0.8,\n",
       "  'classifier': 'RandomForest',\n",
       "  'best_params': {'max_depth': 20, 'n_estimators': 50},\n",
       "  'val_acc': np.float64(0.970852428964253),\n",
       "  'train_acc': 0.9998166819431714,\n",
       "  'test_acc': 0.968475073313783},\n",
       " {'dataset': 'bankrupt',\n",
       "  'seed': 0,\n",
       "  'train_frac': 0.8,\n",
       "  'classifier': 'KNN',\n",
       "  'best_params': {'n_neighbors': 5},\n",
       "  'val_acc': np.float64(0.9679193400549956),\n",
       "  'train_acc': 0.9679193400549955,\n",
       "  'test_acc': 0.967741935483871},\n",
       " {'dataset': 'bankrupt',\n",
       "  'seed': 42,\n",
       "  'train_frac': 0.2,\n",
       "  'classifier': 'LogisticRegression',\n",
       "  'best_params': {'C': 0.01},\n",
       "  'val_acc': np.float64(0.9581771170006463),\n",
       "  'train_acc': 0.9633162142333089,\n",
       "  'test_acc': 0.9567448680351907},\n",
       " {'dataset': 'bankrupt',\n",
       "  'seed': 42,\n",
       "  'train_frac': 0.2,\n",
       "  'classifier': 'RandomForest',\n",
       "  'best_params': {'max_depth': 20, 'n_estimators': 100},\n",
       "  'val_acc': np.float64(0.9669898728722257),\n",
       "  'train_acc': 1.0,\n",
       "  'test_acc': 0.969024926686217},\n",
       " {'dataset': 'bankrupt',\n",
       "  'seed': 42,\n",
       "  'train_frac': 0.2,\n",
       "  'classifier': 'KNN',\n",
       "  'best_params': {'n_neighbors': 5},\n",
       "  'val_acc': np.float64(0.9677197802197803),\n",
       "  'train_acc': 0.9691856199559794,\n",
       "  'test_acc': 0.9664589442815249},\n",
       " {'dataset': 'bankrupt',\n",
       "  'seed': 42,\n",
       "  'train_frac': 0.5,\n",
       "  'classifier': 'LogisticRegression',\n",
       "  'best_params': {'C': 0.01},\n",
       "  'val_acc': np.float64(0.9630395183898097),\n",
       "  'train_acc': 0.9642123789967733,\n",
       "  'test_acc': 0.9636363636363636},\n",
       " {'dataset': 'bankrupt',\n",
       "  'seed': 42,\n",
       "  'train_frac': 0.5,\n",
       "  'classifier': 'RandomForest',\n",
       "  'best_params': {'max_depth': 20, 'n_estimators': 100},\n",
       "  'val_acc': np.float64(0.9703721885617579),\n",
       "  'train_acc': 1.0,\n",
       "  'test_acc': 0.9674486803519061},\n",
       " {'dataset': 'bankrupt',\n",
       "  'seed': 42,\n",
       "  'train_frac': 0.5,\n",
       "  'classifier': 'KNN',\n",
       "  'best_params': {'n_neighbors': 7},\n",
       "  'val_acc': np.float64(0.9677324617497988),\n",
       "  'train_acc': 0.9680258140217073,\n",
       "  'test_acc': 0.967741935483871},\n",
       " {'dataset': 'bankrupt',\n",
       "  'seed': 42,\n",
       "  'train_frac': 0.8,\n",
       "  'classifier': 'LogisticRegression',\n",
       "  'best_params': {'C': 0.01},\n",
       "  'val_acc': np.float64(0.9602199816681944),\n",
       "  'train_acc': 0.9611365719523373,\n",
       "  'test_acc': 0.9596774193548387},\n",
       " {'dataset': 'bankrupt',\n",
       "  'seed': 42,\n",
       "  'train_frac': 0.8,\n",
       "  'classifier': 'RandomForest',\n",
       "  'best_params': {'max_depth': 10, 'n_estimators': 50},\n",
       "  'val_acc': np.float64(0.9719523373052243),\n",
       "  'train_acc': 0.9952337305224565,\n",
       "  'test_acc': 0.9721407624633431},\n",
       " {'dataset': 'bankrupt',\n",
       "  'seed': 42,\n",
       "  'train_frac': 0.8,\n",
       "  'classifier': 'KNN',\n",
       "  'best_params': {'n_neighbors': 5},\n",
       "  'val_acc': np.float64(0.9679193400549956),\n",
       "  'train_acc': 0.9684692942254812,\n",
       "  'test_acc': 0.966275659824047},\n",
       " {'dataset': 'bankrupt',\n",
       "  'seed': 99,\n",
       "  'train_frac': 0.2,\n",
       "  'classifier': 'LogisticRegression',\n",
       "  'best_params': {'C': 0.01},\n",
       "  'val_acc': np.float64(0.9603856927386338),\n",
       "  'train_acc': 0.9655172413793104,\n",
       "  'test_acc': 0.9633431085043989},\n",
       " {'dataset': 'bankrupt',\n",
       "  'seed': 99,\n",
       "  'train_frac': 0.2,\n",
       "  'classifier': 'RandomForest',\n",
       "  'best_params': {'max_depth': None, 'n_estimators': 50},\n",
       "  'val_acc': np.float64(0.9677143934496876),\n",
       "  'train_acc': 1.0,\n",
       "  'test_acc': 0.968475073313783},\n",
       " {'dataset': 'bankrupt',\n",
       "  'seed': 99,\n",
       "  'train_frac': 0.2,\n",
       "  'classifier': 'KNN',\n",
       "  'best_params': {'n_neighbors': 5},\n",
       "  'val_acc': np.float64(0.9677197802197803),\n",
       "  'train_acc': 0.966984592809978,\n",
       "  'test_acc': 0.9664589442815249},\n",
       " {'dataset': 'bankrupt',\n",
       "  'seed': 99,\n",
       "  'train_frac': 0.5,\n",
       "  'classifier': 'LogisticRegression',\n",
       "  'best_params': {'C': 0.01},\n",
       "  'val_acc': np.float64(0.9650923043135634),\n",
       "  'train_acc': 0.9674391317101789,\n",
       "  'test_acc': 0.9656891495601173},\n",
       " {'dataset': 'bankrupt',\n",
       "  'seed': 99,\n",
       "  'train_frac': 0.5,\n",
       "  'classifier': 'RandomForest',\n",
       "  'best_params': {'max_depth': 10, 'n_estimators': 100},\n",
       "  'val_acc': np.float64(0.9686135190185212),\n",
       "  'train_acc': 0.9976532707538868,\n",
       "  'test_acc': 0.9706744868035191},\n",
       " {'dataset': 'bankrupt',\n",
       "  'seed': 99,\n",
       "  'train_frac': 0.5,\n",
       "  'classifier': 'KNN',\n",
       "  'best_params': {'n_neighbors': 7},\n",
       "  'val_acc': np.float64(0.9674392066178339),\n",
       "  'train_acc': 0.9680258140217073,\n",
       "  'test_acc': 0.9668621700879766},\n",
       " {'dataset': 'bankrupt',\n",
       "  'seed': 99,\n",
       "  'train_frac': 0.8,\n",
       "  'classifier': 'LogisticRegression',\n",
       "  'best_params': {'C': 0.01},\n",
       "  'val_acc': np.float64(0.9637030247479377),\n",
       "  'train_acc': 0.9635197066911091,\n",
       "  'test_acc': 0.9618768328445748},\n",
       " {'dataset': 'bankrupt',\n",
       "  'seed': 99,\n",
       "  'train_frac': 0.8,\n",
       "  'classifier': 'RandomForest',\n",
       "  'best_params': {'max_depth': None, 'n_estimators': 50},\n",
       "  'val_acc': np.float64(0.9684692942254813),\n",
       "  'train_acc': 0.9992667277726857,\n",
       "  'test_acc': 0.9706744868035191},\n",
       " {'dataset': 'bankrupt',\n",
       "  'seed': 99,\n",
       "  'train_frac': 0.8,\n",
       "  'classifier': 'KNN',\n",
       "  'best_params': {'n_neighbors': 5},\n",
       "  'val_acc': np.float64(0.9673693858845096),\n",
       "  'train_acc': 0.9688359303391384,\n",
       "  'test_acc': 0.9626099706744868},\n",
       " {'dataset': 'gender',\n",
       "  'seed': 0,\n",
       "  'train_frac': 0.2,\n",
       "  'classifier': 'LogisticRegression',\n",
       "  'best_params': {'C': 0.1},\n",
       "  'val_acc': np.float64(0.6094794943453496),\n",
       "  'train_acc': 0.6098190337147319,\n",
       "  'test_acc': 0.6094927683845998},\n",
       " {'dataset': 'gender',\n",
       "  'seed': 0,\n",
       "  'train_frac': 0.2,\n",
       "  'classifier': 'RandomForest',\n",
       "  'best_params': {'max_depth': 20, 'n_estimators': 100},\n",
       "  'val_acc': np.float64(0.7420635662181009),\n",
       "  'train_acc': 0.9856381353342614,\n",
       "  'test_acc': 0.7484127792489984},\n",
       " {'dataset': 'gender',\n",
       "  'seed': 0,\n",
       "  'train_frac': 0.2,\n",
       "  'classifier': 'KNN',\n",
       "  'best_params': {'n_neighbors': 7},\n",
       "  'val_acc': np.float64(0.5862560626710654),\n",
       "  'train_acc': 0.7095032764064781,\n",
       "  'test_acc': 0.5928311944048347},\n",
       " {'dataset': 'gender',\n",
       "  'seed': 0,\n",
       "  'train_frac': 0.5,\n",
       "  'classifier': 'LogisticRegression',\n",
       "  'best_params': {'C': 1},\n",
       "  'val_acc': np.float64(0.6095553718447162),\n",
       "  'train_acc': 0.6095146263954152,\n",
       "  'test_acc': 0.6094791878861954},\n",
       " {'dataset': 'gender',\n",
       "  'seed': 0,\n",
       "  'train_frac': 0.5,\n",
       "  'classifier': 'RandomForest',\n",
       "  'best_params': {'max_depth': 20, 'n_estimators': 100},\n",
       "  'val_acc': np.float64(0.7612515199326829),\n",
       "  'train_acc': 0.9543010022543934,\n",
       "  'test_acc': 0.7637672302573505},\n",
       " {'dataset': 'gender',\n",
       "  'seed': 0,\n",
       "  'train_frac': 0.5,\n",
       "  'classifier': 'KNN',\n",
       "  'best_params': {'n_neighbors': 7},\n",
       "  'val_acc': np.float64(0.6062416417016879),\n",
       "  'train_acc': 0.7181193470407692,\n",
       "  'test_acc': 0.604101310518096},\n",
       " {'dataset': 'gender',\n",
       "  'seed': 0,\n",
       "  'train_frac': 0.8,\n",
       "  'classifier': 'LogisticRegression',\n",
       "  'best_params': {'C': 10},\n",
       "  'val_acc': np.float64(0.6094639901540551),\n",
       "  'train_acc': 0.6095149174553325,\n",
       "  'test_acc': 0.6094927683845998},\n",
       " {'dataset': 'gender',\n",
       "  'seed': 0,\n",
       "  'train_frac': 0.8,\n",
       "  'classifier': 'RandomForest',\n",
       "  'best_params': {'max_depth': 20, 'n_estimators': 100},\n",
       "  'val_acc': np.float64(0.7672113058608836),\n",
       "  'train_acc': 0.9332937232101176,\n",
       "  'test_acc': 0.7703198207374211},\n",
       " {'dataset': 'gender',\n",
       "  'seed': 0,\n",
       "  'train_frac': 0.8,\n",
       "  'classifier': 'KNN',\n",
       "  'best_params': {'n_neighbors': 7},\n",
       "  'val_acc': np.float64(0.6080634893689258),\n",
       "  'train_acc': 0.7249586215677121,\n",
       "  'test_acc': 0.6095946221226319},\n",
       " {'dataset': 'gender',\n",
       "  'seed': 42,\n",
       "  'train_frac': 0.2,\n",
       "  'classifier': 'LogisticRegression',\n",
       "  'best_params': {'C': 1},\n",
       "  'val_acc': np.float64(0.6099548360005868),\n",
       "  'train_acc': 0.6099548433096799,\n",
       "  'test_acc': 0.6091532559244924},\n",
       " {'dataset': 'gender',\n",
       "  'seed': 42,\n",
       "  'train_frac': 0.2,\n",
       "  'classifier': 'RandomForest',\n",
       "  'best_params': {'max_depth': 20, 'n_estimators': 100},\n",
       "  'val_acc': np.float64(0.7459004916423113),\n",
       "  'train_acc': 0.9862832309102638,\n",
       "  'test_acc': 0.7488880966931486},\n",
       " {'dataset': 'gender',\n",
       "  'seed': 42,\n",
       "  'train_frac': 0.2,\n",
       "  'classifier': 'KNN',\n",
       "  'best_params': {'n_neighbors': 7},\n",
       "  'val_acc': np.float64(0.5907036517100848),\n",
       "  'train_acc': 0.7102841815774285,\n",
       "  'test_acc': 0.5928566578393427},\n",
       " {'dataset': 'gender',\n",
       "  'seed': 42,\n",
       "  'train_frac': 0.5,\n",
       "  'classifier': 'LogisticRegression',\n",
       "  'best_params': {'C': 10},\n",
       "  'val_acc': np.float64(0.6094874684304825),\n",
       "  'train_acc': 0.609528207078252,\n",
       "  'test_acc': 0.6093841243973653},\n",
       " {'dataset': 'gender',\n",
       "  'seed': 42,\n",
       "  'train_frac': 0.5,\n",
       "  'classifier': 'RandomForest',\n",
       "  'best_params': {'max_depth': 20, 'n_estimators': 100},\n",
       "  'val_acc': np.float64(0.7604503535259373),\n",
       "  'train_acc': 0.9563788467284136,\n",
       "  'test_acc': 0.7625993073945814},\n",
       " {'dataset': 'gender',\n",
       "  'seed': 42,\n",
       "  'train_frac': 0.5,\n",
       "  'classifier': 'KNN',\n",
       "  'best_params': {'n_neighbors': 7},\n",
       "  'val_acc': np.float64(0.6034576828727864),\n",
       "  'train_acc': 0.7192872857647282,\n",
       "  'test_acc': 0.6045358864670334},\n",
       " {'dataset': 'gender',\n",
       "  'seed': 42,\n",
       "  'train_frac': 0.8,\n",
       "  'classifier': 'LogisticRegression',\n",
       "  'best_params': {'C': 0.01},\n",
       "  'val_acc': np.float64(0.6094300386198701),\n",
       "  'train_acc': 0.6094300386198701,\n",
       "  'test_acc': 0.6095606708766211},\n",
       " {'dataset': 'gender',\n",
       "  'seed': 42,\n",
       "  'train_frac': 0.8,\n",
       "  'classifier': 'RandomForest',\n",
       "  'best_params': {'max_depth': 20, 'n_estimators': 100},\n",
       "  'val_acc': np.float64(0.7658787081441243),\n",
       "  'train_acc': 0.9334549929974961,\n",
       "  'test_acc': 0.7693012833570992},\n",
       " {'dataset': 'gender',\n",
       "  'seed': 42,\n",
       "  'train_frac': 0.8,\n",
       "  'classifier': 'KNN',\n",
       "  'best_params': {'n_neighbors': 7},\n",
       "  'val_acc': np.float64(0.6100581420022917),\n",
       "  'train_acc': 0.7238636845902474,\n",
       "  'test_acc': 0.6132613566917906},\n",
       " {'dataset': 'gender',\n",
       "  'seed': 99,\n",
       "  'train_frac': 0.2,\n",
       "  'classifier': 'LogisticRegression',\n",
       "  'best_params': {'C': 0.01},\n",
       "  'val_acc': np.float64(0.6096153293029365),\n",
       "  'train_acc': 0.6095134621260992,\n",
       "  'test_acc': 0.6093739390235622},\n",
       " {'dataset': 'gender',\n",
       "  'seed': 99,\n",
       "  'train_frac': 0.2,\n",
       "  'classifier': 'RandomForest',\n",
       "  'best_params': {'max_depth': 20, 'n_estimators': 100},\n",
       "  'val_acc': np.float64(0.7463754413440087),\n",
       "  'train_acc': 0.9868943740875293,\n",
       "  'test_acc': 0.7488201942011272},\n",
       " {'dataset': 'gender',\n",
       "  'seed': 99,\n",
       "  'train_frac': 0.2,\n",
       "  'classifier': 'KNN',\n",
       "  'best_params': {'n_neighbors': 7},\n",
       "  'val_acc': np.float64(0.5949138552406061),\n",
       "  'train_acc': 0.7089260856279496,\n",
       "  'test_acc': 0.5923728525836898},\n",
       " {'dataset': 'gender',\n",
       "  'seed': 99,\n",
       "  'train_frac': 0.5,\n",
       "  'classifier': 'LogisticRegression',\n",
       "  'best_params': {'C': 0.1},\n",
       "  'val_acc': np.float64(0.609541782124189),\n",
       "  'train_acc': 0.6095010457125785,\n",
       "  'test_acc': 0.6095606708766211},\n",
       " {'dataset': 'gender',\n",
       "  'seed': 99,\n",
       "  'train_frac': 0.5,\n",
       "  'classifier': 'RandomForest',\n",
       "  'best_params': {'max_depth': 20, 'n_estimators': 100},\n",
       "  'val_acc': np.float64(0.7598935217361429),\n",
       "  'train_acc': 0.9527120623624956,\n",
       "  'test_acc': 0.7627079513818157},\n",
       " {'dataset': 'gender',\n",
       "  'seed': 99,\n",
       "  'train_frac': 0.5,\n",
       "  'classifier': 'KNN',\n",
       "  'best_params': {'n_neighbors': 7},\n",
       "  'val_acc': np.float64(0.6020452649281249),\n",
       "  'train_acc': 0.7192058016677079,\n",
       "  'test_acc': 0.6035580905819243},\n",
       " {'dataset': 'gender',\n",
       "  'seed': 99,\n",
       "  'train_frac': 0.8,\n",
       "  'classifier': 'LogisticRegression',\n",
       "  'best_params': {'C': 0.01},\n",
       "  'val_acc': np.float64(0.6094130628527776),\n",
       "  'train_acc': 0.6094470143869626,\n",
       "  'test_acc': 0.60996808582875},\n",
       " {'dataset': 'gender',\n",
       "  'seed': 99,\n",
       "  'train_frac': 0.8,\n",
       "  'classifier': 'RandomForest',\n",
       "  'best_params': {'max_depth': 20, 'n_estimators': 100},\n",
       "  'val_acc': np.float64(0.7675423333191869),\n",
       "  'train_acc': 0.9339727538938166,\n",
       "  'test_acc': 0.7674339648265092},\n",
       " {'dataset': 'gender',\n",
       "  'seed': 99,\n",
       "  'train_frac': 0.8,\n",
       "  'classifier': 'KNN',\n",
       "  'best_params': {'n_neighbors': 7},\n",
       "  'val_acc': np.float64(0.609141450579298),\n",
       "  'train_acc': 0.722743283962144,\n",
       "  'test_acc': 0.6150947239763699}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "88c0c306",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>seed</th>\n",
       "      <th>train_frac</th>\n",
       "      <th>classifier</th>\n",
       "      <th>best_params</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>test_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mushroom</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'C': 1}</td>\n",
       "      <td>0.939647</td>\n",
       "      <td>0.940271</td>\n",
       "      <td>0.943692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mushroom</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 50}</td>\n",
       "      <td>0.998148</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mushroom</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>KNN</td>\n",
       "      <td>{'n_neighbors': 3}</td>\n",
       "      <td>0.982135</td>\n",
       "      <td>0.996305</td>\n",
       "      <td>0.991077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mushroom</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'C': 1}</td>\n",
       "      <td>0.941902</td>\n",
       "      <td>0.941901</td>\n",
       "      <td>0.944116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mushroom</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 50}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    dataset  seed  train_frac          classifier  \\\n",
       "0  mushroom     0         0.2  LogisticRegression   \n",
       "1  mushroom     0         0.2        RandomForest   \n",
       "2  mushroom     0         0.2                 KNN   \n",
       "3  mushroom     0         0.5  LogisticRegression   \n",
       "4  mushroom     0         0.5        RandomForest   \n",
       "\n",
       "                               best_params   val_acc  train_acc  test_acc  \n",
       "0                                 {'C': 1}  0.939647   0.940271  0.943692  \n",
       "1  {'max_depth': None, 'n_estimators': 50}  0.998148   1.000000  0.998769  \n",
       "2                       {'n_neighbors': 3}  0.982135   0.996305  0.991077  \n",
       "3                                 {'C': 1}  0.941902   0.941901  0.944116  \n",
       "4  {'max_depth': None, 'n_estimators': 50}  1.000000   1.000000  1.000000  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results = pd.DataFrame(results)\n",
    "df_results.to_csv(\"classification_results.csv\", index=False)\n",
    "df_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d61afe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset: mushroom\n",
      "  Seed: 0\n",
      "    Train fraction: 0.2\n",
      "      Training classifier: LogisticRegression... done! Train acc: 0.940, Test acc: 0.944\n",
      "      Training classifier: RandomForest... done! Train acc: 1.000, Test acc: 0.999\n",
      "      Training classifier: KNN... done! Train acc: 0.996, Test acc: 0.991\n",
      "    Train fraction: 0.5\n",
      "      Training classifier: LogisticRegression... done! Train acc: 0.942, Test acc: 0.944\n",
      "      Training classifier: RandomForest... done! Train acc: 1.000, Test acc: 1.000\n",
      "      Training classifier: KNN... done! Train acc: 0.999, Test acc: 0.997\n",
      "    Train fraction: 0.8\n",
      "      Training classifier: LogisticRegression... done! Train acc: 0.949, Test acc: 0.941\n",
      "      Training classifier: RandomForest... done! Train acc: 1.000, Test acc: 1.000\n",
      "      Training classifier: KNN... done! Train acc: 1.000, Test acc: 0.999\n",
      "  Seed: 42\n",
      "    Train fraction: 0.2\n",
      "      Training classifier: LogisticRegression... done! Train acc: 0.947, Test acc: 0.946\n",
      "      Training classifier: RandomForest... done! Train acc: 1.000, Test acc: 0.999\n",
      "      Training classifier: KNN... done! Train acc: 0.996, Test acc: 0.988\n",
      "    Train fraction: 0.5\n",
      "      Training classifier: LogisticRegression... done! Train acc: 0.947, Test acc: 0.949\n",
      "      Training classifier: RandomForest... done! Train acc: 1.000, Test acc: 1.000\n",
      "      Training classifier: KNN... done! Train acc: 0.999, Test acc: 0.999\n",
      "    Train fraction: 0.8\n",
      "      Training classifier: LogisticRegression... done! Train acc: 0.945, Test acc: 0.952\n",
      "      Training classifier: RandomForest... done! Train acc: 1.000, Test acc: 1.000\n",
      "      Training classifier: KNN... done! Train acc: 1.000, Test acc: 0.999\n",
      "  Seed: 99\n",
      "    Train fraction: 0.2\n",
      "      Training classifier: LogisticRegression... done! Train acc: 0.957, Test acc: 0.945\n",
      "      Training classifier: RandomForest... done! Train acc: 1.000, Test acc: 1.000\n",
      "      Training classifier: KNN... done! Train acc: 0.996, Test acc: 0.991\n",
      "    Train fraction: 0.5\n",
      "      Training classifier: LogisticRegression... done! Train acc: 0.951, Test acc: 0.945\n",
      "      Training classifier: RandomForest... done! Train acc: 1.000, Test acc: 1.000\n",
      "      Training classifier: KNN... done! Train acc: 1.000, Test acc: 0.999\n",
      "    Train fraction: 0.8\n",
      "      Training classifier: LogisticRegression... done! Train acc: 0.950, Test acc: 0.941\n",
      "      Training classifier: RandomForest... done! Train acc: 1.000, Test acc: 1.000\n",
      "      Training classifier: KNN... done! Train acc: 1.000, Test acc: 0.999\n",
      "Processing dataset: bankrupt\n",
      "  Seed: 0\n",
      "    Train fraction: 0.2\n",
      "      Training classifier: LogisticRegression... done! Train acc: 0.963, Test acc: 0.963\n",
      "      Training classifier: RandomForest... done! Train acc: 1.000, Test acc: 0.969\n",
      "      Training classifier: KNN... done! Train acc: 0.970, Test acc: 0.966\n",
      "    Train fraction: 0.5\n",
      "      Training classifier: LogisticRegression... done! Train acc: 0.965, Test acc: 0.965\n",
      "      Training classifier: RandomForest... done! Train acc: 0.998, Test acc: 0.972\n",
      "      Training classifier: KNN... done! Train acc: 0.969, Test acc: 0.967\n",
      "    Train fraction: 0.8\n",
      " done! Train acc: 0.968, Test acc: 0.968\n",
      "      Training classifier: RandomForest... done! Train acc: 1.000, Test acc: 0.968\n",
      "      Training classifier: KNN... done! Train acc: 0.968, Test acc: 0.968\n",
      "  Seed: 42\n",
      "    Train fraction: 0.2\n",
      "      Training classifier: LogisticRegression... done! Train acc: 0.963, Test acc: 0.957\n",
      "      Training classifier: RandomForest... done! Train acc: 1.000, Test acc: 0.969\n",
      "      Training classifier: KNN... done! Train acc: 0.969, Test acc: 0.966\n",
      "    Train fraction: 0.5\n",
      "      Training classifier: LogisticRegression... done! Train acc: 0.964, Test acc: 0.964\n",
      "      Training classifier: RandomForest... done! Train acc: 1.000, Test acc: 0.967\n",
      "      Training classifier: KNN... done! Train acc: 0.968, Test acc: 0.968\n",
      "    Train fraction: 0.8\n",
      "      Training classifier: LogisticRegression... done! Train acc: 0.961, Test acc: 0.960\n",
      "      Training classifier: RandomForest... done! Train acc: 0.995, Test acc: 0.972\n",
      "      Training classifier: KNN... done! Train acc: 0.968, Test acc: 0.966\n",
      "  Seed: 99\n",
      "    Train fraction: 0.2\n",
      "      Training classifier: LogisticRegression... done! Train acc: 0.966, Test acc: 0.963\n",
      "      Training classifier: RandomForest... done! Train acc: 1.000, Test acc: 0.968\n",
      "      Training classifier: KNN... done! Train acc: 0.967, Test acc: 0.966\n",
      "    Train fraction: 0.5\n",
      "      Training classifier: LogisticRegression... done! Train acc: 0.967, Test acc: 0.966\n",
      "      Training classifier: RandomForest... done! Train acc: 0.998, Test acc: 0.971\n",
      "      Training classifier: KNN... done! Train acc: 0.968, Test acc: 0.967\n",
      "    Train fraction: 0.8\n",
      "      Training classifier: LogisticRegression... done! Train acc: 0.964, Test acc: 0.962\n",
      "      Training classifier: RandomForest... done! Train acc: 0.999, Test acc: 0.971\n",
      "      Training classifier: KNN... done! Train acc: 0.969, Test acc: 0.963\n",
      "Processing dataset: gender\n",
      "  Seed: 0\n",
      "    Train fraction: 0.2\n",
      " done! Train acc: 0.610, Test acc: 0.609\n",
      "      Training classifier: RandomForest... done! Train acc: 0.986, Test acc: 0.748\n",
      "      Training classifier: KNN... done! Train acc: 0.710, Test acc: 0.593\n",
      "    Train fraction: 0.5\n",
      " done! Train acc: 0.610, Test acc: 0.609\n",
      "      Training classifier: RandomForest... done! Train acc: 0.954, Test acc: 0.764\n",
      "      Training classifier: KNN... done! Train acc: 0.718, Test acc: 0.604\n",
      "    Train fraction: 0.8\n",
      " done! Train acc: 0.610, Test acc: 0.609\n",
      "      Training classifier: RandomForest... done! Train acc: 0.933, Test acc: 0.770\n",
      "      Training classifier: KNN... done! Train acc: 0.725, Test acc: 0.610\n",
      "  Seed: 42\n",
      "    Train fraction: 0.2\n",
      " done! Train acc: 0.610, Test acc: 0.609\n",
      "      Training classifier: RandomForest... done! Train acc: 0.986, Test acc: 0.749\n",
      "      Training classifier: KNN... done! Train acc: 0.710, Test acc: 0.593\n",
      "    Train fraction: 0.5\n",
      " done! Train acc: 0.610, Test acc: 0.609\n",
      "      Training classifier: RandomForest... done! Train acc: 0.956, Test acc: 0.763\n",
      "      Training classifier: KNN... done! Train acc: 0.719, Test acc: 0.605\n",
      "    Train fraction: 0.8\n",
      " done! Train acc: 0.609, Test acc: 0.610\n",
      "      Training classifier: RandomForest... done! Train acc: 0.933, Test acc: 0.769\n",
      "      Training classifier: KNN... done! Train acc: 0.724, Test acc: 0.613\n",
      "  Seed: 99\n",
      "    Train fraction: 0.2\n",
      " done! Train acc: 0.610, Test acc: 0.609\n",
      "      Training classifier: RandomForest... done! Train acc: 0.987, Test acc: 0.749\n",
      "      Training classifier: KNN... done! Train acc: 0.709, Test acc: 0.592\n",
      "    Train fraction: 0.5\n",
      " done! Train acc: 0.610, Test acc: 0.610\n",
      "      Training classifier: RandomForest... done! Train acc: 0.953, Test acc: 0.763\n",
      "      Training classifier: KNN... done! Train acc: 0.719, Test acc: 0.604\n",
      "    Train fraction: 0.8\n",
      " done! Train acc: 0.609, Test acc: 0.610\n",
      "      Training classifier: RandomForest... done! Train acc: 0.934, Test acc: 0.767\n",
      "      Training classifier: KNN... done! Train acc: 0.723, Test acc: 0.615\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open(\"trained_output.txt\", \"r\") as f:\n",
    "    output_text = f.read()\n",
    "\n",
    "\n",
    "output_lines = output_text.splitlines()\n",
    "\n",
    "remove_keywords = [\n",
    "    \"ConvergenceWarning\",\n",
    "    \"https://\",\n",
    "    \"iteration\",\n",
    "    \"max_iter\",\n",
    "    \"scale the data\",\n",
    "    \"alternative solver options\",\n",
    "    \"_check_optimize_result\",\n",
    "    \"STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\"\n",
    "]\n",
    "\n",
    "clean_lines = [\n",
    "    line for line in output_lines\n",
    "    if not any(keyword in line for keyword in remove_keywords)\n",
    "]\n",
    "\n",
    "clean_lines = [line for line in clean_lines if line.strip() != \"\"]\n",
    "\n",
    "cleaned_output = \"\\n\".join(clean_lines)\n",
    "\n",
    "with open(\"trained_output_cleaned.txt\", \"w\") as f:\n",
    "    f.write(cleaned_output)\n",
    "\n",
    "print(cleaned_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3d457a",
   "metadata": {},
   "source": [
    "# Training with CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fb5a7af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_dataset(dataset_name, partitions, classifiers, cv=3):\n",
    "    \"\"\"\n",
    "    dataset_name: string\n",
    "    partitions: dict of seed -> train fraction -> (X_train, X_test, y_train, y_test)\n",
    "    classifiers: dict of classifier_name -> (model, param_grid)\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    print(f\"Processing dataset: {dataset_name}\")\n",
    "    \n",
    "    for seed, frac_dict in partitions.items():\n",
    "        print(f\"  Seed: {seed}\")\n",
    "        for frac, split in frac_dict.items():\n",
    "            X_train, X_test, y_train, y_test = split\n",
    "            print(f\"    Train fraction: {frac}\")\n",
    "\n",
    "            for clf_name, (model, param_grid) in classifiers.items():\n",
    "                print(f\"      Training classifier: {clf_name}...\", end=\"\", flush=True)\n",
    "                best_model, best_params, val_score = train_classifier(model, param_grid, X_train, y_train, cv=cv)\n",
    "                train_acc, test_acc = evaluate_model(best_model, X_train, y_train, X_test, y_test)\n",
    "                print(f\"done! Train acc: {train_acc:.3f}, Test acc: {test_acc:.3f}\")\n",
    "\n",
    "                results.append({\n",
    "                    \"dataset\": dataset_name,\n",
    "                    \"seed\": seed,\n",
    "                    \"train_frac\": frac,\n",
    "                    \"classifier\": clf_name,\n",
    "                    \"best_params\": best_params,\n",
    "                    \"val_acc\": val_score,\n",
    "                    \"train_acc\": train_acc,\n",
    "                    \"test_acc\": test_acc\n",
    "                })\n",
    "\n",
    "    return pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2b426a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset: mushroom\n",
      "  Seed: 0\n",
      "    Train fraction: 0.2\n",
      "      Training classifier: LogisticRegression..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done! Train acc: 0.940, Test acc: 0.944\n",
      "      Training classifier: RandomForest...done! Train acc: 1.000, Test acc: 0.999\n",
      "      Training classifier: KNN...done! Train acc: 0.996, Test acc: 0.991\n",
      "    Train fraction: 0.5\n",
      "      Training classifier: LogisticRegression...done! Train acc: 0.942, Test acc: 0.944\n",
      "      Training classifier: RandomForest...done! Train acc: 1.000, Test acc: 1.000\n",
      "      Training classifier: KNN...done! Train acc: 0.999, Test acc: 0.997\n",
      "    Train fraction: 0.8\n",
      "      Training classifier: LogisticRegression...done! Train acc: 0.949, Test acc: 0.941\n",
      "      Training classifier: RandomForest...done! Train acc: 1.000, Test acc: 1.000\n",
      "      Training classifier: KNN...done! Train acc: 1.000, Test acc: 0.999\n",
      "  Seed: 42\n",
      "    Train fraction: 0.2\n",
      "      Training classifier: LogisticRegression...done! Train acc: 0.949, Test acc: 0.946\n",
      "      Training classifier: RandomForest...done! Train acc: 1.000, Test acc: 0.999\n",
      "      Training classifier: KNN...done! Train acc: 0.996, Test acc: 0.988\n",
      "    Train fraction: 0.5\n",
      "      Training classifier: LogisticRegression...done! Train acc: 0.947, Test acc: 0.949\n",
      "      Training classifier: RandomForest...done! Train acc: 1.000, Test acc: 1.000\n",
      "      Training classifier: KNN...done! Train acc: 0.999, Test acc: 0.999\n",
      "    Train fraction: 0.8\n",
      "      Training classifier: LogisticRegression...done! Train acc: 0.945, Test acc: 0.952\n",
      "      Training classifier: RandomForest...done! Train acc: 1.000, Test acc: 1.000\n",
      "      Training classifier: KNN...done! Train acc: 1.000, Test acc: 0.999\n",
      "  Seed: 99\n",
      "    Train fraction: 0.2\n",
      "      Training classifier: LogisticRegression...done! Train acc: 0.957, Test acc: 0.945\n",
      "      Training classifier: RandomForest...done! Train acc: 1.000, Test acc: 1.000\n",
      "      Training classifier: KNN...done! Train acc: 0.996, Test acc: 0.991\n",
      "    Train fraction: 0.5\n",
      "      Training classifier: LogisticRegression...done! Train acc: 0.951, Test acc: 0.945\n",
      "      Training classifier: RandomForest...done! Train acc: 1.000, Test acc: 1.000\n",
      "      Training classifier: KNN...done! Train acc: 1.000, Test acc: 0.999\n",
      "    Train fraction: 0.8\n",
      "      Training classifier: LogisticRegression...done! Train acc: 0.950, Test acc: 0.941\n",
      "      Training classifier: RandomForest...done! Train acc: 1.000, Test acc: 1.000\n",
      "      Training classifier: KNN...done! Train acc: 1.000, Test acc: 0.999\n"
     ]
    }
   ],
   "source": [
    "results_mushroom = run_dataset(\n",
    "    dataset_name=\"mushroom\",\n",
    "    partitions=all_partitions[\"mushroom\"],\n",
    "    classifiers=classifiers,\n",
    "    cv=3\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ce7b4885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset: gender\n",
      "  Seed: 0\n",
      "    Train fraction: 0.2\n",
      "      Training classifier: LogisticRegression...done! Train acc: 0.610, Test acc: 0.609\n",
      "      Training classifier: RandomForest...done! Train acc: 0.986, Test acc: 0.747\n",
      "      Training classifier: KNN...done! Train acc: 0.710, Test acc: 0.593\n",
      "    Train fraction: 0.5\n",
      "      Training classifier: LogisticRegression...done! Train acc: 0.610, Test acc: 0.610\n",
      "      Training classifier: RandomForest...done! Train acc: 0.955, Test acc: 0.766\n",
      "      Training classifier: KNN...done! Train acc: 0.718, Test acc: 0.604\n",
      "    Train fraction: 0.8\n",
      "      Training classifier: LogisticRegression...done! Train acc: 0.610, Test acc: 0.609\n",
      "      Training classifier: RandomForest...done! Train acc: 0.935, Test acc: 0.771\n",
      "      Training classifier: KNN...done! Train acc: 0.725, Test acc: 0.610\n",
      "  Seed: 42\n",
      "    Train fraction: 0.2\n",
      "      Training classifier: LogisticRegression...done! Train acc: 0.610, Test acc: 0.609\n",
      "      Training classifier: RandomForest...done! Train acc: 0.986, Test acc: 0.748\n",
      "      Training classifier: KNN...done! Train acc: 0.710, Test acc: 0.593\n",
      "    Train fraction: 0.5\n",
      "      Training classifier: LogisticRegression...done! Train acc: 0.610, Test acc: 0.609\n",
      "      Training classifier: RandomForest...done! Train acc: 0.957, Test acc: 0.762\n",
      "      Training classifier: KNN...done! Train acc: 0.719, Test acc: 0.605\n",
      "    Train fraction: 0.8\n",
      "      Training classifier: LogisticRegression...done! Train acc: 0.609, Test acc: 0.610\n",
      "      Training classifier: RandomForest...done! Train acc: 0.935, Test acc: 0.769\n",
      "      Training classifier: KNN...done! Train acc: 0.724, Test acc: 0.613\n",
      "  Seed: 99\n",
      "    Train fraction: 0.2\n",
      "      Training classifier: LogisticRegression...done! Train acc: 0.609, Test acc: 0.609\n",
      "      Training classifier: RandomForest...done! Train acc: 0.984, Test acc: 0.752\n",
      "      Training classifier: KNN...done! Train acc: 0.709, Test acc: 0.592\n",
      "    Train fraction: 0.5\n",
      "      Training classifier: LogisticRegression...done! Train acc: 0.609, Test acc: 0.609\n",
      "      Training classifier: RandomForest...done! Train acc: 0.955, Test acc: 0.762\n",
      "      Training classifier: KNN...done! Train acc: 0.719, Test acc: 0.604\n",
      "    Train fraction: 0.8\n",
      "      Training classifier: LogisticRegression...done! Train acc: 0.609, Test acc: 0.610\n",
      "      Training classifier: RandomForest...done! Train acc: 0.935, Test acc: 0.767\n",
      "      Training classifier: KNN...done! Train acc: 0.723, Test acc: 0.615\n"
     ]
    }
   ],
   "source": [
    "results_gender = run_dataset(\n",
    "    dataset_name=\"gender\",\n",
    "    partitions=all_partitions[\"gender\"],\n",
    "    classifiers=classifiers,\n",
    "    cv=3\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e6193b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset: bankrupt\n",
      "  Seed: 0\n",
      "    Train fraction: 0.2\n",
      "      Training classifier: LogisticRegression...done! Train acc: 0.963, Test acc: 0.963\n",
      "      Training classifier: RandomForest...done! Train acc: 1.000, Test acc: 0.969\n",
      "      Training classifier: KNN...done! Train acc: 0.970, Test acc: 0.966\n",
      "    Train fraction: 0.5\n",
      "      Training classifier: LogisticRegression...done! Train acc: 0.965, Test acc: 0.965\n",
      "      Training classifier: RandomForest...done! Train acc: 1.000, Test acc: 0.972\n",
      "      Training classifier: KNN...done! Train acc: 0.969, Test acc: 0.967\n",
      "    Train fraction: 0.8\n",
      "      Training classifier: LogisticRegression...done! Train acc: 0.968, Test acc: 0.968\n",
      "      Training classifier: RandomForest...done! Train acc: 1.000, Test acc: 0.969\n",
      "      Training classifier: KNN...done! Train acc: 0.968, Test acc: 0.968\n",
      "  Seed: 42\n",
      "    Train fraction: 0.2\n",
      "      Training classifier: LogisticRegression...done! Train acc: 0.963, Test acc: 0.957\n",
      "      Training classifier: RandomForest...done! Train acc: 0.999, Test acc: 0.968\n",
      "      Training classifier: KNN...done! Train acc: 0.969, Test acc: 0.966\n",
      "    Train fraction: 0.5\n",
      "      Training classifier: LogisticRegression...done! Train acc: 0.964, Test acc: 0.964\n",
      "      Training classifier: RandomForest...done! Train acc: 1.000, Test acc: 0.968\n",
      "      Training classifier: KNN...done! Train acc: 0.968, Test acc: 0.968\n",
      "    Train fraction: 0.8\n",
      "      Training classifier: LogisticRegression...done! Train acc: 0.961, Test acc: 0.960\n",
      "      Training classifier: RandomForest...done! Train acc: 1.000, Test acc: 0.971\n",
      "      Training classifier: KNN...done! Train acc: 0.969, Test acc: 0.968\n",
      "  Seed: 99\n",
      "    Train fraction: 0.2\n",
      "      Training classifier: LogisticRegression...done! Train acc: 0.966, Test acc: 0.963\n",
      "      Training classifier: RandomForest...done! Train acc: 0.999, Test acc: 0.970\n",
      "      Training classifier: KNN...done! Train acc: 0.967, Test acc: 0.966\n",
      "    Train fraction: 0.5\n",
      "      Training classifier: LogisticRegression...done! Train acc: 0.967, Test acc: 0.966\n",
      "      Training classifier: RandomForest...done! Train acc: 0.998, Test acc: 0.972\n",
      "      Training classifier: KNN...done! Train acc: 0.968, Test acc: 0.967\n",
      "    Train fraction: 0.8\n",
      "      Training classifier: LogisticRegression...done! Train acc: 0.964, Test acc: 0.962\n",
      "      Training classifier: RandomForest...done! Train acc: 1.000, Test acc: 0.972\n",
      "      Training classifier: KNN...done! Train acc: 0.969, Test acc: 0.963\n"
     ]
    }
   ],
   "source": [
    "results_bankrupts = run_dataset(\n",
    "    dataset_name=\"bankrupt\",\n",
    "    partitions=all_partitions[\"bankrupt\"],\n",
    "    classifiers=classifiers,\n",
    "    cv=3\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9e6a75aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>seed</th>\n",
       "      <th>train_frac</th>\n",
       "      <th>classifier</th>\n",
       "      <th>best_params</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>test_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mushroom</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'C': 1}</td>\n",
       "      <td>0.935961</td>\n",
       "      <td>0.940271</td>\n",
       "      <td>0.943692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mushroom</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 50}</td>\n",
       "      <td>0.998152</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mushroom</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>KNN</td>\n",
       "      <td>{'n_neighbors': 3}</td>\n",
       "      <td>0.976605</td>\n",
       "      <td>0.996305</td>\n",
       "      <td>0.991077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mushroom</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'C': 1}</td>\n",
       "      <td>0.939193</td>\n",
       "      <td>0.941901</td>\n",
       "      <td>0.944116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mushroom</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 100}</td>\n",
       "      <td>0.999508</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mushroom</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>KNN</td>\n",
       "      <td>{'n_neighbors': 3}</td>\n",
       "      <td>0.995569</td>\n",
       "      <td>0.998769</td>\n",
       "      <td>0.997046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mushroom</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'C': 1}</td>\n",
       "      <td>0.948146</td>\n",
       "      <td>0.948607</td>\n",
       "      <td>0.940923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mushroom</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 50}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>mushroom</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>KNN</td>\n",
       "      <td>{'n_neighbors': 3}</td>\n",
       "      <td>0.998307</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>mushroom</td>\n",
       "      <td>42</td>\n",
       "      <td>0.2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'C': 10}</td>\n",
       "      <td>0.944582</td>\n",
       "      <td>0.948892</td>\n",
       "      <td>0.945846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>mushroom</td>\n",
       "      <td>42</td>\n",
       "      <td>0.2</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 50}</td>\n",
       "      <td>0.999384</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>mushroom</td>\n",
       "      <td>42</td>\n",
       "      <td>0.2</td>\n",
       "      <td>KNN</td>\n",
       "      <td>{'n_neighbors': 3}</td>\n",
       "      <td>0.983373</td>\n",
       "      <td>0.996305</td>\n",
       "      <td>0.988308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>mushroom</td>\n",
       "      <td>42</td>\n",
       "      <td>0.5</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'C': 1}</td>\n",
       "      <td>0.945347</td>\n",
       "      <td>0.947070</td>\n",
       "      <td>0.948794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>mushroom</td>\n",
       "      <td>42</td>\n",
       "      <td>0.5</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 50}</td>\n",
       "      <td>0.999261</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>mushroom</td>\n",
       "      <td>42</td>\n",
       "      <td>0.5</td>\n",
       "      <td>KNN</td>\n",
       "      <td>{'n_neighbors': 3}</td>\n",
       "      <td>0.994830</td>\n",
       "      <td>0.999015</td>\n",
       "      <td>0.998769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>mushroom</td>\n",
       "      <td>42</td>\n",
       "      <td>0.8</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'C': 10}</td>\n",
       "      <td>0.943068</td>\n",
       "      <td>0.945068</td>\n",
       "      <td>0.952000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>mushroom</td>\n",
       "      <td>42</td>\n",
       "      <td>0.8</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 50}</td>\n",
       "      <td>0.999231</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>mushroom</td>\n",
       "      <td>42</td>\n",
       "      <td>0.8</td>\n",
       "      <td>KNN</td>\n",
       "      <td>{'n_neighbors': 3}</td>\n",
       "      <td>0.996769</td>\n",
       "      <td>0.999692</td>\n",
       "      <td>0.998769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>mushroom</td>\n",
       "      <td>99</td>\n",
       "      <td>0.2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'C': 10}</td>\n",
       "      <td>0.955668</td>\n",
       "      <td>0.956897</td>\n",
       "      <td>0.944615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>mushroom</td>\n",
       "      <td>99</td>\n",
       "      <td>0.2</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 50}</td>\n",
       "      <td>0.998768</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>mushroom</td>\n",
       "      <td>99</td>\n",
       "      <td>0.2</td>\n",
       "      <td>KNN</td>\n",
       "      <td>{'n_neighbors': 3}</td>\n",
       "      <td>0.980906</td>\n",
       "      <td>0.996305</td>\n",
       "      <td>0.990769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>mushroom</td>\n",
       "      <td>99</td>\n",
       "      <td>0.5</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'C': 1}</td>\n",
       "      <td>0.947317</td>\n",
       "      <td>0.951009</td>\n",
       "      <td>0.945347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>mushroom</td>\n",
       "      <td>99</td>\n",
       "      <td>0.5</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 50}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>mushroom</td>\n",
       "      <td>99</td>\n",
       "      <td>0.5</td>\n",
       "      <td>KNN</td>\n",
       "      <td>{'n_neighbors': 3}</td>\n",
       "      <td>0.996553</td>\n",
       "      <td>0.999754</td>\n",
       "      <td>0.998769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>mushroom</td>\n",
       "      <td>99</td>\n",
       "      <td>0.8</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'C': 1}</td>\n",
       "      <td>0.948455</td>\n",
       "      <td>0.949838</td>\n",
       "      <td>0.940923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>mushroom</td>\n",
       "      <td>99</td>\n",
       "      <td>0.8</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 50}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>mushroom</td>\n",
       "      <td>99</td>\n",
       "      <td>0.8</td>\n",
       "      <td>KNN</td>\n",
       "      <td>{'n_neighbors': 3}</td>\n",
       "      <td>0.997692</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     dataset  seed  train_frac          classifier  \\\n",
       "0   mushroom     0         0.2  LogisticRegression   \n",
       "1   mushroom     0         0.2        RandomForest   \n",
       "2   mushroom     0         0.2                 KNN   \n",
       "3   mushroom     0         0.5  LogisticRegression   \n",
       "4   mushroom     0         0.5        RandomForest   \n",
       "5   mushroom     0         0.5                 KNN   \n",
       "6   mushroom     0         0.8  LogisticRegression   \n",
       "7   mushroom     0         0.8        RandomForest   \n",
       "8   mushroom     0         0.8                 KNN   \n",
       "9   mushroom    42         0.2  LogisticRegression   \n",
       "10  mushroom    42         0.2        RandomForest   \n",
       "11  mushroom    42         0.2                 KNN   \n",
       "12  mushroom    42         0.5  LogisticRegression   \n",
       "13  mushroom    42         0.5        RandomForest   \n",
       "14  mushroom    42         0.5                 KNN   \n",
       "15  mushroom    42         0.8  LogisticRegression   \n",
       "16  mushroom    42         0.8        RandomForest   \n",
       "17  mushroom    42         0.8                 KNN   \n",
       "18  mushroom    99         0.2  LogisticRegression   \n",
       "19  mushroom    99         0.2        RandomForest   \n",
       "20  mushroom    99         0.2                 KNN   \n",
       "21  mushroom    99         0.5  LogisticRegression   \n",
       "22  mushroom    99         0.5        RandomForest   \n",
       "23  mushroom    99         0.5                 KNN   \n",
       "24  mushroom    99         0.8  LogisticRegression   \n",
       "25  mushroom    99         0.8        RandomForest   \n",
       "26  mushroom    99         0.8                 KNN   \n",
       "\n",
       "                                 best_params   val_acc  train_acc  test_acc  \n",
       "0                                   {'C': 1}  0.935961   0.940271  0.943692  \n",
       "1    {'max_depth': None, 'n_estimators': 50}  0.998152   1.000000  0.998769  \n",
       "2                         {'n_neighbors': 3}  0.976605   0.996305  0.991077  \n",
       "3                                   {'C': 1}  0.939193   0.941901  0.944116  \n",
       "4   {'max_depth': None, 'n_estimators': 100}  0.999508   1.000000  1.000000  \n",
       "5                         {'n_neighbors': 3}  0.995569   0.998769  0.997046  \n",
       "6                                   {'C': 1}  0.948146   0.948607  0.940923  \n",
       "7    {'max_depth': None, 'n_estimators': 50}  1.000000   1.000000  1.000000  \n",
       "8                         {'n_neighbors': 3}  0.998307   1.000000  0.999385  \n",
       "9                                  {'C': 10}  0.944582   0.948892  0.945846  \n",
       "10   {'max_depth': None, 'n_estimators': 50}  0.999384   1.000000  0.998769  \n",
       "11                        {'n_neighbors': 3}  0.983373   0.996305  0.988308  \n",
       "12                                  {'C': 1}  0.945347   0.947070  0.948794  \n",
       "13   {'max_depth': None, 'n_estimators': 50}  0.999261   1.000000  1.000000  \n",
       "14                        {'n_neighbors': 3}  0.994830   0.999015  0.998769  \n",
       "15                                 {'C': 10}  0.943068   0.945068  0.952000  \n",
       "16   {'max_depth': None, 'n_estimators': 50}  0.999231   1.000000  1.000000  \n",
       "17                        {'n_neighbors': 3}  0.996769   0.999692  0.998769  \n",
       "18                                 {'C': 10}  0.955668   0.956897  0.944615  \n",
       "19   {'max_depth': None, 'n_estimators': 50}  0.998768   1.000000  1.000000  \n",
       "20                        {'n_neighbors': 3}  0.980906   0.996305  0.990769  \n",
       "21                                  {'C': 1}  0.947317   0.951009  0.945347  \n",
       "22   {'max_depth': None, 'n_estimators': 50}  1.000000   1.000000  1.000000  \n",
       "23                        {'n_neighbors': 3}  0.996553   0.999754  0.998769  \n",
       "24                                  {'C': 1}  0.948455   0.949838  0.940923  \n",
       "25   {'max_depth': None, 'n_estimators': 50}  1.000000   1.000000  1.000000  \n",
       "26                        {'n_neighbors': 3}  0.997692   1.000000  0.999385  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_mushroom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "18ce462a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>seed</th>\n",
       "      <th>train_frac</th>\n",
       "      <th>classifier</th>\n",
       "      <th>best_params</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>test_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gender</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'C': 0.01}</td>\n",
       "      <td>0.609785</td>\n",
       "      <td>0.609717</td>\n",
       "      <td>0.609493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gender</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>{'max_depth': 20, 'n_estimators': 100}</td>\n",
       "      <td>0.740434</td>\n",
       "      <td>0.986453</td>\n",
       "      <td>0.747428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gender</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>KNN</td>\n",
       "      <td>{'n_neighbors': 7}</td>\n",
       "      <td>0.583981</td>\n",
       "      <td>0.709503</td>\n",
       "      <td>0.592831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gender</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'C': 0.1}</td>\n",
       "      <td>0.609664</td>\n",
       "      <td>0.609623</td>\n",
       "      <td>0.609534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gender</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>{'max_depth': 20, 'n_estimators': 100}</td>\n",
       "      <td>0.757476</td>\n",
       "      <td>0.955238</td>\n",
       "      <td>0.765587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gender</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>KNN</td>\n",
       "      <td>{'n_neighbors': 7}</td>\n",
       "      <td>0.604639</td>\n",
       "      <td>0.718119</td>\n",
       "      <td>0.604101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gender</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'C': 10}</td>\n",
       "      <td>0.609549</td>\n",
       "      <td>0.609515</td>\n",
       "      <td>0.609493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gender</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>{'max_depth': 20, 'n_estimators': 100}</td>\n",
       "      <td>0.765140</td>\n",
       "      <td>0.935416</td>\n",
       "      <td>0.770625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gender</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>KNN</td>\n",
       "      <td>{'n_neighbors': 7}</td>\n",
       "      <td>0.605008</td>\n",
       "      <td>0.724959</td>\n",
       "      <td>0.609595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>gender</td>\n",
       "      <td>42</td>\n",
       "      <td>0.2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'C': 1}</td>\n",
       "      <td>0.610294</td>\n",
       "      <td>0.609955</td>\n",
       "      <td>0.609153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>gender</td>\n",
       "      <td>42</td>\n",
       "      <td>0.2</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>{'max_depth': 20, 'n_estimators': 100}</td>\n",
       "      <td>0.740977</td>\n",
       "      <td>0.985740</td>\n",
       "      <td>0.748201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gender</td>\n",
       "      <td>42</td>\n",
       "      <td>0.2</td>\n",
       "      <td>KNN</td>\n",
       "      <td>{'n_neighbors': 7}</td>\n",
       "      <td>0.591722</td>\n",
       "      <td>0.710284</td>\n",
       "      <td>0.592857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>gender</td>\n",
       "      <td>42</td>\n",
       "      <td>0.5</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'C': 10}</td>\n",
       "      <td>0.609501</td>\n",
       "      <td>0.609528</td>\n",
       "      <td>0.609384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>gender</td>\n",
       "      <td>42</td>\n",
       "      <td>0.5</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>{'max_depth': 20, 'n_estimators': 100}</td>\n",
       "      <td>0.756526</td>\n",
       "      <td>0.957465</td>\n",
       "      <td>0.762246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>gender</td>\n",
       "      <td>42</td>\n",
       "      <td>0.5</td>\n",
       "      <td>KNN</td>\n",
       "      <td>{'n_neighbors': 7}</td>\n",
       "      <td>0.600796</td>\n",
       "      <td>0.719287</td>\n",
       "      <td>0.604536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>gender</td>\n",
       "      <td>42</td>\n",
       "      <td>0.8</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'C': 10}</td>\n",
       "      <td>0.609396</td>\n",
       "      <td>0.609388</td>\n",
       "      <td>0.609527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>gender</td>\n",
       "      <td>42</td>\n",
       "      <td>0.8</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>{'max_depth': 20, 'n_estimators': 100}</td>\n",
       "      <td>0.764741</td>\n",
       "      <td>0.935127</td>\n",
       "      <td>0.769437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>gender</td>\n",
       "      <td>42</td>\n",
       "      <td>0.8</td>\n",
       "      <td>KNN</td>\n",
       "      <td>{'n_neighbors': 7}</td>\n",
       "      <td>0.605806</td>\n",
       "      <td>0.723864</td>\n",
       "      <td>0.613261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>gender</td>\n",
       "      <td>99</td>\n",
       "      <td>0.2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'C': 1}</td>\n",
       "      <td>0.609378</td>\n",
       "      <td>0.609446</td>\n",
       "      <td>0.609399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>gender</td>\n",
       "      <td>99</td>\n",
       "      <td>0.2</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>{'max_depth': 20, 'n_estimators': 100}</td>\n",
       "      <td>0.739721</td>\n",
       "      <td>0.984144</td>\n",
       "      <td>0.751502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>gender</td>\n",
       "      <td>99</td>\n",
       "      <td>0.2</td>\n",
       "      <td>KNN</td>\n",
       "      <td>{'n_neighbors': 7}</td>\n",
       "      <td>0.591010</td>\n",
       "      <td>0.708926</td>\n",
       "      <td>0.592373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>gender</td>\n",
       "      <td>99</td>\n",
       "      <td>0.5</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'C': 0.01}</td>\n",
       "      <td>0.609515</td>\n",
       "      <td>0.609447</td>\n",
       "      <td>0.609466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>gender</td>\n",
       "      <td>99</td>\n",
       "      <td>0.5</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>{'max_depth': 20, 'n_estimators': 100}</td>\n",
       "      <td>0.759445</td>\n",
       "      <td>0.954532</td>\n",
       "      <td>0.761839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>gender</td>\n",
       "      <td>99</td>\n",
       "      <td>0.5</td>\n",
       "      <td>KNN</td>\n",
       "      <td>{'n_neighbors': 7}</td>\n",
       "      <td>0.597115</td>\n",
       "      <td>0.719206</td>\n",
       "      <td>0.603558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>gender</td>\n",
       "      <td>99</td>\n",
       "      <td>0.8</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'C': 1}</td>\n",
       "      <td>0.609396</td>\n",
       "      <td>0.609447</td>\n",
       "      <td>0.609866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>gender</td>\n",
       "      <td>99</td>\n",
       "      <td>0.8</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>{'max_depth': 20, 'n_estimators': 100}</td>\n",
       "      <td>0.765446</td>\n",
       "      <td>0.934779</td>\n",
       "      <td>0.766959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>gender</td>\n",
       "      <td>99</td>\n",
       "      <td>0.8</td>\n",
       "      <td>KNN</td>\n",
       "      <td>{'n_neighbors': 7}</td>\n",
       "      <td>0.605644</td>\n",
       "      <td>0.722743</td>\n",
       "      <td>0.615095</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset  seed  train_frac          classifier  \\\n",
       "0   gender     0         0.2  LogisticRegression   \n",
       "1   gender     0         0.2        RandomForest   \n",
       "2   gender     0         0.2                 KNN   \n",
       "3   gender     0         0.5  LogisticRegression   \n",
       "4   gender     0         0.5        RandomForest   \n",
       "5   gender     0         0.5                 KNN   \n",
       "6   gender     0         0.8  LogisticRegression   \n",
       "7   gender     0         0.8        RandomForest   \n",
       "8   gender     0         0.8                 KNN   \n",
       "9   gender    42         0.2  LogisticRegression   \n",
       "10  gender    42         0.2        RandomForest   \n",
       "11  gender    42         0.2                 KNN   \n",
       "12  gender    42         0.5  LogisticRegression   \n",
       "13  gender    42         0.5        RandomForest   \n",
       "14  gender    42         0.5                 KNN   \n",
       "15  gender    42         0.8  LogisticRegression   \n",
       "16  gender    42         0.8        RandomForest   \n",
       "17  gender    42         0.8                 KNN   \n",
       "18  gender    99         0.2  LogisticRegression   \n",
       "19  gender    99         0.2        RandomForest   \n",
       "20  gender    99         0.2                 KNN   \n",
       "21  gender    99         0.5  LogisticRegression   \n",
       "22  gender    99         0.5        RandomForest   \n",
       "23  gender    99         0.5                 KNN   \n",
       "24  gender    99         0.8  LogisticRegression   \n",
       "25  gender    99         0.8        RandomForest   \n",
       "26  gender    99         0.8                 KNN   \n",
       "\n",
       "                               best_params   val_acc  train_acc  test_acc  \n",
       "0                              {'C': 0.01}  0.609785   0.609717  0.609493  \n",
       "1   {'max_depth': 20, 'n_estimators': 100}  0.740434   0.986453  0.747428  \n",
       "2                       {'n_neighbors': 7}  0.583981   0.709503  0.592831  \n",
       "3                               {'C': 0.1}  0.609664   0.609623  0.609534  \n",
       "4   {'max_depth': 20, 'n_estimators': 100}  0.757476   0.955238  0.765587  \n",
       "5                       {'n_neighbors': 7}  0.604639   0.718119  0.604101  \n",
       "6                                {'C': 10}  0.609549   0.609515  0.609493  \n",
       "7   {'max_depth': 20, 'n_estimators': 100}  0.765140   0.935416  0.770625  \n",
       "8                       {'n_neighbors': 7}  0.605008   0.724959  0.609595  \n",
       "9                                 {'C': 1}  0.610294   0.609955  0.609153  \n",
       "10  {'max_depth': 20, 'n_estimators': 100}  0.740977   0.985740  0.748201  \n",
       "11                      {'n_neighbors': 7}  0.591722   0.710284  0.592857  \n",
       "12                               {'C': 10}  0.609501   0.609528  0.609384  \n",
       "13  {'max_depth': 20, 'n_estimators': 100}  0.756526   0.957465  0.762246  \n",
       "14                      {'n_neighbors': 7}  0.600796   0.719287  0.604536  \n",
       "15                               {'C': 10}  0.609396   0.609388  0.609527  \n",
       "16  {'max_depth': 20, 'n_estimators': 100}  0.764741   0.935127  0.769437  \n",
       "17                      {'n_neighbors': 7}  0.605806   0.723864  0.613261  \n",
       "18                                {'C': 1}  0.609378   0.609446  0.609399  \n",
       "19  {'max_depth': 20, 'n_estimators': 100}  0.739721   0.984144  0.751502  \n",
       "20                      {'n_neighbors': 7}  0.591010   0.708926  0.592373  \n",
       "21                             {'C': 0.01}  0.609515   0.609447  0.609466  \n",
       "22  {'max_depth': 20, 'n_estimators': 100}  0.759445   0.954532  0.761839  \n",
       "23                      {'n_neighbors': 7}  0.597115   0.719206  0.603558  \n",
       "24                                {'C': 1}  0.609396   0.609447  0.609866  \n",
       "25  {'max_depth': 20, 'n_estimators': 100}  0.765446   0.934779  0.766959  \n",
       "26                      {'n_neighbors': 7}  0.605644   0.722743  0.615095  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c45e8bcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>seed</th>\n",
       "      <th>train_frac</th>\n",
       "      <th>classifier</th>\n",
       "      <th>best_params</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>test_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bankrupt</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'C': 0.01}</td>\n",
       "      <td>0.955237</td>\n",
       "      <td>0.962583</td>\n",
       "      <td>0.962977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bankrupt</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 100}</td>\n",
       "      <td>0.972852</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.968842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bankrupt</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>KNN</td>\n",
       "      <td>{'n_neighbors': 3}</td>\n",
       "      <td>0.967722</td>\n",
       "      <td>0.969919</td>\n",
       "      <td>0.966092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bankrupt</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'C': 0.01}</td>\n",
       "      <td>0.963333</td>\n",
       "      <td>0.965092</td>\n",
       "      <td>0.964516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bankrupt</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 100}</td>\n",
       "      <td>0.970078</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.971848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bankrupt</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>KNN</td>\n",
       "      <td>{'n_neighbors': 7}</td>\n",
       "      <td>0.968026</td>\n",
       "      <td>0.968612</td>\n",
       "      <td>0.967449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bankrupt</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'C': 0.01}</td>\n",
       "      <td>0.963703</td>\n",
       "      <td>0.967919</td>\n",
       "      <td>0.967742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bankrupt</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>{'max_depth': 20, 'n_estimators': 50}</td>\n",
       "      <td>0.970670</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.969208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bankrupt</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>KNN</td>\n",
       "      <td>{'n_neighbors': 7}</td>\n",
       "      <td>0.967553</td>\n",
       "      <td>0.968103</td>\n",
       "      <td>0.968475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bankrupt</td>\n",
       "      <td>42</td>\n",
       "      <td>0.2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'C': 0.01}</td>\n",
       "      <td>0.957446</td>\n",
       "      <td>0.963316</td>\n",
       "      <td>0.956745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>bankrupt</td>\n",
       "      <td>42</td>\n",
       "      <td>0.2</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 50}</td>\n",
       "      <td>0.965516</td>\n",
       "      <td>0.999266</td>\n",
       "      <td>0.968292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>bankrupt</td>\n",
       "      <td>42</td>\n",
       "      <td>0.2</td>\n",
       "      <td>KNN</td>\n",
       "      <td>{'n_neighbors': 5}</td>\n",
       "      <td>0.967719</td>\n",
       "      <td>0.969186</td>\n",
       "      <td>0.966459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>bankrupt</td>\n",
       "      <td>42</td>\n",
       "      <td>0.5</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'C': 0.01}</td>\n",
       "      <td>0.963038</td>\n",
       "      <td>0.964212</td>\n",
       "      <td>0.963636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>bankrupt</td>\n",
       "      <td>42</td>\n",
       "      <td>0.5</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 100}</td>\n",
       "      <td>0.970666</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.967742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>bankrupt</td>\n",
       "      <td>42</td>\n",
       "      <td>0.5</td>\n",
       "      <td>KNN</td>\n",
       "      <td>{'n_neighbors': 7}</td>\n",
       "      <td>0.967733</td>\n",
       "      <td>0.968026</td>\n",
       "      <td>0.967742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>bankrupt</td>\n",
       "      <td>42</td>\n",
       "      <td>0.8</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'C': 0.01}</td>\n",
       "      <td>0.960587</td>\n",
       "      <td>0.961137</td>\n",
       "      <td>0.959677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>bankrupt</td>\n",
       "      <td>42</td>\n",
       "      <td>0.8</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>{'max_depth': 20, 'n_estimators': 100}</td>\n",
       "      <td>0.969386</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.970674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>bankrupt</td>\n",
       "      <td>42</td>\n",
       "      <td>0.8</td>\n",
       "      <td>KNN</td>\n",
       "      <td>{'n_neighbors': 7}</td>\n",
       "      <td>0.967736</td>\n",
       "      <td>0.969019</td>\n",
       "      <td>0.967742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>bankrupt</td>\n",
       "      <td>99</td>\n",
       "      <td>0.2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'C': 0.01}</td>\n",
       "      <td>0.961114</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.963343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>bankrupt</td>\n",
       "      <td>99</td>\n",
       "      <td>0.2</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 50}</td>\n",
       "      <td>0.969186</td>\n",
       "      <td>0.999266</td>\n",
       "      <td>0.969575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>bankrupt</td>\n",
       "      <td>99</td>\n",
       "      <td>0.2</td>\n",
       "      <td>KNN</td>\n",
       "      <td>{'n_neighbors': 5}</td>\n",
       "      <td>0.967719</td>\n",
       "      <td>0.966985</td>\n",
       "      <td>0.966459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>bankrupt</td>\n",
       "      <td>99</td>\n",
       "      <td>0.5</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'C': 0.01}</td>\n",
       "      <td>0.964798</td>\n",
       "      <td>0.967439</td>\n",
       "      <td>0.965689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>bankrupt</td>\n",
       "      <td>99</td>\n",
       "      <td>0.5</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 50}</td>\n",
       "      <td>0.968612</td>\n",
       "      <td>0.997653</td>\n",
       "      <td>0.971848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>bankrupt</td>\n",
       "      <td>99</td>\n",
       "      <td>0.5</td>\n",
       "      <td>KNN</td>\n",
       "      <td>{'n_neighbors': 7}</td>\n",
       "      <td>0.967733</td>\n",
       "      <td>0.968026</td>\n",
       "      <td>0.966862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>bankrupt</td>\n",
       "      <td>99</td>\n",
       "      <td>0.8</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'C': 0.01}</td>\n",
       "      <td>0.964803</td>\n",
       "      <td>0.963520</td>\n",
       "      <td>0.961877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>bankrupt</td>\n",
       "      <td>99</td>\n",
       "      <td>0.8</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 50}</td>\n",
       "      <td>0.968836</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.972141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>bankrupt</td>\n",
       "      <td>99</td>\n",
       "      <td>0.8</td>\n",
       "      <td>KNN</td>\n",
       "      <td>{'n_neighbors': 5}</td>\n",
       "      <td>0.967919</td>\n",
       "      <td>0.968836</td>\n",
       "      <td>0.962610</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     dataset  seed  train_frac          classifier  \\\n",
       "0   bankrupt     0         0.2  LogisticRegression   \n",
       "1   bankrupt     0         0.2        RandomForest   \n",
       "2   bankrupt     0         0.2                 KNN   \n",
       "3   bankrupt     0         0.5  LogisticRegression   \n",
       "4   bankrupt     0         0.5        RandomForest   \n",
       "5   bankrupt     0         0.5                 KNN   \n",
       "6   bankrupt     0         0.8  LogisticRegression   \n",
       "7   bankrupt     0         0.8        RandomForest   \n",
       "8   bankrupt     0         0.8                 KNN   \n",
       "9   bankrupt    42         0.2  LogisticRegression   \n",
       "10  bankrupt    42         0.2        RandomForest   \n",
       "11  bankrupt    42         0.2                 KNN   \n",
       "12  bankrupt    42         0.5  LogisticRegression   \n",
       "13  bankrupt    42         0.5        RandomForest   \n",
       "14  bankrupt    42         0.5                 KNN   \n",
       "15  bankrupt    42         0.8  LogisticRegression   \n",
       "16  bankrupt    42         0.8        RandomForest   \n",
       "17  bankrupt    42         0.8                 KNN   \n",
       "18  bankrupt    99         0.2  LogisticRegression   \n",
       "19  bankrupt    99         0.2        RandomForest   \n",
       "20  bankrupt    99         0.2                 KNN   \n",
       "21  bankrupt    99         0.5  LogisticRegression   \n",
       "22  bankrupt    99         0.5        RandomForest   \n",
       "23  bankrupt    99         0.5                 KNN   \n",
       "24  bankrupt    99         0.8  LogisticRegression   \n",
       "25  bankrupt    99         0.8        RandomForest   \n",
       "26  bankrupt    99         0.8                 KNN   \n",
       "\n",
       "                                 best_params   val_acc  train_acc  test_acc  \n",
       "0                                {'C': 0.01}  0.955237   0.962583  0.962977  \n",
       "1     {'max_depth': 10, 'n_estimators': 100}  0.972852   1.000000  0.968842  \n",
       "2                         {'n_neighbors': 3}  0.967722   0.969919  0.966092  \n",
       "3                                {'C': 0.01}  0.963333   0.965092  0.964516  \n",
       "4   {'max_depth': None, 'n_estimators': 100}  0.970078   1.000000  0.971848  \n",
       "5                         {'n_neighbors': 7}  0.968026   0.968612  0.967449  \n",
       "6                                {'C': 0.01}  0.963703   0.967919  0.967742  \n",
       "7      {'max_depth': 20, 'n_estimators': 50}  0.970670   1.000000  0.969208  \n",
       "8                         {'n_neighbors': 7}  0.967553   0.968103  0.968475  \n",
       "9                                {'C': 0.01}  0.957446   0.963316  0.956745  \n",
       "10     {'max_depth': 10, 'n_estimators': 50}  0.965516   0.999266  0.968292  \n",
       "11                        {'n_neighbors': 5}  0.967719   0.969186  0.966459  \n",
       "12                               {'C': 0.01}  0.963038   0.964212  0.963636  \n",
       "13  {'max_depth': None, 'n_estimators': 100}  0.970666   1.000000  0.967742  \n",
       "14                        {'n_neighbors': 7}  0.967733   0.968026  0.967742  \n",
       "15                               {'C': 0.01}  0.960587   0.961137  0.959677  \n",
       "16    {'max_depth': 20, 'n_estimators': 100}  0.969386   1.000000  0.970674  \n",
       "17                        {'n_neighbors': 7}  0.967736   0.969019  0.967742  \n",
       "18                               {'C': 0.01}  0.961114   0.965517  0.963343  \n",
       "19     {'max_depth': 10, 'n_estimators': 50}  0.969186   0.999266  0.969575  \n",
       "20                        {'n_neighbors': 5}  0.967719   0.966985  0.966459  \n",
       "21                               {'C': 0.01}  0.964798   0.967439  0.965689  \n",
       "22     {'max_depth': 10, 'n_estimators': 50}  0.968612   0.997653  0.971848  \n",
       "23                        {'n_neighbors': 7}  0.967733   0.968026  0.966862  \n",
       "24                               {'C': 0.01}  0.964803   0.963520  0.961877  \n",
       "25   {'max_depth': None, 'n_estimators': 50}  0.968836   1.000000  0.972141  \n",
       "26                        {'n_neighbors': 5}  0.967919   0.968836  0.962610  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_bankrupts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c0d61a",
   "metadata": {},
   "source": [
    "Concatinate all results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "98d2a6c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>seed</th>\n",
       "      <th>train_frac</th>\n",
       "      <th>classifier</th>\n",
       "      <th>best_params</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>test_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mushroom</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'C': 1}</td>\n",
       "      <td>0.935961</td>\n",
       "      <td>0.940271</td>\n",
       "      <td>0.943692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mushroom</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 50}</td>\n",
       "      <td>0.998152</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mushroom</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>KNN</td>\n",
       "      <td>{'n_neighbors': 3}</td>\n",
       "      <td>0.976605</td>\n",
       "      <td>0.996305</td>\n",
       "      <td>0.991077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mushroom</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'C': 1}</td>\n",
       "      <td>0.939193</td>\n",
       "      <td>0.941901</td>\n",
       "      <td>0.944116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mushroom</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 100}</td>\n",
       "      <td>0.999508</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    dataset  seed  train_frac          classifier  \\\n",
       "0  mushroom     0         0.2  LogisticRegression   \n",
       "1  mushroom     0         0.2        RandomForest   \n",
       "2  mushroom     0         0.2                 KNN   \n",
       "3  mushroom     0         0.5  LogisticRegression   \n",
       "4  mushroom     0         0.5        RandomForest   \n",
       "\n",
       "                                best_params   val_acc  train_acc  test_acc  \n",
       "0                                  {'C': 1}  0.935961   0.940271  0.943692  \n",
       "1   {'max_depth': None, 'n_estimators': 50}  0.998152   1.000000  0.998769  \n",
       "2                        {'n_neighbors': 3}  0.976605   0.996305  0.991077  \n",
       "3                                  {'C': 1}  0.939193   0.941901  0.944116  \n",
       "4  {'max_depth': None, 'n_estimators': 100}  0.999508   1.000000  1.000000  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results = pd.concat([results_mushroom, results_gender, results_bankrupts], ignore_index=True)\n",
    "all_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e21a102",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <th colspan=\"3\" halign=\"left\">bankrupt</th>\n",
       "      <th colspan=\"3\" halign=\"left\">gender</th>\n",
       "      <th colspan=\"3\" halign=\"left\">mushroom</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_frac</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.8</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.8</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.8</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>classifier</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.966</td>\n",
       "      <td>0.967</td>\n",
       "      <td>0.966</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.613</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.998</td>\n",
       "      <td>0.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.961</td>\n",
       "      <td>0.965</td>\n",
       "      <td>0.963</td>\n",
       "      <td>0.609</td>\n",
       "      <td>0.609</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.945</td>\n",
       "      <td>0.946</td>\n",
       "      <td>0.945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>0.969</td>\n",
       "      <td>0.970</td>\n",
       "      <td>0.971</td>\n",
       "      <td>0.749</td>\n",
       "      <td>0.763</td>\n",
       "      <td>0.769</td>\n",
       "      <td>0.999</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "dataset            bankrupt               gender               mushroom  \\\n",
       "train_frac              0.2    0.5    0.8    0.2    0.5    0.8      0.2   \n",
       "classifier                                                                \n",
       "KNN                   0.966  0.967  0.966  0.593  0.604  0.613    0.990   \n",
       "LogisticRegression    0.961  0.965  0.963  0.609  0.609  0.610    0.945   \n",
       "RandomForest          0.969  0.970  0.971  0.749  0.763  0.769    0.999   \n",
       "\n",
       "dataset                           \n",
       "train_frac            0.5    0.8  \n",
       "classifier                        \n",
       "KNN                 0.998  0.999  \n",
       "LogisticRegression  0.946  0.945  \n",
       "RandomForest        1.000  1.000  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_results_1 = (\n",
    "    all_results\n",
    "    .groupby([\"train_frac\", \"dataset\", \"classifier\"])\n",
    "    .agg(test_acc_mean=(\"test_acc\", \"mean\"))\n",
    "    .reset_index()\n",
    ")\n",
    "table_acc_1 = agg_results_1.pivot_table(\n",
    "    index=\"classifier\",\n",
    "    columns=[\"dataset\", \"train_frac\"],\n",
    "    values=\"test_acc_mean\"\n",
    ")\n",
    "table_acc_1 = table_acc_1.sort_index(axis=1, level=[0,1])\n",
    "table_acc_1 = table_acc_1.round(3)\n",
    "table_acc_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad7b16c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Train fraction: 0.2 ===\n",
      "dataset             bankrupt  gender  mushroom\n",
      "classifier                                    \n",
      "KNN                    0.966   0.593     0.990\n",
      "LogisticRegression     0.961   0.609     0.945\n",
      "RandomForest           0.969   0.749     0.999\n",
      "\n",
      "=== Train fraction: 0.5 ===\n",
      "dataset             bankrupt  gender  mushroom\n",
      "classifier                                    \n",
      "KNN                    0.967   0.604     0.998\n",
      "LogisticRegression     0.965   0.609     0.946\n",
      "RandomForest           0.970   0.763     1.000\n",
      "\n",
      "=== Train fraction: 0.8 ===\n",
      "dataset             bankrupt  gender  mushroom\n",
      "classifier                                    \n",
      "KNN                    0.966   0.613     0.999\n",
      "LogisticRegression     0.963   0.610     0.945\n",
      "RandomForest           0.971   0.769     1.000\n"
     ]
    }
   ],
   "source": [
    "train_fracs = sorted(all_results['train_frac'].unique())\n",
    "\n",
    "for frac in train_fracs:\n",
    "    df_frac = all_results[all_results['train_frac'] == frac]\n",
    "    agg_results = (\n",
    "        df_frac\n",
    "        .groupby([\"dataset\", \"classifier\"])\n",
    "        .agg(test_acc_mean=(\"test_acc\", \"mean\"))\n",
    "        .reset_index()\n",
    "    )\n",
    "    table_acc = agg_results.pivot_table(\n",
    "        index=\"classifier\",\n",
    "        columns=\"dataset\",\n",
    "        values=\"test_acc_mean\"\n",
    "    )\n",
    "    table_acc = table_acc.sort_index(axis=1)\n",
    "    table_acc = table_acc.round(3)\n",
    "    \n",
    "    print(f\"\\n=== Train fraction: {frac} ===\")\n",
    "    print(table_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c88786d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== df_frac_02 ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>dataset</th>\n",
       "      <th>bankrupt</th>\n",
       "      <th>gender</th>\n",
       "      <th>mushroom</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>classifier</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.966</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.961</td>\n",
       "      <td>0.609</td>\n",
       "      <td>0.945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>0.969</td>\n",
       "      <td>0.749</td>\n",
       "      <td>0.999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "dataset             bankrupt  gender  mushroom\n",
       "classifier                                    \n",
       "KNN                    0.966   0.593     0.990\n",
       "LogisticRegression     0.961   0.609     0.945\n",
       "RandomForest           0.969   0.749     0.999"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== df_frac_05 ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>dataset</th>\n",
       "      <th>bankrupt</th>\n",
       "      <th>gender</th>\n",
       "      <th>mushroom</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>classifier</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.967</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.965</td>\n",
       "      <td>0.609</td>\n",
       "      <td>0.946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>0.970</td>\n",
       "      <td>0.763</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "dataset             bankrupt  gender  mushroom\n",
       "classifier                                    \n",
       "KNN                    0.967   0.604     0.998\n",
       "LogisticRegression     0.965   0.609     0.946\n",
       "RandomForest           0.970   0.763     1.000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== df_frac_08 ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>dataset</th>\n",
       "      <th>bankrupt</th>\n",
       "      <th>gender</th>\n",
       "      <th>mushroom</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>classifier</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.966</td>\n",
       "      <td>0.613</td>\n",
       "      <td>0.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.963</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>0.971</td>\n",
       "      <td>0.769</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "dataset             bankrupt  gender  mushroom\n",
       "classifier                                    \n",
       "KNN                    0.966   0.613     0.999\n",
       "LogisticRegression     0.963   0.610     0.945\n",
       "RandomForest           0.971   0.769     1.000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_frac_02 = (\n",
    "    all_results[all_results[\"train_frac\"] == 0.2]\n",
    "    .groupby([\"dataset\", \"classifier\"])\n",
    "    .agg(test_acc_mean=(\"test_acc\", \"mean\"))\n",
    "    .reset_index()\n",
    "    .pivot(index=\"classifier\", columns=\"dataset\", values=\"test_acc_mean\")\n",
    "    .round(3)\n",
    ")\n",
    "\n",
    "df_frac_05 = (\n",
    "    all_results[all_results[\"train_frac\"] == 0.5]\n",
    "    .groupby([\"dataset\", \"classifier\"])\n",
    "    .agg(test_acc_mean=(\"test_acc\", \"mean\"))\n",
    "    .reset_index()\n",
    "    .pivot(index=\"classifier\", columns=\"dataset\", values=\"test_acc_mean\")\n",
    "    .round(3)\n",
    ")\n",
    "\n",
    "df_frac_08 = (\n",
    "    all_results[all_results[\"train_frac\"] == 0.8]\n",
    "    .groupby([\"dataset\", \"classifier\"])\n",
    "    .agg(test_acc_mean=(\"test_acc\", \"mean\"))\n",
    "    .reset_index()\n",
    "    .pivot(index=\"classifier\", columns=\"dataset\", values=\"test_acc_mean\")\n",
    "    .round(3)\n",
    ")\n",
    "print(\"=== df_frac_02 ===\")\n",
    "display(df_frac_02)\n",
    "\n",
    "print(\"=== df_frac_05 ===\")\n",
    "display(df_frac_05)\n",
    "\n",
    "print(\"=== df_frac_08 ===\")\n",
    "display(df_frac_08)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "52096209",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results.to_csv(\"final_result.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a9d4cdd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 81 entries, 0 to 80\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   dataset      81 non-null     object \n",
      " 1   seed         81 non-null     int64  \n",
      " 2   train_frac   81 non-null     float64\n",
      " 3   classifier   81 non-null     object \n",
      " 4   best_params  81 non-null     object \n",
      " 5   val_acc      81 non-null     float64\n",
      " 6   train_acc    81 non-null     float64\n",
      " 7   test_acc     81 non-null     float64\n",
      "dtypes: float64(4), int64(1), object(3)\n",
      "memory usage: 5.2+ KB\n"
     ]
    }
   ],
   "source": [
    "all_results.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ef78eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "agg_results = (\n",
    "    all_results\n",
    "    .groupby([\"train_frac\", \"dataset\", \"classifier\"])\n",
    "    .agg(test_acc_mean=(\"test_acc\", \"mean\"))\n",
    "    .reset_index()\n",
    ")\n",
    "train_fracs = sorted(agg_results[\"train_frac\"].unique())\n",
    "\n",
    "for frac in train_fracs:\n",
    "    subset = agg_results[agg_results[\"train_frac\"] == frac]\n",
    "\n",
    "    heatmap_data = subset.pivot(index=\"classifier\", columns=\"dataset\", values=\"test_acc_mean\")\n",
    "\n",
    "    plt.figure(figsize=(8,5))\n",
    "    sns.heatmap(\n",
    "        heatmap_data, \n",
    "        annot=True, \n",
    "        fmt=\".3f\", \n",
    "        cmap=\"viridis\",\n",
    "        cbar_kws={'label': 'Test Accuracy'}\n",
    "    )\n",
    "    plt.title(f\"Test Accuracy Heatmap (Train Fraction: {frac})\")\n",
    "    plt.ylabel(\"Classifier\")\n",
    "    plt.xlabel(\"Dataset\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45189c2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x1000 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib import gridspec\n",
    "\n",
    "agg_results = (\n",
    "    all_results\n",
    "    .groupby([\"train_frac\", \"dataset\", \"classifier\"])\n",
    "    .agg(test_acc_mean=(\"test_acc\", \"mean\"))\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "train_fracs = sorted(agg_results[\"train_frac\"].unique())\n",
    "\n",
    "fig = plt.figure(figsize=(14, 10))\n",
    "gs = gridspec.GridSpec(2, 2, figure=fig, width_ratios=[1,1], height_ratios=[1,1], hspace=0.3, wspace=0.3)\n",
    "\n",
    "\n",
    "axes = [fig.add_subplot(gs[0,0]), fig.add_subplot(gs[0,1]), fig.add_subplot(gs[1,0])]\n",
    "\n",
    "vmin = agg_results['test_acc_mean'].min()\n",
    "vmax = agg_results['test_acc_mean'].max()\n",
    "\n",
    "for i, frac in enumerate(train_fracs):\n",
    "    subset = agg_results[agg_results[\"train_frac\"] == frac]\n",
    "    heatmap_data = subset.pivot(index=\"classifier\", columns=\"dataset\", values=\"test_acc_mean\")\n",
    "    \n",
    "    sns.heatmap(\n",
    "        heatmap_data, \n",
    "        annot=True, \n",
    "        fmt=\".3f\", \n",
    "        cmap=\"viridis\",\n",
    "        vmin=vmin, vmax=vmax,  # same scale for all\n",
    "        cbar=False, # if i != 0 else True,  # only first axes gets the colorbar\n",
    "        ax=axes[i]\n",
    "    )\n",
    "\n",
    "    axes[i].set_title(f\"Train Fraction: {frac}\")\n",
    "    axes[i].set_ylabel(\"Classifier\")\n",
    "    axes[i].set_xlabel(\"Dataset\")\n",
    "\n",
    "# Add single colorbar to the right\n",
    "cbar_ax = fig.add_axes([0.92, 0.15, 0.02, 0.7])  # [left, bottom, width, height]\n",
    "norm = plt.cm.ScalarMappable(cmap=\"viridis\", norm=plt.Normalize(vmin=vmin, vmax=vmax))\n",
    "norm.set_array([])\n",
    "fig.colorbar(norm, cax=cbar_ax, label=\"Test Accuracy\")\n",
    "\n",
    "# Turn off last empty subplot\n",
    "axes[-1].axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6ad9357b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6819 entries, 0 to 6818\n",
      "Data columns (total 96 columns):\n",
      " #   Column                                                    Non-Null Count  Dtype  \n",
      "---  ------                                                    --------------  -----  \n",
      " 0   Bankrupt?                                                 6819 non-null   int64  \n",
      " 1    ROA(C) before interest and depreciation before interest  6819 non-null   float64\n",
      " 2    ROA(A) before interest and % after tax                   6819 non-null   float64\n",
      " 3    ROA(B) before interest and depreciation after tax        6819 non-null   float64\n",
      " 4    Operating Gross Margin                                   6819 non-null   float64\n",
      " 5    Realized Sales Gross Margin                              6819 non-null   float64\n",
      " 6    Operating Profit Rate                                    6819 non-null   float64\n",
      " 7    Pre-tax net Interest Rate                                6819 non-null   float64\n",
      " 8    After-tax net Interest Rate                              6819 non-null   float64\n",
      " 9    Non-industry income and expenditure/revenue              6819 non-null   float64\n",
      " 10   Continuous interest rate (after tax)                     6819 non-null   float64\n",
      " 11   Operating Expense Rate                                   6819 non-null   float64\n",
      " 12   Research and development expense rate                    6819 non-null   float64\n",
      " 13   Cash flow rate                                           6819 non-null   float64\n",
      " 14   Interest-bearing debt interest rate                      6819 non-null   float64\n",
      " 15   Tax rate (A)                                             6819 non-null   float64\n",
      " 16   Net Value Per Share (B)                                  6819 non-null   float64\n",
      " 17   Net Value Per Share (A)                                  6819 non-null   float64\n",
      " 18   Net Value Per Share (C)                                  6819 non-null   float64\n",
      " 19   Persistent EPS in the Last Four Seasons                  6819 non-null   float64\n",
      " 20   Cash Flow Per Share                                      6819 non-null   float64\n",
      " 21   Revenue Per Share (Yuan ¥)                               6819 non-null   float64\n",
      " 22   Operating Profit Per Share (Yuan ¥)                      6819 non-null   float64\n",
      " 23   Per Share Net profit before tax (Yuan ¥)                 6819 non-null   float64\n",
      " 24   Realized Sales Gross Profit Growth Rate                  6819 non-null   float64\n",
      " 25   Operating Profit Growth Rate                             6819 non-null   float64\n",
      " 26   After-tax Net Profit Growth Rate                         6819 non-null   float64\n",
      " 27   Regular Net Profit Growth Rate                           6819 non-null   float64\n",
      " 28   Continuous Net Profit Growth Rate                        6819 non-null   float64\n",
      " 29   Total Asset Growth Rate                                  6819 non-null   float64\n",
      " 30   Net Value Growth Rate                                    6819 non-null   float64\n",
      " 31   Total Asset Return Growth Rate Ratio                     6819 non-null   float64\n",
      " 32   Cash Reinvestment %                                      6819 non-null   float64\n",
      " 33   Current Ratio                                            6819 non-null   float64\n",
      " 34   Quick Ratio                                              6819 non-null   float64\n",
      " 35   Interest Expense Ratio                                   6819 non-null   float64\n",
      " 36   Total debt/Total net worth                               6819 non-null   float64\n",
      " 37   Debt ratio %                                             6819 non-null   float64\n",
      " 38   Net worth/Assets                                         6819 non-null   float64\n",
      " 39   Long-term fund suitability ratio (A)                     6819 non-null   float64\n",
      " 40   Borrowing dependency                                     6819 non-null   float64\n",
      " 41   Contingent liabilities/Net worth                         6819 non-null   float64\n",
      " 42   Operating profit/Paid-in capital                         6819 non-null   float64\n",
      " 43   Net profit before tax/Paid-in capital                    6819 non-null   float64\n",
      " 44   Inventory and accounts receivable/Net value              6819 non-null   float64\n",
      " 45   Total Asset Turnover                                     6819 non-null   float64\n",
      " 46   Accounts Receivable Turnover                             6819 non-null   float64\n",
      " 47   Average Collection Days                                  6819 non-null   float64\n",
      " 48   Inventory Turnover Rate (times)                          6819 non-null   float64\n",
      " 49   Fixed Assets Turnover Frequency                          6819 non-null   float64\n",
      " 50   Net Worth Turnover Rate (times)                          6819 non-null   float64\n",
      " 51   Revenue per person                                       6819 non-null   float64\n",
      " 52   Operating profit per person                              6819 non-null   float64\n",
      " 53   Allocation rate per person                               6819 non-null   float64\n",
      " 54   Working Capital to Total Assets                          6819 non-null   float64\n",
      " 55   Quick Assets/Total Assets                                6819 non-null   float64\n",
      " 56   Current Assets/Total Assets                              6819 non-null   float64\n",
      " 57   Cash/Total Assets                                        6819 non-null   float64\n",
      " 58   Quick Assets/Current Liability                           6819 non-null   float64\n",
      " 59   Cash/Current Liability                                   6819 non-null   float64\n",
      " 60   Current Liability to Assets                              6819 non-null   float64\n",
      " 61   Operating Funds to Liability                             6819 non-null   float64\n",
      " 62   Inventory/Working Capital                                6819 non-null   float64\n",
      " 63   Inventory/Current Liability                              6819 non-null   float64\n",
      " 64   Current Liabilities/Liability                            6819 non-null   float64\n",
      " 65   Working Capital/Equity                                   6819 non-null   float64\n",
      " 66   Current Liabilities/Equity                               6819 non-null   float64\n",
      " 67   Long-term Liability to Current Assets                    6819 non-null   float64\n",
      " 68   Retained Earnings to Total Assets                        6819 non-null   float64\n",
      " 69   Total income/Total expense                               6819 non-null   float64\n",
      " 70   Total expense/Assets                                     6819 non-null   float64\n",
      " 71   Current Asset Turnover Rate                              6819 non-null   float64\n",
      " 72   Quick Asset Turnover Rate                                6819 non-null   float64\n",
      " 73   Working capitcal Turnover Rate                           6819 non-null   float64\n",
      " 74   Cash Turnover Rate                                       6819 non-null   float64\n",
      " 75   Cash Flow to Sales                                       6819 non-null   float64\n",
      " 76   Fixed Assets to Assets                                   6819 non-null   float64\n",
      " 77   Current Liability to Liability                           6819 non-null   float64\n",
      " 78   Current Liability to Equity                              6819 non-null   float64\n",
      " 79   Equity to Long-term Liability                            6819 non-null   float64\n",
      " 80   Cash Flow to Total Assets                                6819 non-null   float64\n",
      " 81   Cash Flow to Liability                                   6819 non-null   float64\n",
      " 82   CFO to Assets                                            6819 non-null   float64\n",
      " 83   Cash Flow to Equity                                      6819 non-null   float64\n",
      " 84   Current Liability to Current Assets                      6819 non-null   float64\n",
      " 85   Liability-Assets Flag                                    6819 non-null   int64  \n",
      " 86   Net Income to Total Assets                               6819 non-null   float64\n",
      " 87   Total assets to GNP price                                6819 non-null   float64\n",
      " 88   No-credit Interval                                       6819 non-null   float64\n",
      " 89   Gross Profit to Sales                                    6819 non-null   float64\n",
      " 90   Net Income to Stockholder's Equity                       6819 non-null   float64\n",
      " 91   Liability to Equity                                      6819 non-null   float64\n",
      " 92   Degree of Financial Leverage (DFL)                       6819 non-null   float64\n",
      " 93   Interest Coverage Ratio (Interest expense to EBIT)       6819 non-null   float64\n",
      " 94   Net Income Flag                                          6819 non-null   int64  \n",
      " 95   Equity to Liability                                      6819 non-null   float64\n",
      "dtypes: float64(93), int64(3)\n",
      "memory usage: 5.0 MB\n"
     ]
    }
   ],
   "source": [
    "bankrupts.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "fa47b816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\\\begin{tabular}{lrrrrrrrrr}\\n\\\\toprule\\ndataset & \\\\multicolumn{3}{r}{bankrupt} & \\\\multicolumn{3}{r}{gender} & \\\\multicolumn{3}{r}{mushroom} \\\\\\\\\\ntrain_frac & 0.200000 & 0.500000 & 0.800000 & 0.200000 & 0.500000 & 0.800000 & 0.200000 & 0.500000 & 0.800000 \\\\\\\\\\nclassifier &  &  &  &  &  &  &  &  &  \\\\\\\\\\n\\\\midrule\\nKNN & 0.966000 & 0.967000 & 0.966000 & 0.593000 & 0.604000 & 0.613000 & 0.990000 & 0.998000 & 0.999000 \\\\\\\\\\nLogisticRegression & 0.961000 & 0.965000 & 0.963000 & 0.609000 & 0.609000 & 0.610000 & 0.945000 & 0.946000 & 0.945000 \\\\\\\\\\nRandomForest & 0.969000 & 0.970000 & 0.971000 & 0.749000 & 0.763000 & 0.769000 & 0.999000 & 1.000000 & 1.000000 \\\\\\\\\\n\\\\bottomrule\\n\\\\end{tabular}\\n'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_acc_1.to_latex()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7087433",
   "metadata": {},
   "source": [
    "<div>\n",
    "<style scoped>\n",
    "    .dataframe tbody tr th:only-of-type {\n",
    "        vertical-align: middle;\n",
    "    }\n",
    "\n",
    "    .dataframe tbody tr th {\n",
    "        vertical-align: top;\n",
    "    }\n",
    "\n",
    "    .dataframe thead tr th {\n",
    "        text-align: left;\n",
    "    }\n",
    "\n",
    "    .dataframe thead tr:last-of-type th {\n",
    "        text-align: right;\n",
    "    }\n",
    "</style>\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th>dataset</th>\n",
    "      <th colspan=\"3\" halign=\"left\">bankrupt</th>\n",
    "      <th colspan=\"3\" halign=\"left\">gender</th>\n",
    "      <th colspan=\"3\" halign=\"left\">mushroom</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>train_frac</th>\n",
    "      <th>0.2</th>\n",
    "      <th>0.5</th>\n",
    "      <th>0.8</th>\n",
    "      <th>0.2</th>\n",
    "      <th>0.5</th>\n",
    "      <th>0.8</th>\n",
    "      <th>0.2</th>\n",
    "      <th>0.5</th>\n",
    "      <th>0.8</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>classifier</th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>KNN</th>\n",
    "      <td>0.966</td>\n",
    "      <td>0.967</td>\n",
    "      <td>0.966</td>\n",
    "      <td>0.593</td>\n",
    "      <td>0.604</td>\n",
    "      <td>0.613</td>\n",
    "      <td>0.990</td>\n",
    "      <td>0.998</td>\n",
    "      <td>0.999</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>LogisticRegression</th>\n",
    "      <td>0.961</td>\n",
    "      <td>0.965</td>\n",
    "      <td>0.963</td>\n",
    "      <td>0.609</td>\n",
    "      <td>0.609</td>\n",
    "      <td>0.610</td>\n",
    "      <td>0.945</td>\n",
    "      <td>0.946</td>\n",
    "      <td>0.945</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>RandomForest</th>\n",
    "      <td>0.969</td>\n",
    "      <td>0.970</td>\n",
    "      <td>0.971</td>\n",
    "      <td>0.749</td>\n",
    "      <td>0.763</td>\n",
    "      <td>0.769</td>\n",
    "      <td>0.999</td>\n",
    "      <td>1.000</td>\n",
    "      <td>1.000</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a39193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "',dataset,seed,train_frac,classifier,best_params,val_acc,train_acc,test_acc\\n0,mushroom,0,0.2,LogisticRegression,{\\'C\\': 1},0.9359609215315813,0.9402709359605911,0.9436923076923077\\n1,mushroom,0,0.2,RandomForest,\"{\\'max_depth\\': None, \\'n_estimators\\': 50}\",0.9981515711645103,1.0,0.9987692307692307\\n2,mushroom,0,0.2,KNN,{\\'n_neighbors\\': 3},0.9766047568054238,0.9963054187192119,0.9910769230769231\\n3,mushroom,0,0.5,LogisticRegression,{\\'C\\': 1},0.9391925160019694,0.9419005416051206,0.9441161989167898\\n4,mushroom,0,0.5,RandomForest,\"{\\'max_depth\\': None, \\'n_estimators\\': 100}\",0.999507631708518,1.0,1.0\\n5,mushroom,0,0.5,KNN,{\\'n_neighbors\\': 3},0.9955686853766618,0.9987690792712949,0.9970457902511078\\n6,mushroom,0,0.8,LogisticRegression,{\\'C\\': 1},0.9481461975521062,0.9486074780735497,0.940923076923077\\n7,mushroom,0,0.8,RandomForest,\"{\\'max_depth\\': None, \\'n_estimators\\': 50}\",1.0,1.0,1.0\\n8,mushroom,0,0.8,KNN,{\\'n_neighbors\\': 3},0.9983074555047501,1.0,0.9993846153846154\\n9,mushroom,42,0.2,LogisticRegression,{\\'C\\': 10},0.94458237558346,0.9488916256157636,0.9458461538461539\\n10,mushroom,42,0.2,RandomForest,\"{\\'max_depth\\': None, \\'n_estimators\\': 50}\",0.9993838570548368,1.0,0.9987692307692307\\n11,mushroom,42,0.2,KNN,{\\'n_neighbors\\': 3},0.9833732348414057,0.9963054187192119,0.9883076923076923\\n12,mushroom,42,0.5,LogisticRegression,{\\'C\\': 1},0.9453471196454949,0.9470704086656819,0.9487936976858691\\n13,mushroom,42,0.5,RandomForest,\"{\\'max_depth\\': None, \\'n_estimators\\': 50}\",0.9992614475627769,1.0,1.0\\n14,mushroom,42,0.5,KNN,{\\'n_neighbors\\': 3},0.9948301329394386,0.999015263417036,0.9987690792712949\\n15,mushroom,42,0.8,LogisticRegression,{\\'C\\': 10},0.9430680669484331,0.9450684720726266,0.952\\n16,mushroom,42,0.8,RandomForest,\"{\\'max_depth\\': None, \\'n_estimators\\': 50}\",0.9992308875557606,1.0,1.0\\n17,mushroom,42,0.8,KNN,{\\'n_neighbors\\': 3},0.9967690175657328,0.9996922603477458,0.9987692307692307\\n18,mushroom,99,0.2,LogisticRegression,{\\'C\\': 10},0.9556684014159921,0.9568965517241379,0.9446153846153846\\n19,mushroom,99,0.2,RandomForest,\"{\\'max_depth\\': None, \\'n_estimators\\': 50}\",0.9987677141096735,1.0,1.0\\n20,mushroom,99,0.2,KNN,{\\'n_neighbors\\': 3},0.9809063894705491,0.9963054187192119,0.9907692307692307\\n21,mushroom,99,0.5,LogisticRegression,{\\'C\\': 1},0.9473165928114229,0.9510093549975381,0.9453471196454948\\n22,mushroom,99,0.5,RandomForest,\"{\\'max_depth\\': None, \\'n_estimators\\': 50}\",1.0,1.0,1.0\\n23,mushroom,99,0.5,KNN,{\\'n_neighbors\\': 3},0.9965534219596259,0.9997538158542589,0.9987690792712949\\n24,mushroom,99,0.8,LogisticRegression,{\\'C\\': 1},0.9484551918498795,0.9498384366825665,0.940923076923077\\n25,mushroom,99,0.8,RandomForest,\"{\\'max_depth\\': None, \\'n_estimators\\': 50}\",1.0,1.0,1.0\\n26,mushroom,99,0.8,KNN,{\\'n_neighbors\\': 3},0.99769195249882,1.0,0.9993846153846154\\n'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6df665e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>seed</th>\n",
       "      <th>train_frac</th>\n",
       "      <th>classifier</th>\n",
       "      <th>best_params</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>test_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mushroom</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'C': 1}</td>\n",
       "      <td>0.935961</td>\n",
       "      <td>0.940271</td>\n",
       "      <td>0.943692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mushroom</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 50}</td>\n",
       "      <td>0.998152</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mushroom</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>KNN</td>\n",
       "      <td>{'n_neighbors': 3}</td>\n",
       "      <td>0.976605</td>\n",
       "      <td>0.996305</td>\n",
       "      <td>0.991077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mushroom</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'C': 1}</td>\n",
       "      <td>0.939193</td>\n",
       "      <td>0.941901</td>\n",
       "      <td>0.944116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mushroom</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 100}</td>\n",
       "      <td>0.999508</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>bankrupt</td>\n",
       "      <td>99</td>\n",
       "      <td>0.5</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 50}</td>\n",
       "      <td>0.968612</td>\n",
       "      <td>0.997653</td>\n",
       "      <td>0.971848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>bankrupt</td>\n",
       "      <td>99</td>\n",
       "      <td>0.5</td>\n",
       "      <td>KNN</td>\n",
       "      <td>{'n_neighbors': 7}</td>\n",
       "      <td>0.967733</td>\n",
       "      <td>0.968026</td>\n",
       "      <td>0.966862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>bankrupt</td>\n",
       "      <td>99</td>\n",
       "      <td>0.8</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'C': 0.01}</td>\n",
       "      <td>0.964803</td>\n",
       "      <td>0.963520</td>\n",
       "      <td>0.961877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>bankrupt</td>\n",
       "      <td>99</td>\n",
       "      <td>0.8</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 50}</td>\n",
       "      <td>0.968836</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.972141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>bankrupt</td>\n",
       "      <td>99</td>\n",
       "      <td>0.8</td>\n",
       "      <td>KNN</td>\n",
       "      <td>{'n_neighbors': 5}</td>\n",
       "      <td>0.967919</td>\n",
       "      <td>0.968836</td>\n",
       "      <td>0.962610</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     dataset  seed  train_frac          classifier  \\\n",
       "0   mushroom     0         0.2  LogisticRegression   \n",
       "1   mushroom     0         0.2        RandomForest   \n",
       "2   mushroom     0         0.2                 KNN   \n",
       "3   mushroom     0         0.5  LogisticRegression   \n",
       "4   mushroom     0         0.5        RandomForest   \n",
       "..       ...   ...         ...                 ...   \n",
       "76  bankrupt    99         0.5        RandomForest   \n",
       "77  bankrupt    99         0.5                 KNN   \n",
       "78  bankrupt    99         0.8  LogisticRegression   \n",
       "79  bankrupt    99         0.8        RandomForest   \n",
       "80  bankrupt    99         0.8                 KNN   \n",
       "\n",
       "                                 best_params   val_acc  train_acc  test_acc  \n",
       "0                                   {'C': 1}  0.935961   0.940271  0.943692  \n",
       "1    {'max_depth': None, 'n_estimators': 50}  0.998152   1.000000  0.998769  \n",
       "2                         {'n_neighbors': 3}  0.976605   0.996305  0.991077  \n",
       "3                                   {'C': 1}  0.939193   0.941901  0.944116  \n",
       "4   {'max_depth': None, 'n_estimators': 100}  0.999508   1.000000  1.000000  \n",
       "..                                       ...       ...        ...       ...  \n",
       "76     {'max_depth': 10, 'n_estimators': 50}  0.968612   0.997653  0.971848  \n",
       "77                        {'n_neighbors': 7}  0.967733   0.968026  0.966862  \n",
       "78                               {'C': 0.01}  0.964803   0.963520  0.961877  \n",
       "79   {'max_depth': None, 'n_estimators': 50}  0.968836   1.000000  0.972141  \n",
       "80                        {'n_neighbors': 5}  0.967919   0.968836  0.962610  \n",
       "\n",
       "[81 rows x 8 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacf6bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate LaTeX code for the full table\n",
    "with open(\"all_results.tex\", \"w\") as f:\n",
    "    f.write(all_results.to_latex(index=False, longtable=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "68c23366",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results.to_latex(\n",
    "    \"all_results.tex\",\n",
    "    index=False,\n",
    "    longtable=True,\n",
    "    escape=True   # escapes all LaTeX special characters automatically\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "068c2af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results['best_params_str'] = all_results['best_params'].apply(lambda d: str(d).replace(\"{\", \"\").replace(\"}\", \"\"))\n",
    "all_results.to_latex(\n",
    "    \"all_results.tex\",\n",
    "    index=False,\n",
    "    longtable=True,\n",
    "    escape=True,\n",
    "    columns=['dataset','seed','train_frac','classifier','best_params_str','val_acc','train_acc','test_acc']\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7691bed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cogs118a",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
